{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "699b4730",
   "metadata": {},
   "source": [
    "# 2.6 Building agents for complex tasks\n",
    "\n",
    "## ğŸš„ Preface\n",
    "\n",
    "Having completed the previous chapters, you have successfully built a Q&A bot â€“ one that can accurately answer questions related to writing guidelines.\n",
    "\n",
    "Now, many colleagues have raised a similar request: since the Q&A bot is well-versed in writing guidelines, could it assist in developing educational courses?\n",
    "\n",
    "Let's analyze the technical feasibility. You'll find that the bot can only retrieve writing guidelines from its internal knowledge base. It cannot access the latest research papers, nor can it automatically remember the progress of course development.\n",
    "\n",
    "This is because a standalone Large Language Model (LLM) is like a brain isolated in a room â€“ it can think, but it lacks senses to receive real-time information, hands and feet to perform specific tasks, and the ability to learn continuously.\n",
    "\n",
    "To overcome these limitations, you need to build a complete system on top of an LLM, allowing it to perceive its environment, think, plan, execute tasks, and learn from experience, much like a domain expert. This system is called an Agent. It consists of the following core modules:\n",
    "\n",
    "| Core Module        | Function                                                  | Analogy         |\n",
    "|--------------------|-----------------------------------------------------------|-----------------|\n",
    "| Thinking & Planning| LLM understands intent, breaks down tasks into executable steps | ğŸ§  Brain        |\n",
    "| Perception         | Receives user input, API responses, system status         | ğŸ‘€ Senses       |\n",
    "| Execution          | Calls APIs, queries databases, sends messages             | âœ‹ Hands & Feet  |\n",
    "| Memory             | Stores history, experiences, lessons, supports decision-making | ğŸ“š Memory       |\n",
    "\n",
    "\n",
    "\n",
    "These four modules form a **\"Think-Act-Observe\"** closed loop. Through this cycle, an Agent can autonomously plan, execute tasks, and adjust its behavior based on real-world feedback to accomplish complex tasks.\n",
    "\n",
    "## ğŸ Goals\n",
    "\n",
    "Agent building is an experimental science; there is currently no standard methodology, so you will need to continuously explore and iterate on Agent architectures in practice. This section will delve into the core modules and evaluation system of Agents, helping you master:\n",
    "- Task Decomposition Capability: Breaking down complex requirements into executable steps.\n",
    "- Prototype Building Capability: Rapidly setting up business Agent systems.\n",
    "- Evaluation and Iteration Capability: Quantitatively diagnosing and continuously optimizing.\n",
    "\n",
    "## ğŸ› ï¸ Environment setup and basic tools\n",
    "\n",
    "At the start of this course, you will continue to learn how to use the OpenAI SDK to call LLMs. Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a71daa4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T06:05:25.158583Z",
     "iopub.status.busy": "2025-11-20T06:05:25.158370Z",
     "iopub.status.idle": "2025-11-20T06:05:28.049720Z",
     "shell.execute_reply": "2025-11-20T06:05:28.049147Z",
     "shell.execute_reply.started": "2025-11-20T06:05:25.158565Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I'm Qwen, a large-scale language model independently developed by the Tongyi Lab under Alibaba Group. I can answer questions, create text such as stories, official documents, emails, scripts, perform logical reasoning, coding, and more. I can also express opinions and play games. I support 100 languages, including but not limited to Chinese, English, German, French, Spanish, etc., meeting international usage needs. If you have any questions or need assistance, feel free to let me know anytime!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from config.load_key import load_key\n",
    "load_key()\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n",
    "    base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
    ")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"qwen-plus\", \n",
    "    messages=[\n",
    "        {'role': 'system', 'content': 'You are a helpful assistant.'},\n",
    "        {'role': 'user', 'content': 'Who are you?'}\n",
    "    ]\n",
    ")\n",
    "print(completion.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3e0258",
   "metadata": {},
   "source": [
    "## 1 Teaching the agent to use tools\n",
    "### 1.1 Your first tool function\n",
    "A colleague is developing an online course on \"Basic Principles of LLMs,\" and he hopes the bot can help him collect the latest teaching materials from the internet.\n",
    "\n",
    "You will find that the bot can only retrieve information from the company's knowledge base or answer questions using the LLM's world knowledge.\n",
    "\n",
    "#### 1.1.1 Hardcoded solution: The simplest implementation\n",
    "To enable the bot to access internet information, the most direct approach is to write a web search tool function for it. This function will search for the user's question each time and send the search results along with the question to the LLM.\n",
    "\n",
    "Suppose you have already written a function called web_search that can find information via a search engine. Now, when a user makes a request, you want the model to utilize this function. The simplest way to implement this is for the program to \"hardcode\" the execution of this function upon receiving a request, then send the execution result along with the original request to the LLM, allowing it to generate a summary response.\n",
    "\n",
    "<img src=\"https://img.alicdn.com/imgextra/i4/O1CN01lERk2B1mVjalZ5hOh_!!6000000004960-55-tps-2281-435.svg\" width=\"700\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f470ccce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T06:05:28.050612Z",
     "iopub.status.busy": "2025-11-20T06:05:28.050449Z",
     "iopub.status.idle": "2025-11-20T06:05:34.330553Z",
     "shell.execute_reply": "2025-11-20T06:05:34.329987Z",
     "shell.execute_reply.started": "2025-11-20T06:05:28.050597Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- [Tool Executing] Searching: Hello, please help me collect some latest materials about Transformer models. ---\n",
      "User Request: Hello, please help me collect some latest materials about Transformer models.\n",
      "Tool Result: {\n",
      "        \"results\": [\n",
      "            {\"title\": \"Attention Is All You Need (Transformer original paper)\", \"url\": \"https://arxiv.org/abs/1706.03762\", \"snippet\": \"The dominant sequence transduction models are based on complex recurrent or convolutional neural networks... We propose a new simple network architecture, the Transformer, based solely on attention mechanisms...\"},\n",
      "            {\"title\": \"The Illustrated Transformer â€“ Jay Alammar\", \"url\": \"https://jalammar.github.io/illustrated-transformer/\", \"snippet\": \"A visual and intuitive explanation of the Transformer model.\"}\n",
      "        ]\n",
      "    }\n",
      "\n",
      "Model's Final Response:\n",
      "Hello! Here are some helpful materials about Transformer models:\n",
      "\n",
      "1. **[Attention Is All You Need (Transformer Original Paper)](https://arxiv.org/abs/1706.03762)**  \n",
      "   This is the groundbreaking 2017 paper that introduced the Transformer architecture. It explains how the model relies entirely on attention mechanisms, moving away from recurrent and convolutional structures. A must-read for understanding the foundation of modern NLP.\n",
      "\n",
      "2. **[The Illustrated Transformer â€“ Jay Alammar](https://jalammar.github.io/illustrated-transformer/)**  \n",
      "   A fantastic visual guide that breaks down the Transformer model in an intuitive and easy-to-understand way. Great if you're looking for a more accessible introduction with helpful diagrams.\n",
      "\n",
      "Let me know if you'd like more recent advancements (like BERT, GPT, or newer variants), or materials focused on specific applications or implementations!\n"
     ]
    }
   ],
   "source": [
    "# 1. User's original request\n",
    "user_request = \"Hello, please help me collect some latest materials about Transformer models.\"\n",
    "\n",
    "# 2. \"Hardcoded\" execution of the tool function\n",
    "# The web_search function here is simulated to focus on the core logic.\n",
    "def web_search(query: str):\n",
    "    \"\"\"Simulates performing a web search and returning results in JSON format.\"\"\"\n",
    "    print(f\"--- [Tool Executing] Searching: {query} ---\")\n",
    "    # In a real scenario, this would call a real search engine API.\n",
    "    return '''{\n",
    "        \"results\": [\n",
    "            {\"title\": \"Attention Is All You Need (Transformer original paper)\", \"url\": \"https://arxiv.org/abs/1706.03762\", \"snippet\": \"The dominant sequence transduction models are based on complex recurrent or convolutional neural networks... We propose a new simple network architecture, the Transformer, based solely on attention mechanisms...\"},\n",
    "            {\"title\": \"The Illustrated Transformer â€“ Jay Alammar\", \"url\": \"https://jalammar.github.io/illustrated-transformer/\", \"snippet\": \"A visual and intuitive explanation of the Transformer model.\"}\n",
    "        ]\n",
    "    }'''\n",
    "\n",
    "tool_result = web_search(query=user_request)\n",
    "\n",
    "print(f\"User Request: {user_request}\")\n",
    "print(f\"Tool Result: {tool_result}\\n\")\n",
    "\n",
    "# 3. Concatenate the user request and tool result into a prompt and send it to the LLM.\n",
    "#    The goal is for the model to generate a human-readable response based on the structured tool output.\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"qwen-plus\",\n",
    "    messages=[\n",
    "        {'role': 'system', 'content': 'You are a course research assistant. Your task is to generate a friendly and clear response to the user based on the tool execution results.'},\n",
    "        {'role': 'user', 'content': f'User original request: \"{user_request}\"\\nTool execution result: {tool_result}'}\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 4. Output the model's final response\n",
    "final_response = completion.choices[0].message.content\n",
    "print(f\"Model's Final Response:\\n{final_response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1472cef6",
   "metadata": {},
   "source": [
    "#### 1.1.2 Limitations analysis: Why a more flexible solution is needed\n",
    "\n",
    "While this approach is simple and effective, it has limitations: it only applies to scenarios where \"there is exactly one tool, and it must be called every time.\" As colleagues' needs grow, your bot may need to add more tools, such as `search_arxiv_paper` (to search for papers on academic sites like Arxiv) or `fetch_webpage_content` (to retrieve the full content of a specified web page). At this point, you will encounter a more difficult problem: how can the bot call tools on demand?\n",
    "\n",
    "### 1.2 Intent recognition: Letting the agent decide which tool to use\n",
    "#### 1.2.1 Fragile keyword matching\n",
    "A direct idea is to write a \"router\" that uses `if/elif` structures and keyword matching to determine the user's intent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "758a2102",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T06:05:34.331132Z",
     "iopub.status.busy": "2025-11-20T06:05:34.330973Z",
     "iopub.status.idle": "2025-11-20T06:05:34.334084Z",
     "shell.execute_reply": "2025-11-20T06:05:34.333572Z",
     "shell.execute_reply.started": "2025-11-20T06:05:34.331115Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pseudocode: A fragile, keyword-based tool router\n",
    "def route_to_tool(user_input):\n",
    "    if \"paper\" in user_input or \"arxiv\" in user_input:\n",
    "        return \"search_arxiv_paper\"\n",
    "    elif \"search\" in user_input or \"find\" in user_input or \"materials\" in user_input:\n",
    "        return \"web_search\"\n",
    "    elif \"summarize\" in user_input or \"content\" in user_input or \"http\" in user_input:\n",
    "        return \"fetch_webpage_content\"\n",
    "    # ... You need to keep adding elif conditions here\n",
    "    else:\n",
    "        return \"no_tool_needed\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b167f398",
   "metadata": {},
   "source": [
    "You can immediately see the drawbacks of this method. It is very **fragile and difficult to maintain**. If the user says, \"I want to see what that 'Attention Is All You Need' paper is about,\" this rudimentary router cannot identify the intent to use `search_arxiv_paper` and `fetch_webpage_content` because it does not contain any predefined keywords.\n",
    "\n",
    "#### 1.2.2 LLM-based intent recognition\n",
    "A better approach is to list all available tools in the prompt and let the LLM decide which tool to call and with what parameters. This is a simple implementation of intent recognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac27af44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T06:05:34.334911Z",
     "iopub.status.busy": "2025-11-20T06:05:34.334767Z",
     "iopub.status.idle": "2025-11-20T06:05:36.681973Z",
     "shell.execute_reply": "2025-11-20T06:05:36.681335Z",
     "shell.execute_reply.started": "2025-11-20T06:05:34.334897Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User request: \"Help me find that classic Transformer paper titled 'Attention Is All You Need'\"\n",
      "Model decision: I will use the **search_arxiv_paper** tool to find the classic Transformer paper titled \"Attention Is All You Need\".\n",
      "\n",
      "**Tool:** search_arxiv_paper  \n",
      "**Input parameters:**  \n",
      "- query: \"Attention Is All You Need\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_tool_decision_from_llm(user_request):\n",
    "    from textwrap import dedent\n",
    "\n",
    "    # Use dedent to remove indentation added for code aesthetics,\n",
    "    # preventing these formatting tabs/spaces from being passed to the LLM.\n",
    "    prompt = dedent(f\"\"\"\n",
    "        You are a routing module for an intelligent assistant. Your task is to select the most suitable tool from the list below to solve the problem based on the user's request, and provide the input parameters.\n",
    "\n",
    "        [Available tools list]\n",
    "        1. web_search: Used to search for general information on the internet.\n",
    "        2. search_arxiv_paper: Used to search for academic papers on Arxiv.org.\n",
    "        3. fetch_webpage_content: Used to retrieve the content of a web page from a specified URL.\n",
    "\n",
    "        [User request]\n",
    "        \"{user_request}\"\n",
    "\n",
    "        [Decision]\n",
    "        Please tell the user your decision.\n",
    "    \"\"\")\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"qwen-plus\",\n",
    "        messages=[\n",
    "            {'role': 'user', 'content': prompt}\n",
    "        ],\n",
    "        temperature=0.0 # Use low temperature to get more deterministic decisions\n",
    "    )\n",
    "    decision = completion.choices[0].message.content\n",
    "    return decision\n",
    "\n",
    "# --- Test cases ---\n",
    "request = \"Help me find that classic Transformer paper titled 'Attention Is All You Need'\"\n",
    "decision = get_tool_decision_from_llm(request)\n",
    "print(f\"User request: \\\"{request}\\\"\")\n",
    "print(f\"Model decision: {decision}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beaafbee",
   "metadata": {},
   "source": [
    "### 1.3 Ensuring reliability: Structured output\n",
    "#### 1.3.1 Why structured output is needed\n",
    "Now that you've solved the problem of \"which tool to call,\" the next step is to parse and execute the LLM's decision using code. However, you'll find that the LLM's results are interspersed with natural language and lack a fixed format:\n",
    "\n",
    "*   `I will use the search_arxiv_paper tool to search for the classic Transformer paper titled \"Attention Is All You Need\".`\n",
    "*   `Okay, the tool is search_arxiv_paper`\n",
    "*   `search_arxiv_paper(query=\"Attention Is All You Need\")`\n",
    "\n",
    "This is because LLMs tend to generate diverse text, but what you need is an easy-to-parse, deterministic data format. To solve this problem, you need to turn it around and require the model to output strictly according to your predefined structured format.\n",
    "\n",
    "JSON is such an ideal format. A clearly defined JSON output is unambiguous and easy to parse:\n",
    "```json\n",
    "{\n",
    "  \"tool_name\": \"search_arxiv_paper\",\n",
    "  \"parameters\": {\n",
    "    \"query\": \"Attention Is All You Need\"\n",
    "  }\n",
    "}\n",
    "```\n",
    "It clearly defines \"what to do\" (tool_name) and \"what to use to do it\" (parameters). This key-value pair structure can be easily parsed by any programming language.\n",
    "\n",
    "#### 1.3.2 Building a \"guide-validate-retry\" closed loop\n",
    "\n",
    "The next task is to ensure that the model can consistently and strictly output in the JSON structure you define. To achieve this, you need to establish a clear process.\n",
    "\n",
    "1.  **Define structure**: First, you need to precisely define your expected output structure. You can use JSON Schema (a language for describing JSON data structures) or define data models in Python code using libraries like Pydantic. This Schema explicitly states which fields the final output must contain and the type of each field, serving as the foundation of the entire process.\n",
    "\n",
    "2.  **Construct the prompt**: In your prompt, in addition to giving task instructions, you should also include the complete Schema definition and provide one or two output examples that perfectly conform to this Schema. Through this \"instruction + example\" method, the model can more thoroughly understand your requirements.\n",
    "\n",
    "3.  **Validate and retry**: After receiving the model's output, the program must strictly validate it using the same Schema. If validation fails, the program should capture the validation error message and send it, along with the model's previous erroneous output, back to the model as a correction clue, requesting it to regenerate.\n",
    "\n",
    "<img src=\"https://img.alicdn.com/imgextra/i2/O1CN01PPZqEP1NWJhdVXbPs_!!6000000001577-55-tps-2701-491.svg\" width=\"700\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f9171ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T06:05:36.682666Z",
     "iopub.status.busy": "2025-11-20T06:05:36.682492Z",
     "iopub.status.idle": "2025-11-20T06:05:37.768485Z",
     "shell.execute_reply": "2025-11-20T06:05:37.767951Z",
     "shell.execute_reply.started": "2025-11-20T06:05:36.682650Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"tool_name\": \"search_arxiv_paper\",\n",
      "  \"parameters\": {\n",
      "    \"query\": \"Attention Is All You Need\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from textwrap import dedent\n",
    "from typing import Union, Literal\n",
    "from pydantic import BaseModel, Field, ValidationError, TypeAdapter\n",
    "\n",
    "# 1. Define Pydantic parameter models for course research-related tools\n",
    "class WebSearchParams(BaseModel):\n",
    "    query: str = Field(description=\"Keywords for web search.\")\n",
    "\n",
    "class SearchArxivParams(BaseModel):\n",
    "    query: str = Field(description=\"Paper title or keywords for searching on Arxiv.org.\")\n",
    "\n",
    "# 2. Define the tool call model, binding tool name with its corresponding parameter model\n",
    "class WebSearchCall(BaseModel):\n",
    "    tool_name: Literal[\"web_search\"]\n",
    "    parameters: WebSearchParams\n",
    "\n",
    "class SearchArxivCall(BaseModel):\n",
    "    tool_name: Literal[\"search_arxiv_paper\"]\n",
    "    parameters: SearchArxivParams\n",
    "\n",
    "# Use Union type to indicate that the model's final decision is one of these two calls\n",
    "ToolCall = Union[WebSearchCall, SearchArxivCall]\n",
    "\n",
    "# 3. Build the prompt, including clear instructions, tool definitions, and examples\n",
    "def build_prompt(user_request: str) -> str:\n",
    "    return dedent(f\"\"\"\n",
    "        Your task is to select the most suitable tool from the list of available tools based on the user's request, and output the call information in a strict JSON format.\n",
    "\n",
    "        # Available tools:\n",
    "        - `web_search(query: str)`: Use when needing to search for general information, news, or non-academic content.\n",
    "        - `search_arxiv_paper(query: str)`: Use when needing to search for academic papers, especially from Arxiv.org.\n",
    "        - `fetch_webpage_content(url: str)`: Use to retrieve content from a specified URL. # Note: This tool was mentioned in 1.2.1 but not defined in the class here, adding it for completeness if it were present.\n",
    "\n",
    "        # Output format requirements:\n",
    "        You must strictly follow the JSON structure below and do not include any additional natural language explanations.\n",
    "\n",
    "        {{\n",
    "        \"tool_name\": \"tool_name\",\n",
    "        \"parameters\": {{\n",
    "            \"parameter_name\": \"parameter_value\"\n",
    "        }}\n",
    "        }}\n",
    "\n",
    "        # Example:\n",
    "        User request: \"What's the latest interesting news in the AI field?\"\n",
    "        Your output:\n",
    "        {{\n",
    "        \"tool_name\": \"web_search\",\n",
    "        \"parameters\": {{\n",
    "            \"query\": \"latest news in AI field\"\n",
    "        }}\n",
    "        }}\n",
    "\n",
    "        # User request:\n",
    "        \"{user_request}\"\n",
    "\n",
    "        # Your output:\n",
    "    \"\"\")\n",
    "\n",
    "# 4. Call and validate (with retry)\n",
    "def get_structured_output(user_request: str, max_retries: int = 2):\n",
    "    messages = [{'role': 'user', 'content': build_prompt(user_request)}]\n",
    "    adapter = TypeAdapter(ToolCall)\n",
    "\n",
    "    for attempt in range(max_retries):\n",
    "        # This is an API call to the LLM service. For the universality of the course, the specific implementation is omitted.\n",
    "        # You can replace it with your own code, e.g., client.chat.completions.create(...)\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"qwen-plus\", messages=messages, temperature=0\n",
    "        )\n",
    "        raw_output = completion.choices[0].message.content\n",
    "\n",
    "        try:\n",
    "            # Parse and validate\n",
    "            # Remove markdown code block fences if present\n",
    "            clean_output = raw_output.strip().removeprefix('```json').removesuffix('```').strip()\n",
    "            data = json.loads(clean_output)\n",
    "            # Use Pydantic model to validate the parsed data\n",
    "            validated_data = adapter.validate_python(data)\n",
    "            return validated_data.model_dump()\n",
    "        except (json.JSONDecodeError, ValidationError) as e:\n",
    "            # If failed, add the error message and the original output to the conversation history,\n",
    "            # so the model can make corrections\n",
    "            messages.extend([\n",
    "                {'role': 'assistant', 'content': raw_output},\n",
    "                {'role': 'user', 'content': f\"Format error: {e}. Please strictly re-output in JSON format.\"}\n",
    "            ])\n",
    "\n",
    "    return None\n",
    "\n",
    "# Usage\n",
    "# Assume client variable is already initialized elsewhere\n",
    "user_request = \"Help me find that classic Transformer paper titled 'Attention Is All You Need'\"\n",
    "result = get_structured_output(user_request)\n",
    "\n",
    "if result:\n",
    "    print(json.dumps(result, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ae2779",
   "metadata": {},
   "source": [
    "By establishing such a \"guide-validate-retry\" closed loop, you can improve parsing success rates and make your tool-calling code more robust and reliable.\n",
    "\n",
    "> **Further reading: Controlled decoding**\n",
    ">\n",
    "> Many model providers' \"JSON Mode\" does not rely solely on \"optimized training\" but uses a more precise technique: **controlled decoding**.\n",
    ">\n",
    "> When the model generates each token, it first calculates the probability distribution of all candidate tokens. At this point, the system, based on the grammar rules compiled from your provided Schema, prunes all options from these candidate tokens that cannot form a legal JSON.\n",
    ">\n",
    "> This is like a grammar checker, but instead of checking after the fact, it \"hides\" all options that would lead to grammar errors from the keyboard every time you choose the next character.\n",
    ">\n",
    "> This technique transforms \"output format\" from a vague task that the model needs to \"learn\" into a deterministic process driven by grammar rules, fundamentally ensuring the reliability of the output.\n",
    "\n",
    "### 1.4 Mainstream solution: Function calling\n",
    "#### 1.4.1 How function calling works\n",
    "The \"intent recognition -> structured output -> validation and retry\" flow you just manually implemented is a robust tool-calling process, but its full implementation is quite complex. To simplify development, many LLM service providers (such as Alibaba Cloud, OpenAI, Anthropic, Google, etc.) have built this capability into their APIs, which is known as **function calling** or **tool calling**.\n",
    "\n",
    "Taking OpenAI SDK's function calling as an example:\n",
    "\n",
    "*   **Tool definition**: You need to define the available tools in the `tools` parameter of the API, using JSON Schema to describe each tool's `name`, `description`, and `parameters` (the structure of input parameters required by the function).\n",
    "\n",
    "*   Call decision: The model automatically decides whether to call a tool based on user input and tool definitions. If a tool call is needed, the model returns a `tool_calls` field in its response, containing the name of the function to be called and the JSON parameters conforming to the Schema.\n",
    "\n",
    "*   Execute & return: You need to:\n",
    "    1. Parse the function name and parameters from `tool_calls`.\n",
    "    2. Actually execute the corresponding function in your code.\n",
    "    3. Wrap the function execution result into a message with `role: \"tool\"`.\n",
    "    4. Call the API again, sending the tool execution result back to the model.\n",
    "    5. The model generates the final user response based on the tool's return.\n",
    "\n",
    "<img src=\"https://img.alicdn.com/imgextra/i2/O1CN01LQjXNd1NGkEiph7LF_!!6000000001543-55-tps-1696-1769.svg\" width=\"700\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f4182ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T06:05:37.769020Z",
     "iopub.status.busy": "2025-11-20T06:05:37.768872Z",
     "iopub.status.idle": "2025-11-20T06:05:46.120981Z",
     "shell.execute_reply": "2025-11-20T06:05:46.120332Z",
     "shell.execute_reply.started": "2025-11-20T06:05:37.769003Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model decided to call tool: `search_arxiv_paper`\n",
      "Arguments: {'query': 'Attention Is All You Need'}\n",
      "Tool execution result: {\"paper_id\": \"1706.03762\", \"url\": \"https://arxiv.org/abs/1706.03762\", \"title\": \"Attention Is All You Need\"}\n",
      "\n",
      "Model's final response:\n",
      "Here is the classic Transformer paper you're looking for:\n",
      "\n",
      "**Title:** [Attention Is All You Need](https://arxiv.org/abs/1706.03762)  \n",
      "**Authors:** Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Åukasz Kaiser, Illia Polosukhin  \n",
      "**Published:** June 2017  \n",
      "**arXiv ID:** [1706.03762](https://arxiv.org/abs/1706.03762)\n",
      "\n",
      "This groundbreaking paper introduced the **Transformer architecture**, which relies entirely on **self-attention mechanisms** and has become the foundation for most modern large language models (like BERT, GPT, T5, etc.).\n",
      "\n",
      "ğŸ‘‰ [Read the paper on arXiv](https://arxiv.org/abs/1706.03762)\n",
      "\n",
      "Let me know if you'd like a summary or explanation of the key concepts!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "# 1. Define the list of tools, including the JSON Schema description for each function\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"search_arxiv_paper\",\n",
    "            \"description\": \"Search for academic papers on Arxiv.org\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"query\": {\"type\": \"string\", \"description\": \"Title or keywords of the paper\"},\n",
    "                },\n",
    "                \"required\": [\"query\"],\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "]\n",
    "# 2. Make the first API call to let the model decide\n",
    "messages = [{\"role\": \"user\", \"content\": \"Help me find that classic Transformer paper 'Attention Is All You Need'\"}]\n",
    "response = client.chat.completions.create(\n",
    "    model=\"qwen-plus\", messages=messages, tools=tools, tool_choice=\"auto\"\n",
    ")\n",
    "response_message = response.choices[0].message\n",
    "# 3. Check if the model decided to call a tool and execute\n",
    "if response_message.tool_calls:\n",
    "    tool_call = response_message.tool_calls[0]\n",
    "    function_name = tool_call.function.name\n",
    "    function_args = json.loads(tool_call.function.arguments)\n",
    "    print(f\"Model decided to call tool: `{function_name}`\")\n",
    "    print(f\"Arguments: {function_args}\")\n",
    "\n",
    "    # Here we simulate the function execution result\n",
    "    tool_result = json.dumps({\"paper_id\": \"1706.03762\", \"url\": \"https://arxiv.org/abs/1706.03762\", \"title\": \"Attention Is All You Need\"})\n",
    "    print(f\"Tool execution result: {tool_result}\")\n",
    "    # 4. Pass the model's decision and the tool's execution result back to the model to generate the final response\n",
    "    messages.append(response_message)\n",
    "    messages.append(\n",
    "        {\"tool_call_id\": tool_call.id, \"role\": \"tool\", \"name\": function_name, \"content\": tool_result}\n",
    "    )\n",
    "\n",
    "    final_response = client.chat.completions.create(model=\"qwen-plus\", messages=messages)\n",
    "    print(\"\\nModel's final response:\")\n",
    "    print(final_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46496fe1",
   "metadata": {},
   "source": [
    "#### 1.4.2 ReAct pattern: Think-act-observe\n",
    "\n",
    "You will find that the results of tool calls are passed to the LLM through another call. The LLM will observe the results of the tool call, then think about whether the task is complete, and then reply with the final answer or continue to act (call another tool). This is very similar to the \"multi-turn conversation\" you learned earlier.\n",
    "\n",
    "We call this **think-act-observe** loop pattern **ReAct**, and Agents that work according to this pattern are called **ReAct Agents**.\n",
    "\n",
    "Manually implementing ReAct Agent logic is complex. To simplify the development process, we will use <a href=\"https://github.com/agentscope-ai/agentscope\">AgentScope</a>, a production-grade Agent framework that has already encapsulated the complete logic of ReAct Agent and tool calling for you.\n",
    "\n",
    "> AgentScope is a production-grade Agent framework designed for developers. It defines Agent communication, memory, and tool calling in a standardized way, allowing you to focus on business logic rather than underlying implementations. Key advantages of AgentScope include:\n",
    "> \n",
    "> - **Out-of-the-box ReAct Agent**ï¼šBuilt-in complete \"think-act-observe\" loop logic.\n",
    "> - **Flexible tool management**: Uniformly manages tool functions through the `Toolkit` class, supporting automatic parsing of tool JSON Schema.\n",
    "> - **Multi-model support**: Compatible with mainstream LLM APIs such as OpenAI, DashScope, Anthropic.\n",
    "> - **State management**: Automatically handles conversation history, tool call records, and other states.\n",
    "> - **Asynchronous support**: All core functions support asynchronous calls to improve performance.\n",
    "\n",
    "Let's look at how AgentScope implements the tool call we just discussed:\n",
    "\n",
    "<img src=\"https://img.alicdn.com/imgextra/i1/O1CN01quzCo31zMekRGxENy_!!6000000006700-55-tps-1640-1098.svg\" width=\"700\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81fe2bae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T06:05:46.121658Z",
     "iopub.status.busy": "2025-11-20T06:05:46.121504Z",
     "iopub.status.idle": "2025-11-20T06:05:48.823501Z",
     "shell.execute_reply": "2025-11-20T06:05:48.822837Z",
     "shell.execute_reply.started": "2025-11-20T06:05:46.121643Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User request: Help me find that classic Transformer paper 'Attention Is All You Need'\n",
      "\n",
      "Course Research Agent: {\n",
      "    \"type\": \"tool_use\",\n",
      "    \"id\": \"call_bc5e158501b247588a7ce3\",\n",
      "    \"name\": \"search_arxiv_paper\",\n",
      "    \"input\": {\n",
      "        \"query\": \"Attention Is All You Need\"\n",
      "    }\n",
      "}\n",
      "--- [Tool executing] Searching Arxiv for: Attention Is All You Need ---\n",
      "system: {\n",
      "    \"type\": \"tool_result\",\n",
      "    \"id\": \"call_bc5e158501b247588a7ce3\",\n",
      "    \"name\": \"search_arxiv_paper\",\n",
      "    \"output\": [\n",
      "        {\n",
      "            \"type\": \"text\",\n",
      "            \"text\": \"Successfully found paper 'Attention Is All You Need'. You can access it here: https://arxiv.org/abs/1706.03762\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "Course Research Agent: I found the classic Transformer paper titled 'Attention Is All You Need'! You can access and download it from: https://arxiv.org/abs/1706.03762\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from agentscope.agent import ReActAgent\n",
    "from agentscope.tool import Toolkit, ToolResponse\n",
    "from agentscope.model import DashScopeChatModel\n",
    "from agentscope.message import Msg, TextBlock\n",
    "from agentscope.formatter import DashScopeChatFormatter\n",
    "\n",
    "\n",
    "# 1. Define a tool that returns results using ToolResponse\n",
    "def search_arxiv_paper(query: str) -> ToolResponse:\n",
    "    \"\"\"Searches for academic papers on Arxiv.org.\n",
    "\n",
    "    Args:\n",
    "        query (str): Search keyword\n",
    "    \"\"\"\n",
    "    print(f\"--- [Tool executing] Searching Arxiv for: {query} ---\")\n",
    "    # Simulate search results here\n",
    "    paper_url = \"https://arxiv.org/abs/1706.03762\"\n",
    "    return ToolResponse(\n",
    "        content=[\n",
    "            TextBlock(\n",
    "                type=\"text\",\n",
    "                text=f\"Successfully found paper '{query}'. You can access it here: {paper_url}\",\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "\n",
    "async def run_agentscope_example():\n",
    "    # 2. Register the tool function to the toolkit\n",
    "    toolkit = Toolkit()\n",
    "    toolkit.register_tool_function(search_arxiv_paper)\n",
    "\n",
    "    # 3. Create a ReActAgent and equip it with the toolkit\n",
    "    agent = ReActAgent(\n",
    "        name=\"Course Research Agent\",\n",
    "        sys_prompt=\"You are a course research assistant, skilled at collecting and organizing learning materials.\",\n",
    "        model=DashScopeChatModel(\n",
    "            model_name=\"qwen-plus\",\n",
    "            api_key=\"sk-HEStHMdURe\",\n",
    "            # base_http_api_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
    "        ),\n",
    "        toolkit=toolkit,\n",
    "        formatter=DashScopeChatFormatter()\n",
    "    )\n",
    "\n",
    "    # 4. Send a message to the Agent, it will automatically complete all steps\n",
    "    user_request = \"Help me find that classic Transformer paper 'Attention Is All You Need'\"\n",
    "    msg = Msg(name=\"user\", content=user_request, role=\"user\")\n",
    "\n",
    "    print(f\"User request: {user_request}\\n\")\n",
    "    await agent(msg)\n",
    "\n",
    "# Run the example\n",
    "try:\n",
    "    # In a Jupyter Notebook environment, you can directly await the coroutine\n",
    "    await run_agentscope_example()\n",
    "except NameError:\n",
    "    # In a regular Python script, you need to use asyncio.run() to run asynchronous functions\n",
    "    asyncio.run(run_agentscope_example())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d5517f",
   "metadata": {},
   "source": [
    "Compared to the manually implemented OpenAI Function Calling, AgentScope's advantages are:\n",
    "1. **More concise tool definition**: You only need to write regular Python functions with docstrings; the framework automatically parses and generates the JSON Schema.\n",
    "2. **No manual parsing required**: `ReActAgent` automatically handles the tedious steps of parsing `tool_calls`, executing functions, and wrapping results internally.\n",
    "3. **Automatic conversation history management**: The framework automatically records user messages, tool calls, tool results, etc., without requiring manual maintenance.\n",
    "4. **Supports multi-turn tool calls**: If one tool call is insufficient, the Agent will automatically continue to think and call more tools until the task is completed.\n",
    "\n",
    "Seeing AgentScope's concise implementation, you might wonder: since there's an existing framework, why bother learning the cumbersome manual implementation?\n",
    "This is because:\n",
    "\n",
    "1. **Understand underlying principles**: The framework internally performs the \"call model -> parse tool_calls -> execute function -> call model again\" process. Understanding the mechanism is essential for debugging issues.\n",
    "2. **Custom requirements**: Production environments often require special logic such as permission validation, caching, retries, and logging monitoring. Understanding the underlying principles allows for framework extension.\n",
    "3. **Compatibility assurance**: When some models or platforms do not support standard Function Calling formats, manual implementation can serve as a fallback solution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1ca6b3",
   "metadata": {},
   "source": [
    "### 1.5 Scalable management: Model context protocol (MCP)\n",
    "#### 1.5.1 Challenges of tool reuse\n",
    "The Function Calling pattern solves the problem of how a single application calls tools. However, when tools need to be reused across multiple Agent applications, it introduces challenges for scalable maintenance.\n",
    "Imagine your team has multiple Agents, all needing to call internet search, internal company document search, and other tools. If a parameter in a tool's API changes, you need to modify every Agent that depends on it, leading to high maintenance costs. The root cause of the problem is that **tool definitions are hardcoded into the code of each \"consumer\" (Agent application)**.\n",
    "\n",
    "#### 1.5.2 Decoupling concept of MCP\n",
    "To solve this problem, Anthropic proposed the **Model Context Protocol (MCP)**. Its core idea is to shift the responsibility for defining tools from the \"consumer\" to the \"provider.\"\n",
    "\n",
    "* **Without MCP**: Each AI application needs to encapsulate all tool definitions itself. When a tool is updated, all applications need to be modified.\n",
    "* **With MCP**: The tool service provider (e.g., search service) \"broadcasts\" its capability definitions. AI applications only need to connect to the service provider via the MCP protocol to automatically obtain the latest tool definitions, without hardcoding.\n",
    "\n",
    "<img src=\"https://img.alicdn.com/imgextra/i4/O1CN01vRbQ0S1tPxumQyLll_!!6000000005895-55-tps-3161-1436.svg\" width=\"700\">\n",
    "\n",
    "#### 1.5.3 Practice: Connecting to remote MCP services\n",
    "\n",
    "AgentScope provides direct support for the MCP protocol. Here is a simple example:\n",
    "\n",
    "> **Before you start**\n",
    "> Before running this code, please go to [Alibaba Cloud Bailian official website](https://bailian.console.aliyun.com/?tab=mcp#/mcp-market/detail/WebSearch)to enable the web search MCP service and understand its billing details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3301aaea",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2025-11-24T08:19:56.771800Z",
     "iopub.status.busy": "2025-11-24T08:19:56.771577Z",
     "iopub.status.idle": "2025-11-24T08:20:38.224440Z",
     "shell.execute_reply": "2025-11-24T08:20:38.223893Z",
     "shell.execute_reply.started": "2025-11-24T08:19:56.771782Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-24 16:20:16,136 | INFO    | _toolkit:register_mcp_client:716 - Registered 1 tool functions from MCP: bailian_web_search.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User request: I am collecting materials for the 'Principles of LLMs' course. I need an example of calling external real-time data, for instance, please search for the latest developments regarding 'large language models'.\n",
      "\n",
      "Research Assistant Agent: {\n",
      "    \"type\": \"tool_use\",\n",
      "    \"id\": \"call_4693fc7f61544abc9dc880\",\n",
      "    \"name\": \"bailian_web_search\",\n",
      "    \"input\": {\n",
      "        \"query\": \"latest developments in large language models\",\n",
      "        \"count\": 5\n",
      "    }\n",
      "}\n",
      "system: {\n",
      "    \"type\": \"tool_result\",\n",
      "    \"id\": \"call_4693fc7f61544abc9dc880\",\n",
      "    \"name\": \"bailian_web_search\",\n",
      "    \"output\": [\n",
      "        {\n",
      "            \"type\": \"text\",\n",
      "            \"text\": \"{\\\"status\\\": 0, \\\"pages\\\": [{\\\"snippet\\\": \\\"å†…å®¹æ¦‚è¦ï¼šæœ¬æ–‡å…¨é¢è§£æäº†DeepSeekå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„èµ·æºä¸å‘å±•å†ç¨‹ï¼Œç‰¹åˆ«æ˜¯å®ƒå¦‚ä½•é€šè¿‡æŠ€æœ¯åˆ›æ–°é™ä½è®­ç»ƒæˆæœ¬å¹¶æé«˜æ€§èƒ½ã€‚DeepSeeké‡‡ç”¨å¤šå±‚æ³¨æ„åŠ›æ¶æ„ï¼ˆMLAï¼‰ã€ \\\", \\\"title\\\": \\\"LLMï¼ˆå¤§è¯­è¨€æ¨¡å‹ï¼‰æŠ€æœ¯çš„æœ€æ–°è¿›å±•å¯æ€»ç»“åŸåˆ›\\\", \\\"url\\\": \\\"https://blog.csdn.net/u014158430/article/details/147527236\\\", \\\"hostname\\\": \\\"CSDN - ä¸“ä¸šå¼€å‘è€…ç¤¾åŒº\\\", \\\"hostlogo\\\": \\\"https://img.alicdn.com/imgextra/i3/O1CN01QA3ndK1maJQ8rZTo1_!!6000000004970-55-tps-32-32.svg\\\"}, {\\\"snippet\\\": \\\"æ€»æ‹¬è€Œè¨€ï¼Œæœ¬æ¬¡è¯„ä¼°é€è¿‡äº‹å®æ€§åŒå¿ å®æ€§çš„åˆ†ç±»æ¡†æ¶ï¼Œæ·±å…¥é˜è¿°å¤§è¯­è¨€æ¨¡å‹å¹»è§‰æ§åˆ¶èƒ½åŠ›çš„æ ¸å¿ƒç†è®ºåŸºç¡€ä¸æ¨¡å‹è¡¨ç°ã€‚æœªæ¥ï¼Œ AIå¯ä¿¡åº¦éœ€å…¼é¡¾æ§åˆ¶äº‹å®æ€§å¹»è§‰ä¸å¿ å®æ€§ \\\", \\\"title\\\": \\\"æ¸¯å¤§ç»ç®¡å­¦é™¢æœ€æ–°å‘å¸ƒ: AIå¤§è¯­è¨€æ¨¡å‹å¹»è§‰æ§åˆ¶èƒ½åŠ›æ·±åº¦è¯„æµ‹ ...\\\", \\\"url\\\": \\\"https://www.hkubs.hku.hk/sc/media/school-news/a-new-in-depth-report-of-ai-large-language-models-hallucination-control/\\\", \\\"hostname\\\": null, \\\"hostlogo\\\": null}, {\\\"snippet\\\": \\\"è·ç¦»Gemini 2.5å‘å¸ƒä»…ä¸ƒä¸ªæœˆ,è¿™ä¸€æ–°æ¨¡å‹æ˜¯è°·æ­Œè¿„ä»Šä¸ºæ­¢æœ€å¼ºå¤§çš„å¤§è¯­è¨€æ¨¡å‹,ä¹Ÿæ˜¯å¸‚åœºä¸Šæœ€å…·ç«äº‰åŠ›çš„AIå·¥å…·ä¹‹ä¸€ã€‚ è¯¥æ¨¡å‹çš„æ›´åŠ ä¸“æ³¨äºç ”ç©¶çš„ç‰ˆæœ¬,åä¸ºGemini 3 Deepthink,å°†åœ¨æœªæ¥å‡ å‘¨å†…å‘Google AI Ultraè®¢é˜…ç”¨æˆ·æä¾›,å¾…é€šè¿‡è¿›ä¸€æ­¥çš„å®‰å…¨æµ‹è¯•åå³å¯ä½¿ç”¨ã€‚\\\\\\\"å®ƒä»¥å‰æ‰€æœªæœ‰çš„æ·±åº¦å’Œç»†è‡´åº¦è¿›è¡Œå›åº”ã€‚\\\\\\\"è¯¥æ¨¡å‹åœ¨\\\\\\\"äººç±»æœ€åè€ƒè¯•\\\\\\\"åŸºå‡†æµ‹è¯•ä¸­è·å¾—37.4åˆ†,åˆ›ä¸‹äº†è¯¥é¡¹æ—¨åœ¨è¡¡é‡é€šç”¨æ¨ç†å’Œä¸“ä¸šçŸ¥è¯†æµ‹è¯•çš„å†å²æœ€é«˜çºªå½•ã€‚æ­¤å‰çš„æœ€é«˜åˆ†31.64åˆ†ç”±GPT-5 Proä¿æŒã€‚Gemini 3è¿˜åœ¨LMArenaè¿™ä¸€è¡¡é‡ç”¨æˆ·æ»¡æ„åº¦çš„äººå·¥è¯„åˆ¤åŸºå‡†æµ‹è¯•ä¸­ä½å±…æ¦œé¦–ã€‚ é™¤åŸºç¡€æ¨¡å‹å¤–,è°·æ­Œè¿˜å‘å¸ƒäº†ä¸€æ¬¾åŸºäºGeminiçš„ç¼–ç¨‹ç•Œé¢Google Antigravity,æä¾›å¤šçª—æ ¼æ™ºèƒ½ä½“ç¼–ç¨‹åŠŸèƒ½,ç±»ä¼¼äºWarpæˆ–Cursor 2.0ç­‰æ™ºèƒ½ä½“é›†æˆå¼€å‘ç¯å¢ƒã€‚ \\\\\\\"è¯¥æ™ºèƒ½ä½“å¯ä»¥ä¸æ‚¨çš„ç¼–è¾‘å™¨ã€ç»ˆç«¯å’Œæµè§ˆå™¨ååŒå·¥ä½œ,ç¡®ä¿ä»¥æœ€ä½³æ–¹å¼å¸®åŠ©æ‚¨æ„å»ºåº”ç”¨ç¨‹åº,\\\\\\\"DeepMindé¦–å¸­æŠ€æœ¯å®˜Koray Kavukcuogluè¡¨ç¤ºã€‚åœ¨\\\\\\\"äººç±»æœ€åè€ƒè¯•\\\\\\\"åŸºå‡†æµ‹è¯•ä¸­è·å¾—37.4åˆ†çš„å†å²æœ€é«˜çºªå½•,è¶…è¶Šäº†GPT-5 Proæ­¤å‰ä¿æŒçš„31.64åˆ†çºªå½•,å¹¶åœ¨LMArenaç”¨æˆ·æ»¡æ„åº¦æµ‹è¯•ä¸­ä½å±…æ¦œé¦–ã€‚å®ƒç»“åˆäº†ChatGPTé£æ ¼çš„æç¤ºçª—å£ã€å‘½ä»¤è¡Œç•Œé¢å’Œæµè§ˆå™¨çª—å£,æ™ºèƒ½ä½“å¯ä»¥ä¸ç¼–è¾‘å™¨ã€ç»ˆç«¯å’Œæµè§ˆå™¨ååŒå·¥ä½œ,å®æ—¶æ˜¾ç¤ºä»£ç æ›´æ”¹çš„å½±å“,å¸®åŠ©å¼€å‘è€…ä»¥æœ€ä½³æ–¹å¼æ„å»ºåº”ç”¨ç¨‹åºã€‚ A:Gemini 3ç°å·²é€šè¿‡Geminiåº”ç”¨ç¨‹åºå’ŒAIæœç´¢ç•Œé¢ç«‹å³æä¾›æœåŠ¡ã€‚æ®è°·æ­Œæ•°æ®,è¯¥åº”ç”¨ç¨‹åºç›®å‰æ‹¥æœ‰è¶…è¿‡6.5äº¿æœˆæ´»è·ƒç”¨æˆ·ã€‚æ›´é«˜çº§çš„Gemini 3 Deepthinkç‰ˆæœ¬å°†åœ¨æœªæ¥å‡ å‘¨å†…å‘Google AI Ultraè®¢é˜…ç”¨æˆ·æä¾›ã€‚\\\", \\\"title\\\": \\\"è°·æ­Œå‘å¸ƒGemini 3,æ–°å¢ç¼–ç åº”ç”¨å¹¶åˆ›åŸºå‡†æµ‹è¯•çºªå½•\\\", \\\"url\\\": \\\"https://baijiahao.baidu.com/s?id=1849210576538907232&wfr=spider&for=pc\\\", \\\"hostname\\\": \\\"ç™¾å®¶å·\\\", \\\"hostlogo\\\": \\\"https://baijiahao.baidu.com/favicon.ico\\\"}, {\\\"snippet\\\": \\\"ç©å…·å·²å‘å±•æˆä¸ºAIæŠ€æœ¯é›†æˆåº”ç”¨ã€èåˆåˆ›æ–°çš„é‡è¦è½½ä½“,è¯­è¨€å¤§æ¨¡å‹ã€è§†è§‰å¤§æ¨¡å‹ç­‰è®©ç©å…·äº§å“èƒ½â€œå¬å¾—æ‡‚â€â€œçœ‹å¾—åˆ°â€â€œèƒ½æ€è€ƒâ€,å®ƒä¼šåŠ¨è„‘ç­‹ã€ä¼šåŒä½ äº¤æµäº’åŠ¨ã€‚\\\", \\\"title\\\": \\\"AIç©å…·æˆäº§ä¸šæ–°å¼•æ“ å¸‚åœºè§„æ¨¡é¢„è®¡æ˜å¹´è¾¾290äº¿å…ƒ\\\", \\\"url\\\": \\\"https://baijiahao.baidu.com/s?id=1849215152091097520&wfr=spider&for=pc\\\", \\\"hostname\\\": \\\"ç™¾å®¶å·\\\", \\\"hostlogo\\\": \\\"https://baijiahao.baidu.com/favicon.ico\\\"}, {\\\"snippet\\\": \\\"ç›®å‰å…¬å¸æ­£åœ¨æ¨è¿›GPT-6å¤§è¯­è¨€æ¨¡å‹å’ŒSora 3è§†é¢‘ç”Ÿæˆæ¨¡å‹çš„ç ”å‘å·¥ä½œ,æ›´å…³é”®çš„æ˜¯,2027è‡³2028å¹´æœ‰æœ›è½åœ°â€œé€’å½’è‡ªæ”¹è¿›â€æŠ€æœ¯â€”â€”è¿™ä¸€æŠ€æœ¯èƒ½è®©AIæ¨¡å‹è‡ªä¸»ä¼˜åŒ–å‡çº§,å°†æ˜¾è‘—æå‡æ¨¡å‹çš„æ€§èƒ½å’Œæ•ˆç‡,ä½†åŒæ—¶ä¹Ÿéœ€è¦æµ·é‡çš„ç®—åŠ›èµ„æºä½œä¸ºæ”¯æ’‘ã€‚\\\", \\\"title\\\": \\\"å·´å…‹è±æœ€æ–°ç ”ç©¶æŠ¥å‘Š:OpenAIç®—åŠ›éœ€æ±‚æŒç»­æ¿€å¢\\\", \\\"url\\\": \\\"https://baijiahao.baidu.com/s?id=1849327924941759075&wfr=spider&for=pc\\\", \\\"hostname\\\": \\\"ç™¾å®¶å·\\\", \\\"hostlogo\\\": \\\"https://baijiahao.baidu.com/favicon.ico\\\"}], \\\"tools\\\": [], \\\"request_id\\\": \\\"4485ef0d-d140-4a91-8f38-6fb730106617\\\"}\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "Research Assistant Agent: ä»¥ä¸‹æ˜¯å…³äºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æœ€æ–°å‘å±•çš„ææ–™æ‘˜è¦ï¼Œé€‚ç”¨äºã€Šå¤§è¯­è¨€æ¨¡å‹åŸç†ã€‹è¯¾ç¨‹æ•™å­¦å†…å®¹ï¼š\n",
      "\n",
      "1. **DeepSeek æ¨¡å‹çš„æŠ€æœ¯åˆ›æ–°**ï¼š\n",
      "   - DeepSeek é‡‡ç”¨å¤šå±‚æ³¨æ„åŠ›æ¶æ„ï¼ˆMLAï¼‰ï¼Œåœ¨é™ä½è®­ç»ƒæˆæœ¬çš„åŒæ—¶æå‡äº†æ¨¡å‹æ€§èƒ½ã€‚è¯¥æ¨¡å‹å±•ç¤ºäº†å¦‚ä½•é€šè¿‡ç»“æ„ä¼˜åŒ–å®ç°é«˜æ•ˆè®­ç»ƒä¸æ¨ç†ï¼Œæ˜¯å½“å‰ LLM æŠ€æœ¯æ¼”è¿›çš„é‡è¦æ–¹å‘ä¹‹ä¸€ã€‚\n",
      "   - æ¥æºï¼š[CSDN åšå®¢](https://blog.csdn.net/u014158430/article/details/147527236)\n",
      "\n",
      "2. **å¹»è§‰æ§åˆ¶èƒ½åŠ›è¯„æµ‹ï¼ˆæ¸¯å¤§ç»ç®¡å­¦é™¢ï¼‰**ï¼š\n",
      "   - é¦™æ¸¯å¤§å­¦å•†å­¦é™¢è¿‘æœŸå‘å¸ƒæŠ¥å‘Šï¼Œæå‡ºåŸºäºâ€œäº‹å®æ€§â€ä¸â€œå¿ å®æ€§â€çš„åˆ†ç±»æ¡†æ¶ï¼Œç”¨äºè¯„ä¼°å¤§è¯­è¨€æ¨¡å‹çš„å¹»è§‰æ§åˆ¶èƒ½åŠ›ã€‚è¿™ä¸ºè¡¡é‡ AI å¯ä¿¡åº¦æä¾›äº†ç†è®ºåŸºç¡€å’Œå®è¯æ–¹æ³•ï¼Œå¼ºè°ƒæœªæ¥æ¨¡å‹éœ€åŒæ—¶ä¼˜åŒ–ç”Ÿæˆå†…å®¹çš„çœŸå®æ€§å’Œä¸€è‡´æ€§ã€‚\n",
      "   - æ¥æºï¼š[æ¸¯å¤§ç»ç®¡å­¦é™¢å®˜ç½‘](https://www.hkubs.hku.hk/sc/media/school-news/a-new-in-depth-report-of-ai-large-language-models-hallucination-control/)\n",
      "\n",
      "3. **è°·æ­Œå‘å¸ƒ Gemini 3 æ¨¡å‹**ï¼š\n",
      "   - Gemini 3 æ˜¯è°·æ­Œè¿„ä»Šä¸ºæ­¢æœ€å¼ºå¤§çš„å¤§è¯­è¨€æ¨¡å‹ï¼Œåœ¨â€œäººç±»æœ€åè€ƒè¯•â€åŸºå‡†æµ‹è¯•ä¸­å–å¾— 37.4 åˆ†çš„å†å²æœ€é«˜çºªå½•ï¼Œè¶…è¶Š GPT-5 Pro çš„ 31.64 åˆ†ã€‚åŒæ—¶åœ¨ LMArena ç”¨æˆ·æ»¡æ„åº¦è¯„æµ‹ä¸­æ’åç¬¬ä¸€ã€‚\n",
      "   - æ¨å‡ºç¼–ç¨‹æ™ºèƒ½ä½“ç•Œé¢ Google Antigravityï¼Œæ”¯æŒå¤šçª—æ ¼åä½œï¼Œé›†æˆç¼–è¾‘å™¨ã€ç»ˆç«¯ä¸æµè§ˆå™¨ï¼Œæå‡å¼€å‘è€…æ•ˆç‡ã€‚\n",
      "   - æ›´é«˜çº§ç‰ˆæœ¬ Gemini 3 Deepthink å°†é¢å‘ Google AI Ultra è®¢é˜…ç”¨æˆ·å¼€æ”¾ã€‚\n",
      "   - æ¥æºï¼š[ç™¾åº¦ç™¾å®¶å·](https://baijiahao.baidu.com/s?id=1849210576538907232)\n",
      "\n",
      "4. **AI ç©å…·ä¸­çš„ LLM åº”ç”¨**ï¼š\n",
      "   - å¤§è¯­è¨€æ¨¡å‹ä¸è§†è§‰æ¨¡å‹æ­£è¢«å¹¿æ³›åº”ç”¨äº AI ç©å…·ä¸­ï¼Œä½¿å…¶å…·å¤‡â€œå¬æ‡‚ã€çœ‹è§ã€æ€è€ƒâ€çš„èƒ½åŠ›ï¼Œå®ç°è‡ªç„¶äº¤äº’ã€‚é¢„è®¡åˆ° 2025 å¹´ï¼Œä¸­å›½ AI ç©å…·å¸‚åœºè§„æ¨¡å°†è¾¾åˆ° 290 äº¿å…ƒï¼Œæˆä¸º AI æŠ€æœ¯èåˆåˆ›æ–°çš„é‡è¦åœºæ™¯ã€‚\n",
      "   - æ¥æºï¼š[ç™¾åº¦ç™¾å®¶å·](https://baijiahao.baidu.com/s?id=1849215152091097520)\n",
      "\n",
      "5. **OpenAI çš„ GPT-6 ä¸é€’å½’è‡ªæ”¹è¿›æŠ€æœ¯å±•æœ›**ï¼š\\   - å·´å…‹è±ç ”ç©¶æŠ¥å‘ŠæŒ‡å‡ºï¼ŒOpenAI æ­£åœ¨ç ”å‘ GPT-6 å’Œ Sora 3 è§†é¢‘ç”Ÿæˆæ¨¡å‹ï¼Œå¹¶è®¡åˆ’äº 2027â€“2028 å¹´å®ç°â€œé€’å½’è‡ªæ”¹è¿›â€æŠ€æœ¯â€”â€”å³ AI èƒ½å¤Ÿè‡ªä¸»ä¼˜åŒ–è‡ªèº«æ¶æ„ä¸å‚æ•°ï¼Œæ˜¾è‘—æå‡æ•ˆç‡ï¼Œä½†å¯¹ç®—åŠ›éœ€æ±‚ä¹Ÿå°†å‘ˆæŒ‡æ•°çº§å¢é•¿ã€‚\n",
      "   - æ¥æºï¼š[ç™¾åº¦ç™¾å®¶å·](https://baijiahao.baidu.com/s?id=1849327924941759075)\\\n",
      "è¿™äº›èµ„æ–™æ¶µç›–äº†æŠ€æœ¯è¿›å±•ã€åº”ç”¨åœºæ™¯ã€å¯ä¿¡åº¦è¯„ä¼°åŠæœªæ¥è¶‹åŠ¿ï¼Œé€‚åˆä½œä¸ºè¯¾ç¨‹æ¡ˆä¾‹å¸®åŠ©å­¦ç”Ÿç†è§£ LLM çš„å®æ—¶å‘å±•åŠ¨æ€ä¸äº§ä¸šå½±å“ã€‚\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import os\n",
    "from agentscope.agent import ReActAgent\n",
    "from agentscope.mcp import HttpStatelessClient\n",
    "from agentscope.tool import Toolkit\n",
    "from agentscope.model import DashScopeChatModel\n",
    "from agentscope.message import Msg\n",
    "from agentscope.formatter import DashScopeChatFormatter\n",
    "\n",
    "async def run_mcp_example():\n",
    "    # 1. Configure the MCP client, pointing to the remote tool service\n",
    "    #    This connects to Alibaba Cloud DashScope's public web search MCP service\n",
    "    web_search_client = HttpStatelessClient(\n",
    "        name=\"web_search_service\", # Give this client a name\n",
    "        transport=\"sse\",\n",
    "        url=\"https://dashscope.aliyuncs.com/api/v1/mcps/WebSearch/sse\",\n",
    "        headers={\"Authorization\": \"Bearer \" + os.environ.get(\"DASHSCOPE_API_KEY\")},\n",
    "    )\n",
    "    # 2. Register the MCP client to the toolkit\n",
    "    #    The Agent will automatically \"discover\" all tools provided by the remote service via the client at startup\n",
    "    toolkit = Toolkit()\n",
    "    await toolkit.register_mcp_client(web_search_client)\n",
    "    # 3. Create an Agent and equip it with a toolkit containing MCP tools\n",
    "    agent = ReActAgent(\n",
    "        name=\"Research Assistant Agent\",\n",
    "        sys_prompt=\"You are a course research assistant, skilled at using tools to collect and organize the latest teaching materials.\",\n",
    "        model=DashScopeChatModel(\n",
    "            model_name=\"qwen-plus\", api_key=os.environ.get(\"DASHSCOPE_API_KEY\")\n",
    "        ),\n",
    "        toolkit=toolkit,\n",
    "        formatter=DashScopeChatFormatter()\n",
    "    )\n",
    "\n",
    "    # 4. Ask a question that requires a remote tool to answer\n",
    "    user_request = \"I am collecting materials for the 'Principles of LLMs' course. I need an example of calling external real-time data, for instance, please search for the latest developments regarding 'large language models'.\"\n",
    "    msg = Msg(name=\"user\", content=user_request, role=\"user\")\n",
    "\n",
    "    print(f\"User request: {user_request}\\n\")\n",
    "    response_msg = await agent(msg)\n",
    "\n",
    "# Run the example\n",
    "try:\n",
    "    # In a Jupyter Notebook environment, you can directly await the coroutine\n",
    "    await run_mcp_example()\n",
    "except NameError:\n",
    "    # In a regular Python script, you need to use asyncio.run() to run asynchronous functions\n",
    "    asyncio.run(run_mcp_example())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e28236",
   "metadata": {},
   "source": [
    "In this example, the Agent code does not need to define the `WebSearch` tool. Instead, it dynamically discovers the tool and its usage from the `web_search_service` via the MCP protocol at runtime, achieving complete decoupling.\n",
    "\n",
    "MCP aims to solve the scalability problem of \"how tools are discovered and managed\" by decoupling tool definition from tool usage.\n",
    "\n",
    "> **Related thinking: USB protocol**\n",
    ">\n",
    "> You can compare MCP to the USB protocol in the real world. Before USB, each peripheral (mouse, keyboard, printer) had its own unique interface, and computers needed to adapt to each one. The USB protocol unified all of this, allowing any compliant device to be plug-and-play.\n",
    "> *   **Function Calling** is like an **internal bus** on a computer motherboard, defining how the CPU communicates with a specific component.\n",
    "> *   **MCP** is like an **external USB interface**, defining an open standard that allows countless third-party devices to easily integrate into the ecosystem.\n",
    "\n",
    "At this point, you have mastered the complete chain from single tool functions, reliable intent recognition, to scalable tool management. Your Agent can now stably and efficiently interact with the outside world.\n",
    "\n",
    "### 1.6 Summary\n",
    "\n",
    "Let's review what you've learned in this section:\n",
    "* **Connecting models to the outside world**: You learned how to write tool functions for Agents to retrieve external information, and how to upgrade from fragile `if/else` rule judgments to leveraging the LLM's own understanding to decide which tool to call.\n",
    "* **Manually implementing reliable tool calls**: You mastered how to build a \"guide-validate-retry\" closed loop to make the model stably output structured JSON instructions, and understood that this is the underlying logic for robust tool calls.\n",
    "* **Function calling and tool discovery**: You learned about \"function calling,\" an industry standard that encapsulates the complex process of tool calling into simple APIs. Furthermore, you also learned how the MCP protocol decouples tool definition from usage, solving the challenges of scalable reuse and maintenance.\n",
    "* **ReAct loop and development frameworks**: You recognized that tool calling is key to implementing the **ReAct (think-act-observe)** loop pattern and learned how to use development frameworks like AgentScope to free you from tedious manual implementations, allowing you to focus more on business logic.\n",
    "\n",
    "## 2 Teaching the agent to reflect\n",
    "### 2.1 Course unexpectedly modified\n",
    "A colleague wrote an interactive course in Jupyter Notebook format, which included some executable Python code. To make the course language more engaging, you asked the bot to polish the language style of the entire document.\n",
    "\n",
    "After polishing, the course language became smoother and the structure clearer. However, when he tried to run the code examples in the course, he discovered a critical issue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "598dfe20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T08:19:43.276837Z",
     "iopub.status.busy": "2025-11-24T08:19:43.276616Z",
     "iopub.status.idle": "2025-11-24T08:19:43.279998Z",
     "shell.execute_reply": "2025-11-24T08:19:43.279326Z",
     "shell.execute_reply.started": "2025-11-24T08:19:43.276820Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for u-123\n"
     ]
    }
   ],
   "source": [
    "# Original code of the course\n",
    "def get_user_data(usr_id: str):\n",
    "  # ... some logic ...\n",
    "  return f\"Data for {usr_id}\"\n",
    "\n",
    "# Executes normally\n",
    "print(get_user_data(usr_id=\"u-123\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fd289a",
   "metadata": {},
   "source": [
    "When \"optimizing\" the language style, the bot quietly \"corrected\" the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d2398ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T08:19:47.558227Z",
     "iopub.status.busy": "2025-11-24T08:19:47.557991Z",
     "iopub.status.idle": "2025-11-24T08:19:47.560778Z",
     "shell.execute_reply": "2025-11-24T08:19:47.560235Z",
     "shell.execute_reply.started": "2025-11-24T08:19:47.558198Z"
    },
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Agent's polished code\n",
    "def get_user_data(user_id: str):\n",
    "  # ... some logic ...\n",
    "  return f\"Data for {user_id}\"\n",
    "\n",
    "# Runtime error!\n",
    "# print(get_user_data(usr_id=\"u-123\"))  # TypeError: get_user_data() got an unexpected keyword argument 'usr_id'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2562a19e",
   "metadata": {},
   "source": [
    "The bot thought `user_id` was more standard than `usr_id`, so it \"optimized\" the function definition, but this caused an error when calling the function, because the parameter name at the call site was not changed along with it.\n",
    "\n",
    "### 2.2 LLM hallucinations\n",
    "\n",
    "How should you solve this problem? The most direct idea is to tell the bot to \"be careful.\" Try adding a warning to its instructions (System Prompt):\n",
    "\n",
    "```\n",
    "You are a top course writer, responsible for polishing Jupyter Notebook formatted courses.\n",
    "Please optimize the text to make it more engaging.\n",
    "**Important: Absolutely do not modify any content within code blocks, including variable names, parameter names, and function calls.**\n",
    "```\n",
    "But this doesn't work well, because you can't list prohibitions to cover all possible scenarios. Even if you explicitly forbid certain modifications, the LLM still has a certain probability of \"accidentally\" changing correct content into errors.\n",
    "\n",
    "The reason is that due to LLM hallucinations, each generation it produces may introduce new errors, and it lacks an internal mechanism for verification and correction. This \"optimization\" is not limited to variable names, but can also occur in:\n",
    "\n",
    "- Command-line arguments (changing `-p 8080` to `--port 8080`)\n",
    "- API version numbers (updating `v1/users` to `v2/users`)\n",
    "- Example values (replacing demo IP address `192.168.1.10` with `127.0.0.1`)\n",
    "\n",
    "and any other places it deems \"not standardized enough.\" Ultimately, a course that has been \"optimized\" but is mixed with errors will plunge students into endless debugging loops.\n",
    "\n",
    "Therefore, you naturally think of another approach: let the LLM check itself before outputting, just as humans check their answers before submitting an exam. This is one method currently used in the industry to solve such problems, which we call **reflection**.\n",
    "\n",
    "### 2.3 Two modes of reflection\n",
    "#### 2.3.1 Mode one: Self review\n",
    "\n",
    "To implement reflection, the most direct approach is to have the model examine its own output. There are two ways to implement this: one is simple but has limited effectiveness, the other is more complex but significantly more effective.\n",
    "\n",
    "##### 2.3.1.1 Method one: Single-step instruction-based reflection\n",
    "\n",
    "This is the easiest method to think of. You try to instruct the model within a single model call, through the Prompt, to reflect while generating the answer.\n",
    "\n",
    "```\n",
    "## Role\n",
    "You are a top course writer.\n",
    "\n",
    "## Task\n",
    "1. Polish the language expression of the course and output the entire polished document.\n",
    "\n",
    "2. Reflect on the polished content:\n",
    "   - Does it comply with writing guidelines?\n",
    "   - Has other content been accidentally modified besides language expression?\n",
    "   Output the reflection results and modification suggestions.\n",
    "\n",
    "3. Modify the course according to the suggestions and output the modified full content.\n",
    "\n",
    "## Course draft\n",
    "{original_notebook_content}\n",
    "```\n",
    "\n",
    "<img src=\"https://img.alicdn.com/imgextra/i1/O1CN01QeBLhn1msB07H0F3S_!!6000000005009-55-tps-1534-260.svg\" width=\"700\">\n",
    "\n",
    "This method has its advantages: the model can promptly detect and correct issues during generation, and the context remains coherent, reducing the overhead of multiple rounds of communication.\n",
    "However, it also has obvious drawbacks: when reflection is tied to generation, the model can easily fall into a \"self-verification\" trap, carrying the same cognitive bias into its self-assessment. For example, if it changed `usr_id` to `user_id` in the first step, it is very likely to consider this a \"standardization improvement\" rather than an error during the second step of reflection.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0426b035",
   "metadata": {},
   "source": [
    "##### 2.3.1.2 Method two: Two-step \"generate-feedback\"\n",
    "\n",
    "You can also separate the reflection process, breaking the task into two model calls: one responsible for generation, and the other for review.\n",
    "\n",
    "```\n",
    "# First call (Writing Agent)\n",
    "You are a top course writer, responsible for polishing Jupyter Notebook formatted courses. Please optimize the text to make it more engaging.\n",
    "\n",
    "[Course Draft]: {original_notebook_content}\n",
    "\n",
    "# Second call (Technical Review Agent)\n",
    "You are a strict technical reviewer. Your task is to review the polished course content to ensure:\n",
    "1. The polished course complies with writing guidelines.\n",
    "2. Technical content such as code, configurations, and data has not been accidentally modified.\n",
    "\n",
    "Please compare [Original Content] and [Polished Content]:\n",
    "- If only the wording has been changed, and technical content such as code is completely identical (or only non-functional changes like comments, formatting), answer \"Pass.\"\n",
    "- If any technical content is found to be modified (e.g., code logic, variable names, parameters, configuration items), answer \"Fail\" and specify where the content was accidentally modified.\n",
    "\n",
    "[Original Content]: {original_notebook_content}\n",
    "\n",
    "[Polished Content]: {draft_content}\n",
    "\n",
    "```\n",
    "\n",
    "<img src=\"https://img.alicdn.com/imgextra/i3/O1CN01arwWzK25jS9mSLQBO_!!6000000007562-55-tps-2108-561.svg\" width=\"700\">\n",
    "\n",
    "Because the review Agent has a different perspective from the writing Agent, this method can effectively avoid most role biases. You can even set up multiple specialized review Agentsâ€”for factual review, logical review, style review, security review. This not only increases the comprehensiveness of the review but also facilitates later A/B testing and metric statistics.\n",
    "\n",
    "However, this method also has obvious costs: each additional review Agent adds another model call, leading to higher token consumption.\n",
    "\n",
    "> **Further reading: Cost and optimization**\n",
    ">\n",
    "> **Is this cost worth it?**\n",
    ">\n",
    "> The \"generate-feedback\" loop seemingly increases the number of calls, but we cannot simply compare the cost of \"one high-quality output\" with \"one low-quality output.\" A fairer comparison is: what is the total cost of both paths to obtain a \"usable\" answer?\n",
    ">\n",
    "> If a single call cannot effectively solve the problem, then no matter how low its cost, it is a waste. Conversely, by using a two-step \"generate-feedback\" approach, allowing a mid-tier model to achieve 95% of the effect of a top-tier model, almost the same business value can be achieved at a lower cost.\n",
    ">\n",
    "> **How to further reduce costs?**\n",
    ">\n",
    "> In the \"generate-feedback\" loop, the original course document is repeatedly passed through multiple model callsâ€”the writing Agent needs it, the review Agent needs it, and it may be used again during the correction phase. If the document is very long (e.g., a complete course with dozens of code examples), this repetition can lead to significant token consumption.\n",
    ">\n",
    "> Alibaba Cloud Bailian provides a <a href=\"https://help.aliyun.com/zh/model-studio/context-cache\">context cache</a> mechanism to solve this problem: shared content (like the original document) is cached during the first call, and subsequent calls detect the same prefix and directly reuse it. The cached part is billed at 20% of the standard unit price.\n",
    "> \n",
    "> You can organize your Prompt structure like this:\n",
    "> ```\n",
    "> [Cached part - same for all calls]\n",
    "> ## Original course document\n",
    "> {very long original notebook content}\n",
    "> \n",
    "> [Variable part - different for each call]\n",
    "> ## Task\n",
    "> {writing instructions / review instructions / correction instructions}\n",
    "> \n",
    "> ## Content to be processed\n",
    "> {polished draft / review feedback, etc.}\n",
    "> ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303a8fdc",
   "metadata": {},
   "source": [
    "It is important to note that the review Agent should only be responsible for \"identifying issues\" rather than \"directly rewriting.\" If it directly modifies the content, it may alter the original expressive intent or introduce new errors.\n",
    "\n",
    "Therefore, it's best to feed the review result (`review_result`) back to the writing Agent, allowing it to continue modifying the answer based on the feedback. This forms a \"generate-feedback\" loop, significantly improving the faithfulness of the bot's responses.\n",
    "\n",
    "##### 2.3.1.3 Drawbacks of self-reflection\n",
    "\n",
    "Self-reflection is more suitable for static text-level comparisons (e.g., checking if code has been accidentally modified), but its effectiveness is poor when you need to verify if the code can run normally.\n",
    "\n",
    "This is because LLMs are good at judging whether code \"looks reasonable,\" but cannot perform precise semantic validation like a compiler. More critically, the model cannot actually execute codeâ€”it cannot see runtime logs, catch error reports, or perceive library version conflicts or environment configuration issues.\n",
    "\n",
    "To solve this problem, we need to introduce an external feedback mechanism.\n",
    "\n",
    "#### 2.3.2 Mode two: External feedback\n",
    "##### 2.3.2.1 Using tools to validate results\n",
    "The core idea of external feedback is to execute the LLM's generated results in a real environment, then feed the execution results (success/failure, error messages, test reports, etc.) back to the model, allowing it to iterate and correct based on these concrete facts.\n",
    "\n",
    "If self-reflection is \"I think I did it right,\" then external feedback is \"facts prove whether I did it right.\"\n",
    "\n",
    "Returning to our Jupyter Notebook course polishing scenario. Suppose the course contains some code examples, and we want to ensure that the code still runs correctly while polishing the text.\n",
    "\n",
    "This requires combining **tool use** (learned in the previous chapter) with reflection mechanisms. Here, the most direct source of external feedback is a code execution tool. AgentScope has a powerful `execute_python_code` tool built-in, which provides a secure code interpreter environment for the Agent, allowing it to truly execute Python code and retrieve results or error messages.\n",
    "\n",
    "The specific workflow is as follows:\n",
    "\n",
    "1. **Generate**: The writing Agent polishes the document and outputs the notebook content containing the code.\n",
    "2. **Interact with external tools**: The system automatically extracts code blocks and calls the `execute_python_code` tool to attempt execution.\n",
    "3. **Obtain external feedback**: The tool returns the execution result, let's say an error: `TypeError: get_user_data() got an unexpected keyword argument 'usr_id'`.\n",
    "4. **Correct**: The Agent receives this error feedback. It now clearly knows what went wrong with the code. Based on this feedback, it generates corrected code.\n",
    "\n",
    "<img src=\"https://img.alicdn.com/imgextra/i1/O1CN01AD9PM029mRCVf8vtm_!!6000000008110-55-tps-3545-454.svg\" width=\"700\">\n",
    "\n",
    "Below is a simple example implemented using AgentScope. The `execute_python_code` tool built into AgentScope does not require manually creating tool functions; you just need to register it via `toolkit.register_tool_function(execute_python_code)`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d5d4c3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T07:57:10.707144Z",
     "iopub.status.busy": "2025-11-21T07:57:10.706748Z",
     "iopub.status.idle": "2025-11-21T07:57:21.815062Z",
     "shell.execute_reply": "2025-11-21T07:57:21.814347Z",
     "shell.execute_reply.started": "2025-11-21T07:57:10.707102Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Original course content:\n",
      "============================================================\n",
      " # Python function example course\n",
      "\n",
      "  This section teaches how to define and call functions.\n",
      "\n",
      "  ## Defining functions\n",
      "\n",
      "  def get_user_data(usr_id: str):\n",
      "      return f\"Data for {usr_id}\"\n",
      "\n",
      "  ## Calling functions\n",
      "\n",
      "  print(get_user_data(usr_id=\"u-123\"))\n",
      "\n",
      "  ## Summary\n",
      "\n",
      "  You have learned to define and call Python functions.\n",
      "  \n",
      "\n",
      "============================================================\n",
      "Agent starts working...\n",
      "============================================================\n",
      "Writer: # Python Function Example Course\n",
      "\n",
      "Welcome to this hands-on introduction to Python functions! Functions are like mini-programs that perform specific tasks and can be reused throughout your code. In this section, you'll learn how to define and call functionsâ€”two essential skills for any Python programmer.\n",
      "\n",
      "## Defining Functions\n",
      "\n",
      "A function is defined using the `def` keyword, followed by the function name and parameters in parentheses. Here's a simple example:\n",
      "\n",
      "def get_user_data(usr_id: str):\n",
      "    return f\"Data for {usr_id}\"\n",
      "\n",
      "This function takes a user ID as input and returns a formatted string containing the user's data.\n",
      "\n",
      "## Calling Functions\n",
      "\n",
      "Once a function is defined, you can use (or \"call\") it anytime. Just pass the required arguments, and the function will do its job. For example:\n",
      "\n",
      "print(get_user_data(usr_id=\"u-123\"))\n",
      "\n",
      "This line calls `get_user_data` with the user ID `u-123` and prints the result.\n",
      "\n",
      "## Summary\n",
      "\n",
      "Great job! You've now learned how to define a function using `def` and how to call it to get useful output. This foundational knowledge will help you write cleaner, more efficient code.\n",
      "\n",
      "============================================================\n",
      "Final output:\n",
      "============================================================\n",
      "# Python Function Example Course\n",
      "\n",
      "Welcome to this hands-on introduction to Python functions! Functions are like mini-programs that perform specific tasks and can be reused throughout your code. In this section, you'll learn how to define and call functionsâ€”two essential skills for any Python programmer.\n",
      "\n",
      "## Defining Functions\n",
      "\n",
      "A function is defined using the `def` keyword, followed by the function name and parameters in parentheses. Here's a simple example:\n",
      "\n",
      "def get_user_data(usr_id: str):\n",
      "    return f\"Data for {usr_id}\"\n",
      "\n",
      "This function takes a user ID as input and returns a formatted string containing the user's data.\n",
      "\n",
      "## Calling Functions\n",
      "\n",
      "Once a function is defined, you can use (or \"call\") it anytime. Just pass the required arguments, and the function will do its job. For example:\n",
      "\n",
      "print(get_user_data(usr_id=\"u-123\"))\n",
      "\n",
      "This line calls `get_user_data` with the user ID `u-123` and prints the result.\n",
      "\n",
      "## Summary\n",
      "\n",
      "Great job! You've now learned how to define a function using `def` and how to call it to get useful output. This foundational knowledge will help you write cleaner, more efficient code.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Using AgentScope to implement an external feedback reflection mechanism (simplified)\n",
    "Scenario: Polishing Jupyter Notebook courses, verifying code correctness via a code interpreter\n",
    "\"\"\"\n",
    "\n",
    "import asyncio\n",
    "import os\n",
    "from textwrap import dedent\n",
    "\n",
    "from agentscope.agent import ReActAgent\n",
    "from agentscope.formatter import DashScopeChatFormatter\n",
    "from agentscope.memory import InMemoryMemory\n",
    "from agentscope.message import Msg\n",
    "from agentscope.model import DashScopeChatModel\n",
    "from agentscope.tool import Toolkit, execute_python_code\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Create writing Agent (equipped with code interpreter tool)\n",
    "# ============================================================\n",
    "\n",
    "def create_writer_agent() -> ReActAgent:\n",
    "    \"\"\"Creates a writing Agent responsible for polishing course content\"\"\"\n",
    "\n",
    "    # Create a toolkit and register the built-in code execution tool\n",
    "    toolkit = Toolkit()\n",
    "    toolkit.register_tool_function(execute_python_code)\n",
    "\n",
    "    writer = ReActAgent(\n",
    "        name=\"Writer\",\n",
    "        sys_prompt=dedent(\"\"\"You are a technical course writer, responsible for polishing Jupyter Notebook courses.\n",
    "            Task requirements:\n",
    "            1. Optimize text expression to make it smoother and more vivid\n",
    "            2. **Absolutely do not modify variable names, function names, or parameter names in the code**\n",
    "            3. After polishing, use the execute_python_code tool to verify all code blocks\n",
    "            4. If code execution fails, check if you accidentally modified the code and correct it\n",
    "\n",
    "            Remember: only change text, not code logic!\n",
    "        \"\"\"),\n",
    "        model=DashScopeChatModel(\n",
    "            model_name=\"qwen-plus\",\n",
    "            api_key=os.environ.get(\"DASHSCOPE_API_KEY\"),\n",
    "            stream=False,\n",
    "        ),\n",
    "        formatter=DashScopeChatFormatter(),\n",
    "        toolkit=toolkit,\n",
    "        memory=InMemoryMemory(),\n",
    "        max_iters=10,  # Max iterations (example configuration, should be adjusted based on task complexity and cost budget)\n",
    "    )\n",
    "\n",
    "    return writer\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Main process\n",
    "# ============================================================\n",
    "\n",
    "async def main():\n",
    "    \"\"\"Main function - demonstrates the external feedback reflection mechanism\"\"\"\n",
    "\n",
    "    # Original course content (contains \"non-standard\" variable name usr_id)\n",
    "    original_notebook = \"\"\" # Python function example course\n",
    "\n",
    "  This section teaches how to define and call functions.\n",
    "\n",
    "  ## Defining functions\n",
    "\n",
    "  def get_user_data(usr_id: str):\n",
    "      return f\"Data for {usr_id}\"\n",
    "\n",
    "  ## Calling functions\n",
    "\n",
    "  print(get_user_data(usr_id=\"u-123\"))\n",
    "\n",
    "  ## Summary\n",
    "\n",
    "  You have learned to define and call Python functions.\n",
    "  \"\"\"\n",
    "\n",
    "    print(\"=\"*60)\n",
    "    print(\"Original course content:\")\n",
    "    print(\"=\"*60)\n",
    "    print(original_notebook)\n",
    "\n",
    "    # Create Agent\n",
    "    writer = create_writer_agent()\n",
    "\n",
    "    # Send polishing request\n",
    "    user_msg = Msg(\n",
    "        name=\"user\",\n",
    "        content=dedent(f\"\"\"Please polish the following course content, requirements:\n",
    "            {original_notebook}\n",
    "            1. Make the text more vivid and easy to understand\n",
    "            2. **Do not modify variable names or function names in the code**\n",
    "            3. After polishing, use execute_python_code to verify if the code can run\n",
    "            4. If an error occurs, it means you might have modified the code incorrectly, please correct it\n",
    "        \"\"\"),\n",
    "        role=\"user\"\n",
    "    )\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Agent starts working...\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # Agent automatically performs: Polish -> Validate -> Correct -> Re-validate\n",
    "    result = await writer(user_msg)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Final output:\")\n",
    "    print(\"=\"*60)\n",
    "    print(result.get_text_content())\n",
    "\n",
    "try:\n",
    "    await main()\n",
    "except NameError:\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33121a53",
   "metadata": {},
   "source": [
    "Through this method, the Agent can use external tools to verify output results, thereby achieving efficient and precise self-correction.\n",
    "\n",
    "##### 2.3.2.2 Other validation methods\n",
    "\n",
    "In addition to code execution, this pattern can be applied to other scenarios requiring objective facts:\n",
    "\n",
    "*   **Scenario: Optimizing Matplotlib charts in research papers**\n",
    "    *   **Problem**: You ask the Agent to generate data visualization code for a research paper. The Agent generates a Matplotlib code that \"looks reasonable,\" containing correct data processing logic and plotting function calls. However, code that runs does not mean the chart looks goodâ€”the actual rendered chart might have overlapping axis labels, legends obscuring data points, fonts too small to read, color schemes unsuitable for printing, etc.\n",
    "    *   **External feedback solution**: The system calls a **code interpreter** tool to execute the Matplotlib code and returns the generated image file. The **Agent receives the actual rendered chart through visual input**, allowing it to intuitively identify visual problems (e.g., \"x-axis labels overlap,\" \"legend blocks critical data points\") and then specifically adjust code parameters (e.g., `plt.xticks(rotation=45)` to rotate labels, `bbox_to_anchor` to adjust legend position, increase `fontsize`). This \"generate-render-adjust\" loop ensures the final chart meets academic publication quality requirements.\n",
    "\n",
    "*   **Scenario: Checking answers for complex calculation problems**\n",
    "    *   **Problem**: In a quantum mechanics lesson, you need to create a practice problem: \"What is the ground state energy in joules for an electron (`mass â‰ˆ 9.11e-31 kg`) confined in a one-dimensional infinite potential well of length 1 nanometer (1e-9 m)? (Planck's constant `h â‰ˆ 6.626e-34 JÂ·s`)\". The Agent might make errors during the solution steps due to complex exponential calculations.\n",
    "    *   **External feedback solution**: The system identifies the expression needing calculation `(1**2 * (6.626e-34)**2) / (8 * 9.11e-31 * (1e-9)**2)` and hands it to a **code interpreter** or **calculator** tool for execution. The tool returns the precise numerical result. This objective calculation result is provided as feedback, allowing the Agent to correct its final answer.\n",
    "\n",
    "*   **Scenario: Structured output validation**\n",
    "    *   **Problem**: You ask the Agent to generate a configuration file conforming to a specific JSON Schema, but it might omit required fields or use incorrect data types.\n",
    "    *   **External feedback solution**: The system uses libraries like Pydantic to validate the generated JSON. When the output does not conform to the Schema, the validator returns a detailed error report (e.g., \"field 'timeout' should be an integer, not a string\"). This objective, precise feedback allows the Agent to correct its output until it fully conforms to the predefined structure. This \"generate-validate-feedback\" loop is the most common and fundamental application of reflection mechanisms in practice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91039088",
   "metadata": {},
   "source": [
    "Finally, how do you choose between these two feedback modes? This depends on your specific needs, budget, and acceptable error rate. For example, if you are just polishing a blog post without code, reflection might not be needed at all. But if you are modifying an interactive course with dozens of code examples, then introducing an \"external feedback\" loop based on a code interpreter is a necessary investment to ensure document quality and avoid publishing accidents.\n",
    "\n",
    "### 2.4 Summary\n",
    "\n",
    "Let's review what you've learned in this section:\n",
    "- **Limitations of direct instructions**: Directly asking the LLM in the Prompt to \"be more careful\" or \"do not modify code\" usually has poor results, because the model aims to generate \"more reasonable\" text and sometimes \"means well but does harm.\"\n",
    "- **Core idea of \"reflection\"**: Mimicking human \"metacognition,\" giving the model an opportunity to review and evaluate its own complete generated content, thereby finding and correcting errors. This is more reliable than simple instructions.\n",
    "- **Self-reflection vs. external feedback**: \"Self-reflection\" is having another Agent check the draft, suitable for subjective evaluation; \"external feedback\" is using tools (like a code interpreter) to verify results, suitable for scenarios requiring objective facts.\n",
    "- **Engineering implementation: \"Generate-feedback\" loop**: An effective way to implement \"reflection\" is to use multiple calls: the first generates a draft, and subsequent calls are responsible for evaluating the draft, providing feedback, and making modifications based on that feedback.\n",
    "\n",
    "## 3 Building workflows\n",
    "\n",
    "### 3.1 Single agent handling complex processes\n",
    "\n",
    "On Monday morning, you received this message:\n",
    "\n",
    "> \"The 'Introduction to Python Data Analysis' course submitted last Friday needs to be launched as soon as possible. Can you run it through our standard review process with your AI assistant? That means: 1) all code examples must run; 2) technical concepts must be sound; 3) the difficulty gradient should suit beginners; 4) the language style must conform to our guidelines. I need the results by 3 PM.\"\n",
    "\n",
    "You thought, this task is quite simple. Your bot can already validate code, so handling this \"composite task\" shouldn't be difficult. So you crammed all the requirements into one prompt:\n",
    "\n",
    "```plaintext\n",
    "prompt = \"\"\"Please complete the following course review tasks:\n",
    "1. Verify that all Python code runs correctly.\n",
    "2. Check the accuracy of technical concepts (especially the usage of pandas and numpy).\n",
    "3. Evaluate whether the difficulty curve is suitable for programming novices.\n",
    "4. Adjust the wording according to our style guide (avoid colloquialisms like \"very simple\" or \"super\").\n",
    "Please provide a complete review report.\"\"\"\n",
    "response = agent.run(prompt + course_content)\n",
    "```\n",
    "\n",
    "A few minutes later, you opened the returned result:\n",
    "\n",
    "* The Agent indeed validated the code, but when \"optimizing the language,\" it changed `super()` in the code to `parent()`, because it felt \"super\" was too colloquial.\n",
    "* It found an error in the explanation of DataFrame in Chapter 3, and after correcting it, introduced a more serious error: stating that \"DataFrame is a built-in Python data structure.\"\n",
    "* As for difficulty assessment? It seemed to have forgotten about it when it reached the 50th issue.\n",
    "\n",
    "You tried to make it start over. This time it remembered to assess the difficulty but missed half of the code validation. The third time, it did all the tasks but \"corrected\" some originally correct concepts into errors.\n",
    "\n",
    "The problem is obvious: asking a single Agent to manage multiple complex tasks simultaneously is like asking an intern to answer four phones at onceâ€”something is bound to go wrong.\n",
    "\n",
    "### 3.2 Analysis of failure causes\n",
    "#### 3.2.1 Forgetting effect of attention mechanisms\n",
    "\n",
    "When LLMs generate responses, their \"attention\" to information at different positions is uneven. When the Agent processes the fourth task (polishing language), the details of the first task (code validation) have been diluted by a large amount of intermediate information.\n",
    "\n",
    "Specifically, the model \"forgets\" the constraints validated earlier when making later modifications. For example, even if you have confirmed that `super()` is correct Python syntax, during the language polishing phase, the model might replace it because the word \"super\" seems colloquial, leading to code errors.\n",
    "\n",
    "This is not simply \"poor memory,\" but an inherent limitation of the self-attention mechanism in the Transformer architectureâ€”the attention weights between tokens are diluted as the sequence length increases.\n",
    "\n",
    "#### 3.2.2 Cascading error amplification\n",
    "\n",
    "When executing multiple tasks sequentially, early errors become the \"factual basis\" for subsequent processing. Suppose the Agent incorrectly \"corrected\" the definition of DataFrame during the fact-checking phase (e.g., claiming it's built-in Python). This error would then enter the subsequent context.\n",
    "What's worse, the model would continue reasoning based on this erroneous \"fact\":\n",
    "\n",
    "- Since DataFrame is \"built-in,\" there's no need to import pandas.\n",
    "- Import statements would be removed from teaching examples.\n",
    "- All code examples would become invalid.\n",
    "\n",
    "This error propagation is not linear, but exponentialâ€”a small error can trigger a cascade of incorrect decisions.\n",
    "\n",
    "#### 3.2.3 Flattened understanding vs. structured requirements\n",
    "\n",
    "Your complex requirement is actually a task graph with an internal structure:\n",
    "- Some tasks can be performed in parallel (code checking and style checking don't interfere with each other).\n",
    "- Some tasks have dependencies (conceptual understanding must precede difficulty assessment).\n",
    "- Some tasks require a global perspective (evaluating the overall difficulty curve).\n",
    "\n",
    "But for the model, your prompt is just a flat sequence of tokens. It cannot automatically recognize these structural relationships and instead attempts to solve an inherently graph-structured problem with a linear generation process.\n",
    "\n",
    "It's like asking someone to play four games with different rules simultaneously, without telling them which can be played in turns and which must be played concurrently.\n",
    "\n",
    "Ultimately, relying on a single Agent to perform complex reviews is like building a house without blueprints; every brick laid might affect the structural stability of the entire building.\n",
    "\n",
    "### 3.3 Several workflow patterns\n",
    "\n",
    "Since having one Agent handle everything doesn't work, you naturally think of another approach: just as you break a project into subtasks and assign them to different people or complete them at different times when managing a project. This \"Divide and Conquer\" approach is central to solving such problems.\n",
    "\n",
    "We call this pattern of breaking down complex tasks into multiple nodes and defining their execution relationships a **workflow**.\n",
    "\n",
    "The key to building workflows is understanding the business and making the most appropriate task breakdown. Below, we will start with the simplest pattern and gradually build powerful workflows capable of handling complex course reviews.\n",
    "\n",
    "#### 3.3.1 Pattern one: Pipeline\n",
    "\n",
    "This is the most basic and intuitive workflow. It breaks a task into several fixed, sequentially executed steps. The output of the previous step serves strictly as the input for the next step. The entire process resembles a factory assembly line, unidirectional and immutable. The RAG Q&A bot you built earlier in this course is a perfect example of this pattern.\n",
    "\n",
    "<img src=\"https://img.alicdn.com/imgextra/i4/O1CN01HuDh7v1KD8GVPSeEh_!!6000000001129-55-tps-2514-176.svg\" width=\"700\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9bfad2cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T08:08:41.267950Z",
     "iopub.status.busy": "2025-11-21T08:08:41.267684Z",
     "iopub.status.idle": "2025-11-21T08:08:55.198885Z",
     "shell.execute_reply": "2025-11-21T08:08:55.198296Z",
     "shell.execute_reply.started": "2025-11-21T08:08:41.267929Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Pipeline output:\n",
      "### Inspection Report for Course Designer\n",
      "\n",
      "**Code Sample Provided:**\n",
      "```python\n",
      "print('Hello, World!')\n",
      "x = 1 / 0\n",
      "```\n",
      "\n",
      "**Validation Results:**\n",
      "\n",
      "- **Line 1:** `print('Hello, World!')` - This line of code is valid and will execute as expected, printing 'Hello, World!' to the console.\n",
      "- **Line 2:** `x = 1 / 0` - This line of code contains a critical error. The attempt to divide by zero will raise a `ZeroDivisionError`, causing the program to terminate abruptly.\n",
      "\n",
      "**Recommendations:**\n",
      "\n",
      "- It's important to handle potential errors like `ZeroDivisionError` in the code to ensure that the program does not crash unexpectedly. Consider using a try-except block to catch and handle such exceptions gracefully.\n",
      "- For educational purposes, it would be beneficial to include an example of how to properly handle this error, which will teach students about exception handling in Python.\n",
      "\n",
      "**Suggested Code Modification:**\n",
      "```python\n",
      "print('Hello, World!')\n",
      "\n",
      "try:\n",
      "    x = 1 / 0\n",
      "except ZeroDivisionError:\n",
      "    print('Cannot divide by zero.')\n",
      "```\n",
      "\n",
      "This modification introduces the concept of exception handling, which is a fundamental practice in writing robust and user-friendly programs.\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Pattern one: Pipeline - Scenario: Course quick check process\n",
    "Goal: User submits a course draft, the system sequentially completes 1) Extract code from course -> 2) Validate code executability -> 3) Generate code review report \"\"\"\n",
    "import asyncio\n",
    "from agentscope.message import Msg\n",
    "from agentscope.pipeline import sequential_pipeline\n",
    "from chatbot.agent import create_agent, disable_console_output\n",
    "\n",
    "async def run_pipeline() -> None:\n",
    "    # Node A: Code Extraction Agent\n",
    "    # multi_agent=True is a configuration in AgentScope, used to ensure communication format compatibility between Agents,\n",
    "    # and is a recommended setting for building workflows and multi-agent systems.\n",
    "    code_extractor = create_agent(\n",
    "        name=\"Code Extractor\",\n",
    "        sys_prompt=(\n",
    "            \"You are a code extraction expert. Please accurately extract all Python code blocks from the user-provided course text.\"\n",
    "            \"Only output the code, without any other explanations.\"\n",
    "        ),\n",
    "        model_name=\"qwen-flash\",\n",
    "        multi_agent=True,\n",
    "    )\n",
    "\n",
    "    # Node B: Code Validation Agent (can call external tools)\n",
    "    code_validator = create_agent(\n",
    "        name=\"Code Validator\",\n",
    "        sys_prompt=(\n",
    "            \"You are a code execution and validation expert. You will receive code text. Please use a code interpreter to execute it.\"\n",
    "            \"Report whether the code runs successfully, and if not, point out the error.\"\n",
    "        ),\n",
    "        # Here you can configure code_validator to use the code interpreter tool you learned in section two\n",
    "        model_name=\"qwen-plus\",\n",
    "        multi_agent=True,\n",
    "    )\n",
    "\n",
    "    # Node C: Report Generation Agent\n",
    "    report_generator = create_agent(\n",
    "        name=\"Report Generator\",\n",
    "        sys_prompt=(\n",
    "            \"You are a review report writing assistant. Generate a concise and clear inspection report for the course designer based on the code validation results from the previous step.\"\n",
    "        ),\n",
    "        model_name=\"qwen-max\",\n",
    "        multi_agent=True,\n",
    "    )\n",
    "\n",
    "    agents = [code_extractor, code_validator, report_generator]\n",
    "    disable_console_output(agents)\n",
    "\n",
    "    course_draft = (\n",
    "        \"This is our new course. The first part is `print('Hello, World!')`.\"\n",
    "        \"The second part is a problematic code `x = 1 / 0`.\"\n",
    "    )\n",
    "    result = await sequential_pipeline(\n",
    "        agents=agents,\n",
    "        msg=Msg(\"user\", course_draft, \"user\"),\n",
    "    )\n",
    "\n",
    "    print(\"=\" * 50)\n",
    "    print(\"Pipeline output:\")\n",
    "    print(result.content)\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "async def main() -> None:\n",
    "    await run_pipeline()\n",
    "\n",
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3464de3a",
   "metadata": {},
   "source": [
    "Its core advantage lies in its **simplicity, predictability, and ease of debugging**. Because the process is fixed, when a problem occurs, you can easily pinpoint which stage (extraction, validation, or reporting) caused the issue. This determinism is crucial in many enterprise applications.\n",
    "\n",
    "It is suitable for tasks with very fixed business processes and single logic. For example:\n",
    "\n",
    "* **Initial code check**: First extract the code, then run the validation.\n",
    "* **Document translation**: First extract the text, then translate, and finally format the output.\n",
    "* **New employee onboarding material distribution**: First generate a welcome email, then attach company documents, and finally send them.\n",
    "\n",
    "The rigidity of the pipeline is its greatest strength and also its most fatal weakness. It cannot handle any changes outside the defined process. Faced with a request like \"help me evaluate the fun factor of this course,\" this pipeline designed for \"code checking\" will be completely at a loss, because it lacks the ability to handle such intent. It assumes all inputs should follow the same processing logic.\n",
    "\n",
    "#### 3.3.2 Pattern two: Branching\n",
    "\n",
    "To overcome the rigidity of pipelines, you need to introduce decision-making capabilities. The core of the branching pattern is to set up a \"router\" or \"dispatch center\" at the beginning or at key nodes of the workflow. This decision node analyzes the input (e.g., user review requirements) and then, like a traffic policeman, directs the task to different, predefined processing paths (i.e., different pipelines or experts).\n",
    "\n",
    "<img src=\"https://img.alicdn.com/imgextra/i1/O1CN01pZMqbg1yst0CIdiTg_!!6000000006635-55-tps-2206-542.svg\" width=\"700\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0fa2aba8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T08:09:58.820352Z",
     "iopub.status.busy": "2025-11-21T08:09:58.820118Z",
     "iopub.status.idle": "2025-11-21T08:10:01.914696Z",
     "shell.execute_reply": "2025-11-21T08:10:01.914052Z",
     "shell.execute_reply.started": "2025-11-21T08:09:58.820334Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review Task Dispatcher: I will perform a comprehensive review of the course, with special attention to the code quality and difficulty level.\n",
      "==================================================\n",
      "Branch choice: full_review\n",
      "I will now initiate a comprehensive review process for the course, focusing on three key aspects: code quality and correctness, factual accuracy, and pedagogical effectiveness. I'll examine the content thoroughly to ensure it meets high standards in all areas. Please allow me some time to complete this detailed evaluation.\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Pattern two: Branching - Scenario: Course review task distribution\n",
    "Routing Agent reads review request, selects one of the following branches:\n",
    "1) code_check: Quick code check only\n",
    "2) style_guide: Polish language according to style guide\n",
    "3) full_review: Perform a comprehensive multi-dimensional review \"\"\"\n",
    "import asyncio\n",
    "from typing import Literal\n",
    "from pydantic import BaseModel, Field\n",
    "from agentscope.message import Msg\n",
    "from chatbot.agent import create_agent, disable_console_output\n",
    "\n",
    "class RouteChoice(BaseModel):\n",
    "    choice: Literal[\"code_check\", \"style_guide\", \"full_review\", None] = Field(\n",
    "        description=\"Select branch based on user intent: code_check/style_guide/full_review/None\"\n",
    "    )\n",
    "    extra: str | None = Field(default=None, description=\"Brief description of the task\")\n",
    "\n",
    "async def branch_code_check(user_msg: Msg) -> Msg:\n",
    "    agent = create_agent(\n",
    "        name=\"Code Quick Check Expert\",\n",
    "        sys_prompt=\"You are a code quick check expert. Based on user requirements, quickly verify if code snippets in the course can run.\",\n",
    "        model_name=\"qwen-plus\",\n",
    "        multi_agent=True,\n",
    "    )\n",
    "    disable_console_output([agent])\n",
    "    return await agent(user_msg)\n",
    "\n",
    "async def branch_style_guide(user_msg: Msg) -> Msg:\n",
    "    agent = create_agent(\n",
    "        name=\"Language Polishing Expert\",\n",
    "        sys_prompt=\"You are a language polishing expert. Please rewrite and polish the user-provided course text according to the company style guide.\",\n",
    "        model_name=\"qwen-max\",\n",
    "        multi_agent=True,\n",
    "    )\n",
    "    disable_console_output([agent])\n",
    "    return await agent(user_msg)\n",
    "\n",
    "async def branch_full_review(user_msg: Msg) -> Msg:\n",
    "    agent = create_agent(\n",
    "        name=\"Chief Reviewer\",\n",
    "        sys_prompt=\"You are the chief reviewer. Inform the user that you will initiate a comprehensive review process including code, facts, and pedagogy.\",\n",
    "        model_name=\"qwen-flash\", # Use a lightweight model to simulate the notification action for starting the process\n",
    "        multi_agent=True,\n",
    "    )\n",
    "    disable_console_output([agent])\n",
    "    return await agent(user_msg)\n",
    "\n",
    "\n",
    "async def run_branching() -> None:\n",
    "    router = create_agent(\n",
    "        name=\"Review Task Dispatcher\",\n",
    "        sys_prompt=(\n",
    "            \"You are a course review task dispatcher. Select a branch based on user input:\\n\"\n",
    "            \"- If only checking code, output code_check\\n\"\n",
    "            \"- If polishing text, output style_guide\\n\"\n",
    "            \"- If a complete, comprehensive review is needed, output full_review\\n\"\n",
    "            \"Only express your choice through structured output, do not provide a main body response.\"\n",
    "        ),\n",
    "        model_name=\"qwen-plus\",\n",
    "        multi_agent=False,\n",
    "    )\n",
    "\n",
    "    user_text = \"This course is almost done, please give it a comprehensive check, especially the code and difficulty.\"\n",
    "\n",
    "    res = await router(\n",
    "        Msg(\"user\", user_text, \"user\"),\n",
    "        structured_model=RouteChoice,\n",
    "    )\n",
    "    choice = res.metadata.get(\"choice\")\n",
    "\n",
    "    if choice == \"code_check\":\n",
    "        out = await branch_code_check(Msg(\"user\", user_text, \"user\"))\n",
    "    elif choice == \"style_guide\":\n",
    "        out = await branch_style_guide(Msg(\"user\", user_text, \"user\"))\n",
    "    elif choice == \"full_review\":\n",
    "        out = await branch_full_review(Msg(\"user\", user_text, \"user\"))\n",
    "    else:\n",
    "        # Default to full review to ensure the example runs\n",
    "        out = await branch_full_review(Msg(\"user\", user_text, \"user\"))\n",
    "\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Branch choice: {choice}\")\n",
    "    print(out.content)\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "async def main() -> None:\n",
    "    await run_branching()\n",
    "\n",
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4bc008",
   "metadata": {},
   "source": [
    "Compared to a single pipeline, branching makes the system more flexible and intelligent. It enables an application to handle multiple types of tasks, greatly expanding its applicability and improving the user experience.\n",
    "\n",
    "Common application scenarios include:\n",
    "\n",
    "* **Intelligent customer service**: Routes based on user query type (course content inquiry, platform technical support, purchase advice) to different processing flows.\n",
    "* **Multi-tool Agent**: The Agent decides whether to call a code interpreter, search engine, or internal knowledge base based on task requirements.\n",
    "* **Content processing system**: Calls different review processes based on content type (video, text, interactive Notebook).\n",
    "\n",
    "Branching is essentially \"one of many choices,\" and it is still sequential. It can handle \"code checking\" or \"language polishing,\" but it cannot handle composite requests like \"checking code while polishing language.\" For our initial complex request involving four review dimensions, it can only follow one branch at a time, requiring multiple independent conversations between the user and the bot, which is very inefficient.\n",
    "\n",
    "#### 3.3.3 Pattern three: Parallel execution\n",
    "\n",
    "When a request can be broken down into multiple independent subtasks, queuing them up is a huge waste. The core idea of the parallel execution pattern is \"doing things simultaneously.\" It first breaks a complex task into multiple subtasks, then distributes these subtasks to different execution units (Agents or tools) for concurrent processing, and finally gathers all results to form the final output.\n",
    "\n",
    "<img src=\"https://img.alicdn.com/imgextra/i3/O1CN01UHv4l51rexeQFw6pe_!!6000000005657-55-tps-2243-759.svg\" width=\"700\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0440c6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T08:12:54.563042Z",
     "iopub.status.busy": "2025-11-21T08:12:54.562818Z",
     "iopub.status.idle": "2025-11-21T08:13:27.844508Z",
     "shell.execute_reply": "2025-11-21T08:13:27.843908Z",
     "shell.execute_reply.started": "2025-11-21T08:12:54.563022Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Parallel execution output:\n",
      "In order to compile a comprehensive and well-structured review report, I will need to consolidate the information and feedback from multiple experts. Before we proceed, let's ensure we have all the necessary details. Could you please provide the following information regarding the introductory Python data analysis course?\n",
      "\n",
      "1. A detailed outline of the **course structure**, including the number of modules, the sequence of topics, and how the content flows from one topic to another.\n",
      "2. The **target audience** - whether the course is designed for complete beginners, individuals with some programming experience, or those specifically interested in data analysis with Python.\n",
      "3. The **learning objectives** - what should the learners be able to achieve by the end of the course?\n",
      "4. Any **technical concepts and coding examples** that you would like to be reviewed for accuracy and clarity.\n",
      "5. Your openness to **curriculum improvement suggestions** - are there areas where you would welcome ideas for enhancement?\n",
      "6. The **language style and terminology** used in the course - if there are any particular style guidelines or preferences you follow, it would be useful to know them for the review.\n",
      "\n",
      "With this information, I can create a consolidated review that addresses the course's difficulty, its attractiveness to the target audience, the effectiveness of the exercises, and the overall coherence and consistency of the content. Please share the requested details and any other pertinent information.\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Pattern three: Parallel Execution - Scenario: Comprehensive course review\n",
    "Executes independent review subtasks in parallel: code check, fact verification, pedagogy evaluation, language style check.\n",
    "Example uses fanout_pipeline to collect reports in parallel, then a summarizer Agent consolidates them. \"\"\"\n",
    "import asyncio\n",
    "from typing import List\n",
    "from agentscope.message import Msg\n",
    "from agentscope.pipeline import fanout_pipeline\n",
    "from chatbot.agent import create_agent, disable_console_output\n",
    "\n",
    "async def run_parallel() -> None:\n",
    "    # Four independent subtask \"expert\" Agents\n",
    "    code_checker = create_agent(\n",
    "        name=\"Code Checker\",\n",
    "        sys_prompt=\"Verify that the code in the course is correct and provide suggestions for fixing it.\",\n",
    "        model_name=\"qwen-plus\",\n",
    "        multi_agent=True,\n",
    "    )\n",
    "    fact_checker = create_agent(\n",
    "        name=\"Fact Checker\",\n",
    "        sys_prompt=\"Verify the accuracy of technical concepts, function explanations, and citation norms in the course.\",\n",
    "        model_name=\"qwen-plus\",\n",
    "        multi_agent=True,\n",
    "    )\n",
    "    pedagogy_evaluator = create_agent(\n",
    "        name=\"Pedagogy Evaluator\",\n",
    "        sys_prompt=\"Evaluate the course's difficulty curve, case appeal, and exercise effectiveness.\",\n",
    "        model_name=\"qwen-flash\",\n",
    "        multi_agent=True,\n",
    "    )\n",
    "    style_editor = create_agent(\n",
    "        name=\"Style Editor\",\n",
    "        sys_prompt=\"Check and report on language style and terminology consistency issues according to company style guidelines.\",\n",
    "        model_name=\"qwen-flash\",\n",
    "        multi_agent=True,\n",
    "    )\n",
    "\n",
    "    experts = [code_checker, fact_checker, pedagogy_evaluator, style_editor]\n",
    "    disable_console_output(experts)\n",
    "\n",
    "    course_content = \"This is our newly developed introductory Python data analysis course...\"\n",
    "    msgs = await fanout_pipeline(\n",
    "        agents=experts,\n",
    "        msg=Msg(\"user\", course_content, \"user\"),\n",
    "        enable_gather=True,\n",
    "    )\n",
    "\n",
    "    # Summarizer Agent\n",
    "    summarizer = create_agent(\n",
    "        name=\"Chief Editor\",\n",
    "        sys_prompt=\"Consolidate review comments from multiple experts into a clear, well-structured comprehensive review report.\",\n",
    "        model_name=\"qwen-max\",\n",
    "        multi_agent=True,\n",
    "    )\n",
    "    disable_console_output([summarizer])\n",
    "\n",
    "    merged_text: List[str] = [m.content for m in msgs]\n",
    "    prompt = \"\\n\\n\".join(merged_text)\n",
    "    summary = await summarizer(Msg(\"user\", prompt, \"user\"))\n",
    "\n",
    "    print(\"=\" * 50)\n",
    "    print(\"Parallel execution output:\")\n",
    "    print(summary.content)\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "async def main() -> None:\n",
    "    await run_parallel()\n",
    "\n",
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d077054e",
   "metadata": {},
   "source": [
    "The most significant advantage is a substantial increase in efficiency. The total time taken for the workflow is no longer the sum of all subtask times, but depends on the longest subtask. This allows the Agent to quickly respond to complex requests involving multiple steps.\n",
    "\n",
    "Common application scenarios include:\n",
    "\n",
    "* Handling complex review requests: Such as our course review scenario, simultaneously addressing multiple dimensions like code, facts, pedagogy, and style.\n",
    "* Generating comprehensive reports: Simultaneously pulling information from different data sources (user feedback, market trends, competitor analysis) and analyzing them separately, finally consolidating into a new course project proposal report.\n",
    "* Batch data processing: Performing the same formatting or checking operations on multiple course units concurrently.\n",
    "\n",
    "The prerequisite for this pattern is that subtasks are mutually independent. If tasks have dependencies (e.g., the core knowledge points of a course must be confirmed before evaluating the relevance of its cases), simple parallelization is not possible. Moreover, it assumes that each execution unit can provide a \"correct\" answer, making it unsuitable for creative or decision-making tasks that require comparison and trade-offs between multiple parties to arrive at the best solution.\n",
    "\n",
    "#### 3.3.4 Pattern four: Mixture-of-Agents (MoA)\n",
    "\n",
    "Unlike parallel execution, which aims to improve efficiency, the core objective of the Mixture-of-Agents pattern is to **pursue extreme quality, robustness, and creativity**. The core concept of MoA is based on a key discovery: **different LLMs have their own unique strengths and specialties, and when one model can refer to the outputs of other models, it often generates higher quality responsesâ€”this phenomenon is called \"collaborativeness\" of models**. The MoA approach involves having multiple **different LLMs** process the **same task** simultaneously, then an aggregation model synthesizes, analyzes, and merges all outputs to produce a final result that far surpasses the capabilities of any single model.\n",
    "\n",
    "<img src=\"https://img.alicdn.com/imgextra/i2/O1CN01OkCy2A1kYMdUG2eFb_!!6000000004695-55-tps-2204-821.svg\" width=\"700\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "835ce9d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T08:15:04.730556Z",
     "iopub.status.busy": "2025-11-21T08:15:04.730326Z",
     "iopub.status.idle": "2025-11-21T08:16:05.175163Z",
     "shell.execute_reply": "2025-11-21T08:16:05.174510Z",
     "shell.execute_reply.started": "2025-11-21T08:15:04.730538Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "MoA aggregated output:\n",
      "Based on the provided answers, here is a comprehensive and high-quality synthesis of the core selling points and promotional copy for the course \"LLM Applications for Web Developers.\"\n",
      "\n",
      "### **Core Selling Points**\n",
      "\n",
      "The course is designed to bridge the gap between web development and the practical application of Large Language Models (LLMs), offering a unique value proposition for professional developers. Its key strengths are:\n",
      "\n",
      "1.  **Built Exclusively for Web Developers:** The curriculum assumes no prior AI or machine learning knowledge, making it accessible to frontend, backend, and full-stack developers. It leverages familiar tools and frameworks like JavaScript/TypeScript, Node.js, React, and Next.js, focusing on APIs and SDKs rather than complex mathematical theory or model training.\n",
      "\n",
      "2.  **Practical, Project-Based Learning:** The course moves beyond theoretical concepts to provide hands-on experience. Students will build a portfolio of 6-7 production-ready applications, such as intelligent chatbots, AI-powered search, content generators, code assistants, and automated testing tools. Each project includes critical real-world features like authentication, error handling, and deployment pipelines.\n",
      "\n",
      "3.  **Focus on Production-Ready Skills:** A major differentiator is its emphasis on the skills needed to ship LLM features in a professional environment. This includes:\n",
      "    *   **Cost Optimization:** Teaching strategies for token management, caching (e.g., with Redis), and intelligent model selection (e.g., knowing when to use GPT-4 vs. a cheaper alternative) to reduce API costs by 40-60%.\n",
      "    *   **Security & Ethics:** Providing a robust framework for preventing common vulnerabilities like prompt injection, sanitizing inputs, managing user data privacy (GDPR/CCPA compliance), and implementing abuse prevention measures.\n",
      "    *   **Performance:** Covering modern deployment on platforms like Vercel/Netlify and the use of edge computing for optimal performance.\n",
      "\n",
      "4.  **Cutting-Edge & Future-Proof Curriculum:** The course teaches in-demand, industry-relevant patterns such as Retrieval-Augmented Generation (RAG) and function calling for autonomous agents. It focuses on transferable concepts and architectural patterns that remain valuable even as specific APIs evolve.\n",
      "\n",
      "5.  **Comprehensive Support & Resources:** The offering is bolstered by extensive resources, including 40+ hours of video content, complete source code, a private community for support, and a commitment to content updates for at least one year to keep pace with this fast-moving field.\n",
      "\n",
      "---\n",
      "\n",
      "### **Promotional Copy**\n",
      "\n",
      "**Headline:**\n",
      "From Web Dev to AI Engineer: Ship Production-Ready LLM Features in 30 Days\n",
      "\n",
      "**Sub-headline:**\n",
      "The only course that teaches web developers to build secure, cost-effective, and deployable AI applicationsâ€”without needing an AI PhD.\n",
      "\n",
      "**Body Copy:**\n",
      "AI isn't comingâ€”it's already here. But most tutorials leave you with insecure, expensive toy projects that can't go to production. Itâ€™s time to move beyond the hype.\n",
      "\n",
      "In **LLM Applications for Web Developers**, youâ€™ll learn the exact strategies used by leading tech companies to integrate powerful AI into their web applications. We cut through the noise and focus on what matters: shipping real features your users will love.\n",
      "\n",
      "**You Will Learn To:**\n",
      "*   **Build & Deploy:** Create a portfolio of 6 production-grade AI applications, from smart chatbots to dynamic content engines.\n",
      "*   **Save Money:** Slash your LLM API bills by up to 60% with expert-level prompt engineering and caching techniques.\n",
      "*   **Secure Your Apps:** Implement enterprise-grade security to block prompt injection attacks and protect user data.\n",
      "*   **Make Smart Choices:** Confidently select the right model for every task, avoiding unnecessary costs.\n",
      "*   **Future-Proof Your Career:** Add in-demand AI integration skills to your resume that make you indispensable.\n",
      "\n",
      "**This course is perfect for:** React, Node.js, or full-stack developers with 2+ years of experience who are ready to lead the next wave of intelligent web applications.\n",
      "\n",
      "**Your Investment Includes:**\n",
      "*   40+ hours of hands-on video tutorials\n",
      "*   Full source code for all projects\n",
      "*   Lifetime access to a private Discord community & weekly office hours\n",
      "*   1-year guarantee of updated course content\n",
      "\n",
      "**Special Launch Offer:** The first 100 enrollees receive a \"Production Deployment Checklist\" and a 1-on-1 code review session.\n",
      "\n",
      "**Call to Action:**\n",
      "**Enroll Now â€” Start Building Your First AI-Powered Web App Today!**\n",
      "\n",
      "*Backed by a 30-day money-back guarantee. If you donâ€™t successfully build and deploy your first LLM feature, you get a full refund.*\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Pattern four: Mixture-of-Agents (MoA) - Scenario: Course core selling point extraction\n",
    "Uses three different LLMs to process the same task in parallel, and an aggregator model fuses their outputs,\n",
    "leveraging the collaborativeness between models to produce higher quality results. \"\"\"\n",
    "import asyncio\n",
    "from agentscope.message import Msg\n",
    "from agentscope.pipeline import fanout_pipeline\n",
    "from chatbot.agent import create_agent, disable_console_output\n",
    "\n",
    "async def run_moa() -> None:\n",
    "    # Use three different models as Proposers\n",
    "    # Each model has its unique strengths but processes the same task\n",
    "    proposer1 = create_agent(\n",
    "        name=\"Qwen3-Max\",\n",
    "        sys_prompt=\"You are a professional course analyst. Please extract the core selling points and promotional copy for the given course.\",\n",
    "        model_name=\"qwen3-max\",\n",
    "        multi_agent=True,\n",
    "    )\n",
    "    proposer2 = create_agent(\n",
    "        name=\"DeepSeek-V3.2\",\n",
    "        sys_prompt=\"You are a professional course analyst. Please extract the core selling points and promotional copy for the given course.\",\n",
    "        model_name=\"deepseek-v3.2-exp\",\n",
    "        multi_agent=True,\n",
    "    )\n",
    "    proposer3 = create_agent(\n",
    "        name=\"Kimi-K2\",\n",
    "        sys_prompt=\"You are a professional course analyst. Please extract the core selling points and promotional copy for the given course.\",\n",
    "        model_name=\"kimi-k2-thinking\",\n",
    "        multi_agent=True,\n",
    "    )\n",
    "\n",
    "    proposers = [proposer1, proposer2, proposer3]\n",
    "    disable_console_output(proposers)\n",
    "\n",
    "    task = (\n",
    "        \"This is a new course on 'LLM Applications for Web Developers'. Please extract its core selling points and promotional copy.\"\n",
    "    )\n",
    "    msgs = await fanout_pipeline(\n",
    "        agents=proposers,\n",
    "        msg=Msg(\"user\", task, \"user\"),\n",
    "        enable_gather=True,\n",
    "    )\n",
    "\n",
    "    # The Aggregator receives outputs from all models and synthesizes the best result\n",
    "    aggregator = create_agent(\n",
    "        name=\"Aggregator\",\n",
    "        sys_prompt=(\n",
    "            \"Your task is to synthesize the answers from multiple LLMs to the same question.\"\n",
    "            \"These answers come from different models, each with its strengths and weaknesses. Please critically evaluate these answers,\"\n",
    "            \"identify their pros and cons, and then merge this information to generate a high-quality, accurate, and comprehensive final answer.\"\n",
    "            \"Ensure your answer is clearly structured, logically coherent, and meets the highest standards of accuracy and reliability.\"\n",
    "        ),\n",
    "        model_name=\"qwen3-max\",\n",
    "        multi_agent=True,\n",
    "    )\n",
    "    disable_console_output([aggregator])\n",
    "\n",
    "    # Merge all proposers' outputs and pass to the aggregator\n",
    "    merged = \"\\n\\n\".join([\n",
    "        f\"Model {i+1}'s answer:\\n{m.content}\"\n",
    "        for i, m in enumerate(msgs)\n",
    "    ])\n",
    "    final = await aggregator(Msg(\"user\", merged, \"user\"))\n",
    "\n",
    "    print(\"=\" * 50)\n",
    "    print(\"MoA aggregated output:\")\n",
    "    print(final.content)\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "async def main() -> None:\n",
    "    await run_moa()\n",
    "\n",
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be11297",
   "metadata": {},
   "source": [
    "**How MoA works**:\n",
    "\n",
    "MoA divides participating models into two types of roles:\n",
    "\n",
    "1. **Proposers**: Multiple different models process the same task in parallel, each generating responses. These models may excel in certain aspects (e.g., logical reasoning, creative expression, factual accuracy).\n",
    "2. **Aggregator**: Receives the output from all proposers, and through critical evaluation, comparison, and merging, generates a higher-quality final response.\n",
    "\n",
    "Crucially, the aggregator does not simply choose the best answer; rather, it extracts the strengths from multiple responses to synthesize a result that surpasses any single model.\n",
    "\n",
    "**Advantages of MoA**:\n",
    "\n",
    "* **Leverages model diversity**: Different models have different training data, architectures, and optimization goals, leading to varied performance across tasks. MoA can leverage the strengths of multiple models simultaneously.\n",
    "* **Enhanced robustness**: Even if a particular model performs poorly on certain inputs, the high-quality outputs from other models ensure a minimum level of quality for the final result.\n",
    "* **Emergent quality**: Research shows that even if the individual output quality of proposer models is low, the aggregated result can still surpass any single modelâ€”this is a direct manifestation of \"model collaborativeness.\"\n",
    "\n",
    "MOA is suitable for **open-ended or creative tasks** that have no single standard answer, require extremely high-quality results, and are of significant value.\n",
    "\n",
    "* **Core copy writing**: Such as course slogans, promotional texts, brand stories.\n",
    "* **Complex decision analysis**: Synthesizing analysis reports from different models to form more comprehensive recommendations for new course directions.\n",
    "* **Code generation and optimization**: Allowing different models to generate example code, then having a review Agent select the best or perform integrated restructuring to achieve optimal teaching effects.\n",
    "\n",
    "However, the primary constraint of MOA is **cost**. Calling N expert Agents incurs N times the computational cost and corresponding latency. This is a strategy that exchanges resources for quality, and therefore must be used for critical tasks where \"the steel is used on the blade,\" not for routine, cost-sensitive daily tasks.\n",
    "\n",
    "**Advanced: Multi-layer MoA**\n",
    "\n",
    "The MoA demonstrated above is a \"2-layer structure\": the first layer has multiple experts processing tasks in parallel, and the second layer consists of an aggregator synthesizing the outputs of all experts. However, MoA can also be **extended to 3 or more layers**, continuously refining and optimizing results through multiple iterations to achieve even more outstanding output quality than a single-layer MoA.\n",
    "\n",
    "**The core idea of multi-layer MoA** is to take the aggregated output of the previous layer as input for the next layer, which is then reviewed, critiqued, and improved by multiple experts, followed by a new aggregator performing a higher level of synthesis. This \"iterative refinement\" process is similar to multiple rounds of review and polishing in human teams; each round can uncover issues missed in previous rounds and stimulate new ideas, ultimately achieving a quality level that would be difficult to reach in a single round.\n",
    "\n",
    "**Advantages of multi-layer MoA**:\n",
    "\n",
    "*   **Further quality improvement**: Experts in the second and third layers can build upon the results of the first layer, performing deeper analysis and optimization, much like an editorial team polishes a draft multiple times.\n",
    "*   **Enhanced error correction capability**: Even if some experts in the first layer make mistakes, experts in subsequent layers have the opportunity to discover and correct these errors, making the final result more reliable.\n",
    "*   **Emergence of creativity**ï¼šMulti-layered interaction may produce a \"1+1>2\" effect, where the collision of ideas among experts at different levels can spark innovative solutions that no single layer could generate on its own.\n",
    "\n",
    "**Key implementation points**:\n",
    "\n",
    "<img src=\"https://img.alicdn.com/imgextra/i4/O1CN01tZII8q26LT1vgaxcs_!!6000000007645-55-tps-2817-832.svg\" width=\"700\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2101299c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T08:19:38.338746Z",
     "iopub.status.busy": "2025-11-21T08:19:38.338524Z",
     "iopub.status.idle": "2025-11-21T08:21:54.573785Z",
     "shell.execute_reply": "2025-11-21T08:21:54.573118Z",
     "shell.execute_reply.started": "2025-11-21T08:19:38.338728Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proposer-L1-2: I understand you'd like me to extract the core selling points and promotional copy for a course on \"LLM Applications for Web Developers.\" However, I don't have access to the actual course content or materials to analyze.\n",
      "\n",
      "To provide you with the most accurate and valuable analysis, I would need:\n",
      "\n",
      "1. The course description or syllabus\n",
      "2. Course materials (videos, documents, presentations)\n",
      "3. Learning objectives and outcomes\n",
      "4. Target audience information\n",
      "5. Any existing marketing copy or promotional materials\n",
      "\n",
      "Could you please provide the course content or materials you'd like me to analyze? Once I have access to the course information, I'll be able to extract the key selling points and help you craft compelling promotional copy that highlights the course's unique value proposition for web developers interested in LLM applications.\n",
      "Proposer-L1-1: **Core Selling Points:**\n",
      "\n",
      "- **Tailored for Web Developers**: Specifically designed for web developers looking to integrate Large Language Models (LLMs) into their applications.\n",
      "- **Practical, Hands-On Learning**: Focuses on real-world use cases and implementation strategies rather than just theory.\n",
      "- **Cutting-Edge Skillset**: Equips learners with in-demand skills at the intersection of AI and web development.\n",
      "- **Project-Based Curriculum**: Includes building deployable LLM-powered features like chatbots, content generators, and smart search tools.\n",
      "- **No Deep AI Background Required**: Assumes only basic programming knowledgeâ€”no prior machine learning expertise needed.\n",
      "\n",
      "**Promotional Copy:**\n",
      "\n",
      "Unlock the power of AI in your web applications! Our new course, *LLM Applications for Web Developers*, bridges the gap between modern web development and cutting-edge language models. Learn how to seamlessly integrate LLMs into your projectsâ€”whether you're building dynamic user interfaces, intelligent customer support bots, or personalized content engines. With hands-on labs and real-world examples, youâ€™ll gain the practical skills to future-proof your career and ship smarter, AI-enhanced web appsâ€”fast. No PhD required, just your existing web dev know-how!\n",
      "Proposer-L1-3: I can help you create compelling promotional materials for \"LLM Applications for Web Developers.\" However, to extract the *most accurate* and impactful selling points, I'll need the actual course content, curriculum outline, or materials you'd like me to analyze.\n",
      "\n",
      "In the meantime, here are the **core selling points** and **promotional copy** based on best practices for a premium LLM development course:\n",
      "\n",
      "---\n",
      "\n",
      "## **Core Selling Points**\n",
      "\n",
      "### **1. Future-Proof Your Career**\n",
      "- Master the #1 in-demand skill: AI integration for web applications\n",
      "- Position yourself ahead of 90% of developers still learning basic concepts\n",
      "- Transform from \"web developer\" to \"AI-Enabled Full-Stack Engineer\"\n",
      "\n",
      "### **2. Practical, Production-Ready Skills**\n",
      "- Build 6+ real-world projects you can showcase in your portfolio\n",
      "- Learn battle-tested patterns from production AI applications\n",
      "- Avoid costly mistakes with enterprise-grade security and optimization techniques\n",
      "\n",
      "### **3. Complete Implementation Framework**\n",
      "- End-to-end integration: from API calls to scalable architecture\n",
      "- Both frontend (React/Vue) and backend (Node/Python) implementations\n",
      "- Includes RAG, fine-tuning, prompt engineering, and cost optimization\n",
      "\n",
      "### **4. Immediate ROI**\n",
      "- Start shipping AI features in your current job within 2 weeks\n",
      "- Justify the course cost by optimizing your first LLM implementation\n",
      "- Ready-to-use code templates and boilerplates save 50+ development hours\n",
      "\n",
      "---\n",
      "\n",
      "## **Promotional Copy**\n",
      "\n",
      "### **Headline:**\n",
      "**\"From Web Developer to AI Engineer: Build Intelligent Applications with LLMs in 30 Days\"**\n",
      "\n",
      "### **Sub-headline:**\n",
      "The complete, practical guide to integrating Large Language Models into production web applicationsâ€”no AI PhD required.\n",
      "\n",
      "### **Course Description:**\n",
      "Web development has evolved. Static pages and CRUD apps are table stakes. The future belongs to developers who can seamlessly weave AI intelligence into every user experience.\n",
      "\n",
      "This intensive, project-based course takes you from LLM novice to confident AI application builder. You'll master the exact techniques used by top tech companies to implement chatbots, intelligent search, content generation, and custom AI agentsâ€”while avoiding the security pitfalls, performance bottlenecks, and budget overruns that plague 80% of AI projects.\n",
      "\n",
      "**What Makes This Different:**\n",
      "- âš¡ **Immediate Application**: Every lesson includes runnable code for your portfolio\n",
      "- ğŸ›¡ï¸ **Production-First**: Security, caching, and cost controls built into every pattern\n",
      "- ğŸ¯ **Developer-Centric**: No math theoryâ€”just practical APIs, SDKs, and frameworks you already know\n",
      "- ğŸ“ˆ **Scalable Architecture**: From MVP to million-user deployments\n",
      "\n",
      "**Perfect For:**\n",
      "- Full-stack developers ready to add AI to their toolkit\n",
      "- Frontend engineers who want to build smarter user experiences\n",
      "- Technical leads evaluating LLM implementation strategies\n",
      "- Freelancers looking to command 2-3x higher rates with AI expertise\n",
      "\n",
      "**Enroll today and get instant access to:**\n",
      "- 40+ hours of video content\n",
      "- Complete source code for all projects\n",
      "- Private Discord community\n",
      "- Monthly live Q&A sessions\n",
      "- 1-year update guarantee\n",
      "\n",
      "**The AI revolution won't wait. Neither should you.**\n",
      "\n",
      "---\n",
      "\n",
      "**Please share your course materials (curriculum, videos, slides, etc.) and I'll provide a more targeted analysis with specific, data-driven selling points extracted directly from your content.**\n",
      "Aggregator-L1: Based on the conversation history, it appears you're looking to develop compelling promotional materials for a course titled \"LLM Applications for Web Developers.\" While Models 2 and 3 correctly note that they haven't been provided with specific course content to analyze, Model 1 has generated a set of core selling points and promotional copy based on the course title alone.\n",
      "\n",
      "To provide you with the most useful and comprehensive answer, I'll synthesize the best elements from the available responses, creating a robust framework that balances aspirational marketing with practical developer concerns.\n",
      "\n",
      "**Core Selling Points:**\n",
      "\n",
      "- **Designed Exclusively for Web Developers**: No prior AI/ML experience neededâ€”leverages your existing JavaScript, Python, or full-stack skills as the foundation.\n",
      "- **Immediate, Practical Application**: Learn by building real, deployable features like AI chatbots, smart search, dynamic content generators, and personalized user experiences.\n",
      "- **Production-Ready Best Practices**: Go beyond simple API calls to learn enterprise-grade patterns for security, cost optimization, error handling, and scalable architecture.\n",
      "- **Future-Proof Your Career**: Acquire the most in-demand skill at the intersection of web development and AI, transforming your role from a traditional developer to an \"AI-Enabled Engineer.\"\n",
      "- **Complete End-to-End Implementation**: Covers the entire stack, from frontend integration (React, Vue) to backend orchestration (Node.js, Python), including advanced techniques like Retrieval-Augmented Generation (RAG).\n",
      "\n",
      "**Promotional Copy:**\n",
      "\n",
      "**Headline:** Stop Watching the AI Revolutionâ€”Lead It.\n",
      "\n",
      "**Body:**\n",
      "The web is getting smarter, and the developers who thrive will be those who can seamlessly integrate AI into their applications. Our course, *LLM Applications for Web Developers*, is your fast track to becoming that developer.\n",
      "\n",
      "Forget dense theory and academic jargon. This is a hands-on, project-driven bootcamp built for practitioners. Youâ€™ll start by integrating your first LLM on day one and progressively build a portfolio of sophisticated, production-ready applications.\n",
      "\n",
      "Youâ€™ll learn the exact strategies used by leading tech companies to implement intelligent features while avoiding the common pitfalls of runaway costs, security vulnerabilities, and poor user experience.\n",
      "\n",
      "**This course is your toolkit to:**\n",
      "- **Build & Ship Fast**: Get from idea to a deployed AI feature in days, not months.\n",
      "- **Command Higher Rates**: Add a premium, in-demand skillset that justifies a significant salary or freelance rate increase.\n",
      "- **Solve Real Problems**: Move beyond toy examples to create applications that deliver tangible business value.\n",
      "\n",
      "No PhD required. Just your existing web development expertise and the drive to build the next generation of intelligent web applications.\n",
      "\n",
      "**Enroll now and transform from a web developer into an AI pioneer.**\n",
      "Proposer-L2-1: Your marketing plan is already strongâ€”it clearly speaks to web developers, emphasizes practicality, and positions the course as a career accelerator. That said, here are targeted suggestions to further sharpen messaging, boost conversion, and differentiate from competitors:\n",
      "\n",
      "**1. Strengthen the Hook with Specificity**\n",
      "- **Current headline**: â€œStop Watching the AI Revolutionâ€”Lead It.â€ (Good, but generic)\n",
      "- **Optimized alternative**: â€œShip AI Features Like a Senior Engineerâ€”Even If Youâ€™ve Never Used an LLMâ€  \n",
      "  *Why*: Itâ€™s benefit-driven, addresses imposter syndrome, and implies speed + senior-level outcomes.\n",
      "\n",
      "**2. Add Social Proof or Credibility Signals**\n",
      "Include one of the following if available:\n",
      "- â€œUsed by engineers at [Company X]â€  \n",
      "- â€œBased on patterns from production systems at top AI-native startupsâ€  \n",
      "- â€œIncludes code templates adopted by 5,000+ developers on GitHubâ€\n",
      "\n",
      "If no data exists yet, consider:  \n",
      "> â€œCreated by a former lead engineer at [FAANG/startup] who built LLM-powered features serving millions of users.â€\n",
      "\n",
      "**3. Clarify Prerequisites More Transparently**\n",
      "Instead of just â€œNo PhD required,â€ specify:\n",
      "> â€œYou should be comfortable building full-stack apps in JavaScript/Pythonâ€”but you donâ€™t need any AI, ML, or math background.â€\n",
      "\n",
      "This reduces uncertainty and increases sign-up confidence.\n",
      "\n",
      "**4. Inject Urgency or Scarcity (if applicable)**\n",
      "Examples:\n",
      "- â€œEnrollment closes Fridayâ€”next cohort starts with live Q&A sessions.â€\n",
      "- â€œFirst 100 students get access to our private â€˜AI Dev Office Hoursâ€™ community.â€\n",
      "\n",
      "**5. Reframe One Benefit Around Risk Reduction**\n",
      "Web developers fear wasted time. Add a line like:\n",
      "> â€œAvoid costly mistakes: Learn how to structure prompts, manage tokens, and secure API keysâ€”so your AI features donâ€™t blow your budget or leak user data.â€\n",
      "\n",
      "**6. Optimize the Bullet List for Skimmability**\n",
      "Use action-oriented subheads:\n",
      "- ğŸš€ **Go from zero to deployed AI feature in 48 hours**  \n",
      "- ğŸ’° **Justify a $20K+ salary bump with in-demand LLM integration skills**  \n",
      "- ğŸ”’ **Implement enterprise-grade security & cost controls from day one**\n",
      "\n",
      "**7. Consider a Short, High-Impact Tagline for Ads/Landing Pages**\n",
      "Examples:\n",
      "- â€œThe Web Developerâ€™s Shortcut to Building with AIâ€  \n",
      "- â€œLLMs for Buildersâ€”Not Theoristsâ€\n",
      "\n",
      "**Final Tweaked Headline + Subhead Combo:**\n",
      "> **Build Smarter Web Appsâ€”Without Becoming an AI Expert**  \n",
      "> *A hands-on course that teaches web developers to ship secure, scalable LLM features using the tools they already know.*\n",
      "\n",
      "These refinements maintain your core message while increasing clarity, credibility, and emotional resonanceâ€”key drivers for developer audiences who value efficiency, proof, and ROI.\n",
      "Proposer-L2-2: Excellent marketing plan! The existing framework is strong, but here are some specific optimizations and improvements to make it even more compelling:\n",
      "\n",
      "## ENHANCED CORE SELLING POINTS:\n",
      "\n",
      "**1. \"From Code to AI: Your Web Dev Skills Are Your Superpower\"**\n",
      "- Emphasize that students aren't starting from scratch - their existing skills are the foundation\n",
      "- Add: \"Leverage your React, Node.js, or Python expertise as the launchpad for AI mastery\"\n",
      "\n",
      "**2. \"Build 5 Real-World Projects Portfolio-Ready\"**\n",
      "- Make the deliverables more concrete: AI-powered customer support chatbot, intelligent content recommendation engine, automated documentation generator, smart search with semantic understanding, and dynamic content personalization system\n",
      "\n",
      "**3. \"Production-Ready Code, Not Just Demos\"**\n",
      "- Expand on enterprise patterns: rate limiting, caching strategies, monitoring, A/B testing AI features, and deployment pipelines\n",
      "- Add specific metrics: \"Learn to build systems that handle 10,000+ requests/hour while keeping API costs under $50/month\"\n",
      "\n",
      "## OPTIMIZED PROMOTIONAL COPY:\n",
      "\n",
      "**Headline Options:**\n",
      "- \"The AI-Powered Web Developer: Build What Others Only Imagine\"\n",
      "- \"Web Development 2.0: Add AI to Your Stack, Multiply Your Value\"\n",
      "- \"Stop Coding Websites. Start Building Intelligent Applications.\"\n",
      "\n",
      "**Body Enhancements:**\n",
      "\n",
      "**Pain Point Focus:**\n",
      "\"Every day, your clients and employers are asking for AI features they saw on Twitter. They want ChatGPT-style interfaces, personalized recommendations, and intelligent automation. But most web developers hit the same walls: confusing documentation, unpredictable costs, and security nightmares.\n",
      "\n",
      "This course is your blueprint to confidently say 'Yes, we can build that' - and deliver.\"\n",
      "\n",
      "**Social Proof Elements:**\n",
      "- Add testimonials or hypothetical success metrics: \"Join 2,500+ developers who've added $20K+ to their annual income\"\n",
      "- Include specific company examples: \"Learn the patterns used by companies like [mention relevant tech companies]\"\n",
      "\n",
      "**Scarcity & Urgency:**\n",
      "- \"The AI developer gap is real - companies are paying 30-50% premiums for these skills RIGHT NOW\"\n",
      "- \"Early enrollment includes [bonus: deployment templates, API cost calculator, interview prep guide]\"\n",
      "\n",
      "## ADDITIONAL MARKETING ELEMENTS:\n",
      "\n",
      "**Visual Storytelling:**\n",
      "- Before/After comparison: \"From basic CRUD apps â†’ AI-powered intelligent platforms\"\n",
      "- Career progression timeline showing salary increases at 3, 6, and 12 months post-course\n",
      "\n",
      "**Risk Reversal:**\n",
      "- \"30-day money-back guarantee - if you don't build and deploy at least 2 AI features, we'll refund your investment\"\n",
      "- \"Lifetime access to course updates as AI technology evolves\"\n",
      "\n",
      "**Specific Technical Differentiators:**\n",
      "- \"We teach the exact prompting techniques that reduce API costs by 60% while improving output quality\"\n",
      "- \"Master RAG implementation that makes your AI 3x more accurate than basic API calls\"\n",
      "\n",
      "## CALL-TO-ACTION OPTIMIZATION:\n",
      "\n",
      "**Primary CTA:** \"Reserve Your Spot - Next Cohort Starts [Date]\"\n",
      "**Secondary CTA:** \"Download Free Sample: Build Your First AI Chatbot in 45 Minutes\"\n",
      "\n",
      "Would you like me to elaborate on any of these improvements or help you develop specific sections further?\n",
      "Proposer-L2-3: Here's an optimized version of your marketing plan with specific improvements and additions:\n",
      "\n",
      "---\n",
      "\n",
      "### **OPTIMIZED CORE SELLING POINTS**\n",
      "\n",
      "**1. Specific Skill Transformation (Not Just \"Learn AI\")**\n",
      "- **Master the 4 Core LLM Integration Patterns**: Chat Interfaces, Retrieval-Augmented Generation, Function Calling/API Orchestration, and Multi-Agent Workflowsâ€”each built as production-ready npm packages you can reuse\n",
      "- **Build a Deployable AI SaaS Boilerplate**: Not toy examples. You'll create a complete starter kit with auth, rate limiting, cost tracking, and monitoring that you can use for client projects immediately\n",
      "\n",
      "**2. Concrete Technical Outcomes**\n",
      "- **Frontend**: Implement streaming responses, conversation history, and token-efficient prompt engineering in React/Vue with performance budgets under 200ms\n",
      "- **Backend**: Design robust API layers with circuit breakers, retry logic, and provider failover (OpenAI â†’ Anthropic â†’ self-hosted) using Node.js/Python patterns that scale to 10k+ users\n",
      "- **DevOps**: Deploy with Docker configurations that keep LLM costs under $0.01/user/day and monitoring dashboards to track spend in real-time\n",
      "\n",
      "**3. Risk Mitigation & Production Readiness**\n",
      "- **Security**: Implement PII detection, prompt injection guards, and rate limiting patterns that prevent the $10K API bill horror stories\n",
      "- **Cost Architecture**: Master token optimization (saving 40-60% on API costs), caching strategies, and model selection frameworks that use GPT-4 only when necessary\n",
      "- **Error Resilience**: Build fallback chains and graceful degradation so your app works even when OpenAI is down\n",
      "\n",
      "**4. Career Differentiation**\n",
      "- **Positioning Shift**: Move from \"developer who uses AI\" to \"AI Systems Architect\"â€”the role senior engineers are being promoted into (average salary premium: +$45K)\n",
      "- **Portfolio Engineering**: Complete 3 client-ready projects: an AI support chatbot (RAG), a dynamic content generator (function calling), and an AI-powered code review tool (agents)\n",
      "\n",
      "---\n",
      "\n",
      "### **OPTIMIZED PROMOTIONAL COPY**\n",
      "\n",
      "**Headline:** Your Web Dev Skills Just Became 3x More Valuable. Here's the Fastest Path to AI Systems Architect.\n",
      "\n",
      "**Sub-headline:** 87% of tech leads say \"LLM integration experience\" is their #1 hiring priority for 2024. This is the production-grade playbook they expect you to know.\n",
      "\n",
      "**Body:**\n",
      "\n",
      "The AI gold rush is hereâ€”but most developers are stuck in tutorial hell, building demos that would never survive production.\n",
      "\n",
      "**This is not another \"chat with PDF\" course.**\n",
      "\n",
      "*LLM Applications for Web Developers* is a battle-tested implementation framework taught by [Instructor Name], former Staff Engineer at [Company] who scaled AI features to 2M+ users. In 6 weeks, you'll build the exact infrastructure stack that companies like Vercel, Stripe, and Notion use to deploy AI features.\n",
      "\n",
      "**What You'll Actually Build (And Deploy):**\n",
      "\n",
      "1. **Week 1-2: AI Support Agent** - A RAG-powered chatbot with hybrid search (vector + keyword), conversation memory, and cost-aware routing that reduces support tickets by 60%\n",
      "2. **Week 3-4: Dynamic Content Engine** - A function-calling system that generates personalized marketing copy, abiding by brand guidelines and integrating with your CMS via webhooks\n",
      "3. **Week 5-6: AI Code Reviewer** - A multi-agent workflow that analyzes PRs, suggests optimizations, and auto-generates testsâ€”reducing review time by 4 hours/week\n",
      "\n",
      "**Each project includes:**\n",
      "- Production Docker configs with auto-scaling\n",
      "- OpenTelemetry tracing for LLM calls\n",
      "- A/B testing framework for model comparison\n",
      "- Pre-built Terraform modules for cloud deployment\n",
      "\n",
      "**The \"No Surprises\" Guarantee:**\n",
      "- **Cost Transparency**: Every module includes a running cost calculator. You'll never be surprised by an API bill.\n",
      "- **Future-Proof**: Course updates monthly as models evolve. Your purchase includes lifetime access.\n",
      "- **Skills Guarantee**: Complete the projects and if you can't implement a production LLM feature in 30 days, get a full refund.\n",
      "\n",
      "**Who This Is For:**\n",
      "âœ“ Senior web developers (3+ years) ready to lead AI initiatives  \n",
      "âœ“ Tech leads who need to evaluate LLM architecture decisions  \n",
      "âœ“ Freelancers who want to add $5K-$15K per project for AI features\n",
      "\n",
      "**Not for:** Beginners or those looking for basic API call tutorials.\n",
      "\n",
      "**Enrollment Closes:** [Specific Date] - Cohort limited to 50 students for 1:1 code review support\n",
      "\n",
      "**CTA Button:** \"Join the Waitlist - Get the Production Checklist Instantly\"  \n",
      "*Capture emails with a free \"LLM Production Readiness Audit\" PDF*\n",
      "\n",
      "---\n",
      "\n",
      "### **KEY IMPROVEMENTS MADE:**\n",
      "\n",
      "1. **Specificity**: Replaced vague promises with concrete projects, metrics, and tools\n",
      "2. **Authority**: Added instructor credentials and real-world scale examples\n",
      "3. **Risk Reversal**: Added cost transparency and a skills guarantee\n",
      "4. **Urgency/Scarcity**: Limited cohort size and enrollment deadline\n",
      "5. **Differentiation**: Clearly separated from \"tutorial\" courses\n",
      "6. **Technical Depth**: Included specific architectures (OpenTelemetry, Terraform, circuit breakers)\n",
      "7. **Lead Magnet**: Suggested a valuable freebie to capture emails\n",
      "8. **Objection Handling**: Addressed cost fears, skill level concerns, and future-proofing directly\n",
      "\n",
      "Would you like me to expand on any specific section or create additional materials (email sequence, landing page wireframe, ad copy)?\n",
      "Final-Aggregator: Your marketing plan is already compelling, but integrating the strongest elements from each modelâ€™s feedback can significantly sharpen its impact. Below is a refined, comprehensive strategy that blends specificity, credibility, urgency, and technical depthâ€”tailored specifically for web developers who value practicality, ROI, and production readiness.\n",
      "\n",
      "---\n",
      "\n",
      "### **Refined Core Messaging**\n",
      "\n",
      "**Headline (Primary):**  \n",
      "**â€œShip Production-Ready AI Featuresâ€”Without Becoming an AI Expertâ€**\n",
      "\n",
      "**Sub-headline:**  \n",
      "*Web developers: Leverage your existing JavaScript/Python skills to build secure, scalable LLM applications that clients and employers are urgently demanding.*\n",
      "\n",
      "**Alternative Headlines for A/B Testing or Ads:**\n",
      "- â€œFrom CRUD Apps to AI Architect: Multiply Your Value in 6 Weeksâ€\n",
      "- â€œThe Web Developerâ€™s Shortcut to Building What Others Only Demoâ€\n",
      "- â€œStop Watching AI Tutorials. Start Shipping Revenue-Generating Features.â€\n",
      "\n",
      "---\n",
      "\n",
      "### **Enhanced Selling Points**\n",
      "\n",
      "1. **Leverage Existing Skills as a Superpower**  \n",
      "   Emphasize that students arenâ€™t starting from zeroâ€”theyâ€™re upgrading their full-stack expertise with AI integration patterns used at companies like Vercel, Notion, and Stripe.\n",
      "\n",
      "2. **Build 3 Portfolio-Ready, Deployable Projects**  \n",
      "   - **AI Support Chatbot**: RAG-powered with hybrid search, conversation memory, and cost-aware routing (reduces tickets by ~60%)  \n",
      "   - **Dynamic Content Engine**: Function-calling system that generates brand-compliant copy and integrates with CMS via webhooks  \n",
      "   - **AI Code Reviewer**: Multi-agent workflow that analyzes PRs, suggests optimizations, and auto-generates tests (saves ~4 hrs/week)\n",
      "\n",
      "3. **Production-Grade Engineering Focus**  \n",
      "   Teach real-world infrastructure:  \n",
      "   - Rate limiting, PII detection, and prompt injection guards  \n",
      "   - Token optimization (40â€“60% API cost savings)  \n",
      "   - Fallback chains and provider failover (OpenAI â†’ Anthropic â†’ self-hosted)  \n",
      "   - Docker + Terraform templates for one-click deployment  \n",
      "   - OpenTelemetry tracing and real-time cost dashboards\n",
      "\n",
      "4. **Career & Financial Upside**  \n",
      "   - Position graduates as â€œAI Systems Architectsâ€â€”a role commanding **$45K+ salary premiums**  \n",
      "   - Freelancers can add **$5Kâ€“$15K per project** for AI features  \n",
      "   - â€œ87% of tech leads rank â€˜LLM integration experienceâ€™ as their #1 hiring priority in 2024â€\n",
      "\n",
      "---\n",
      "\n",
      "### **Credibility & Social Proof**\n",
      "\n",
      "- **Instructor Authority**: â€œCreated by a former Staff Engineer at [FAANG/startup] who scaled AI features to 2M+ usersâ€  \n",
      "- **Adoption Metrics**: â€œCode patterns used by 5,000+ developers on GitHubâ€ or â€œBased on production systems at top AI-native startupsâ€  \n",
      "- **Guarantee**: â€œComplete the projects and deploy two AI featuresâ€”or get a full refundâ€\n",
      "\n",
      "---\n",
      "\n",
      "### **Risk Reversal & Objection Handling**\n",
      "\n",
      "- **Prerequisites Clarified**: â€œYou should be comfortable building full-stack apps in JavaScript/Pythonâ€”but no AI, ML, or math background needed.â€  \n",
      "- **Cost Transparency**: Every module includes a live API cost calculatorâ€”no surprise bills.  \n",
      "- **Future-Proofing**: Lifetime access with monthly updates as models and best practices evolve.\n",
      "\n",
      "---\n",
      "\n",
      "### **Urgency, Scarcity & Conversion Optimization**\n",
      "\n",
      "- **Limited Cohort**: â€œOnly 50 spotsâ€”includes 1:1 code reviews and live Q&Aâ€  \n",
      "- **Deadline**: â€œEnrollment closes Fridayâ€  \n",
      "- **Bonus for Early Signups**: â€œFirst 100 students get our private â€˜AI Dev Office Hoursâ€™ community + deployment checklistâ€  \n",
      "- **Lead Magnet**: Offer a free â€œLLM Production Readiness Auditâ€ PDF in exchange for email signups\n",
      "\n",
      "---\n",
      "\n",
      "### **Call-to-Action (CTA) Strategy**\n",
      "\n",
      "- **Primary CTA**: â€œReserve Your Spot â€“ Next Cohort Starts [Date]â€  \n",
      "- **Secondary CTA**: â€œDownload Free Sample: Build Your First AI Chatbot in 45 Minutesâ€  \n",
      "- **Landing Page Hook**: â€œThis is not another â€˜chat with PDFâ€™ course. This is the production-grade playbook senior engineers use.â€\n",
      "\n",
      "---\n",
      "\n",
      "This integrated approach maintains your original focus on practicality while adding concrete outcomes, technical depth, and emotional triggers (FOMO, fear of obsolescence, desire for career leverage). It speaks directly to experienced web developers who want to shipâ€”not just learnâ€”and positions your course as the definitive bridge between traditional web development and modern AI engineering.\n",
      "Multi-layer MoA final output:\n",
      "Your marketing plan is already compelling, but integrating the strongest elements from each modelâ€™s feedback can significantly sharpen its impact. Below is a refined, comprehensive strategy that blends specificity, credibility, urgency, and technical depthâ€”tailored specifically for web developers who value practicality, ROI, and production readiness.\n",
      "\n",
      "---\n",
      "\n",
      "### **Refined Core Messaging**\n",
      "\n",
      "**Headline (Primary):**  \n",
      "**â€œShip Production-Ready AI Featuresâ€”Without Becoming an AI Expertâ€**\n",
      "\n",
      "**Sub-headline:**  \n",
      "*Web developers: Leverage your existing JavaScript/Python skills to build secure, scalable LLM applications that clients and employers are urgently demanding.*\n",
      "\n",
      "**Alternative Headlines for A/B Testing or Ads:**\n",
      "- â€œFrom CRUD Apps to AI Architect: Multiply Your Value in 6 Weeksâ€\n",
      "- â€œThe Web Developerâ€™s Shortcut to Building What Others Only Demoâ€\n",
      "- â€œStop Watching AI Tutorials. Start Shipping Revenue-Generating Features.â€\n",
      "\n",
      "---\n",
      "\n",
      "### **Enhanced Selling Points**\n",
      "\n",
      "1. **Leverage Existing Skills as a Superpower**  \n",
      "   Emphasize that students arenâ€™t starting from zeroâ€”theyâ€™re upgrading their full-stack expertise with AI integration patterns used at companies like Vercel, Notion, and Stripe.\n",
      "\n",
      "2. **Build 3 Portfolio-Ready, Deployable Projects**  \n",
      "   - **AI Support Chatbot**: RAG-powered with hybrid search, conversation memory, and cost-aware routing (reduces tickets by ~60%)  \n",
      "   - **Dynamic Content Engine**: Function-calling system that generates brand-compliant copy and integrates with CMS via webhooks  \n",
      "   - **AI Code Reviewer**: Multi-agent workflow that analyzes PRs, suggests optimizations, and auto-generates tests (saves ~4 hrs/week)\n",
      "\n",
      "3. **Production-Grade Engineering Focus**  \n",
      "   Teach real-world infrastructure:  \n",
      "   - Rate limiting, PII detection, and prompt injection guards  \n",
      "   - Token optimization (40â€“60% API cost savings)  \n",
      "   - Fallback chains and provider failover (OpenAI â†’ Anthropic â†’ self-hosted)  \n",
      "   - Docker + Terraform templates for one-click deployment  \n",
      "   - OpenTelemetry tracing and real-time cost dashboards\n",
      "\n",
      "4. **Career & Financial Upside**  \n",
      "   - Position graduates as â€œAI Systems Architectsâ€â€”a role commanding **$45K+ salary premiums**  \n",
      "   - Freelancers can add **$5Kâ€“$15K per project** for AI features  \n",
      "   - â€œ87% of tech leads rank â€˜LLM integration experienceâ€™ as their #1 hiring priority in 2024â€\n",
      "\n",
      "---\n",
      "\n",
      "### **Credibility & Social Proof**\n",
      "\n",
      "- **Instructor Authority**: â€œCreated by a former Staff Engineer at [FAANG/startup] who scaled AI features to 2M+ usersâ€  \n",
      "- **Adoption Metrics**: â€œCode patterns used by 5,000+ developers on GitHubâ€ or â€œBased on production systems at top AI-native startupsâ€  \n",
      "- **Guarantee**: â€œComplete the projects and deploy two AI featuresâ€”or get a full refundâ€\n",
      "\n",
      "---\n",
      "\n",
      "### **Risk Reversal & Objection Handling**\n",
      "\n",
      "- **Prerequisites Clarified**: â€œYou should be comfortable building full-stack apps in JavaScript/Pythonâ€”but no AI, ML, or math background needed.â€  \n",
      "- **Cost Transparency**: Every module includes a live API cost calculatorâ€”no surprise bills.  \n",
      "- **Future-Proofing**: Lifetime access with monthly updates as models and best practices evolve.\n",
      "\n",
      "---\n",
      "\n",
      "### **Urgency, Scarcity & Conversion Optimization**\n",
      "\n",
      "- **Limited Cohort**: â€œOnly 50 spotsâ€”includes 1:1 code reviews and live Q&Aâ€  \n",
      "- **Deadline**: â€œEnrollment closes Fridayâ€  \n",
      "- **Bonus for Early Signups**: â€œFirst 100 students get our private â€˜AI Dev Office Hoursâ€™ community + deployment checklistâ€  \n",
      "- **Lead Magnet**: Offer a free â€œLLM Production Readiness Auditâ€ PDF in exchange for email signups\n",
      "\n",
      "---\n",
      "\n",
      "### **Call-to-Action (CTA) Strategy**\n",
      "\n",
      "- **Primary CTA**: â€œReserve Your Spot â€“ Next Cohort Starts [Date]â€  \n",
      "- **Secondary CTA**: â€œDownload Free Sample: Build Your First AI Chatbot in 45 Minutesâ€  \n",
      "- **Landing Page Hook**: â€œThis is not another â€˜chat with PDFâ€™ course. This is the production-grade playbook senior engineers use.â€\n",
      "\n",
      "---\n",
      "\n",
      "This integrated approach maintains your original focus on practicality while adding concrete outcomes, technical depth, and emotional triggers (FOMO, fear of obsolescence, desire for career leverage). It speaks directly to experienced web developers who want to shipâ€”not just learnâ€”and positions your course as the definitive bridge between traditional web development and modern AI engineering.\n"
     ]
    }
   ],
   "source": [
    "async def run_multi_layer_moa() -> None:\n",
    "    \"\"\"\n",
    "    Multi-layer MoA example: 3-layer architecture for refining course marketing plans\n",
    "    Layer 1: 3 different models act as proposers to generate plans in parallel\n",
    "    Layer 2: 3 different models optimize and improve the aggregated output from Layer 1\n",
    "    Layer 3: The final aggregator synthesizes all information to output the best plan\n",
    "    \"\"\"\n",
    "    # General aggregation prompt\n",
    "    aggregate_prompt = (\n",
    "        \"Your task is to synthesize the answers from multiple LLMs to the same question.\"\n",
    "        \"Please critically evaluate these answers, identify their pros and cons,\"\n",
    "        \"then merge this information to generate a high-quality, accurate, and comprehensive final answer.\"\n",
    "    )\n",
    "\n",
    "    # Layer 1: Initial proposer layer (3 different models)\n",
    "    layer1_proposers = [\n",
    "        create_agent(\n",
    "            name=\"Proposer-L1-1\",\n",
    "            sys_prompt=\"You are a professional course analyst. Please extract the core selling points and promotional copy for the given course.\",\n",
    "            model_name=\"qwen3-max\",\n",
    "            multi_agent=True\n",
    "        ),\n",
    "        create_agent(\n",
    "            name=\"Proposer-L1-2\",\n",
    "            sys_prompt=\"You are a professional course analyst. Please extract the core selling points and promotional copy for the given course.\",\n",
    "            model_name=\"deepseek-v3.2-exp\",\n",
    "            multi_agent=True\n",
    "        ),\n",
    "        create_agent(\n",
    "            name=\"Proposer-L1-3\",\n",
    "            sys_prompt=\"You are a professional course analyst. Please extract the core selling points and promotional copy for the given course.\",\n",
    "            model_name=\"kimi-k2-thinking\",\n",
    "            multi_agent=True\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    task = \"This is a new course on 'LLM Applications for Web Developers'. Please extract its core selling points and promotional copy.\"\n",
    "    layer1_outputs = await fanout_pipeline(\n",
    "        agents=layer1_proposers,\n",
    "        msg=Msg(\"user\", task, \"user\"),\n",
    "        enable_gather=True,\n",
    "    )\n",
    "\n",
    "    # Layer 1 Aggregator\n",
    "    layer1_aggregator = create_agent(\n",
    "        name=\"Aggregator-L1\",\n",
    "        sys_prompt=aggregate_prompt,\n",
    "        model_name=\"qwen3-max\",\n",
    "        multi_agent=True,\n",
    "    )\n",
    "    layer1_merged = \"\\n\\n\".join([f\"Model {i+1}:\\n{m.content}\" for i, m in enumerate(layer1_outputs)])\n",
    "    layer1_result = await layer1_aggregator(Msg(\"user\", layer1_merged, \"user\"))\n",
    "\n",
    "    # Layer 2: Second round proposer layer (3 different models, optimizing based on aggregated result from Layer 1)\n",
    "    layer2_proposers = [\n",
    "        create_agent(\n",
    "            name=\"Proposer-L2-1\",\n",
    "            sys_prompt=\"You are a professional course analyst. Please review the given marketing plan and suggest improvements or optimized versions.\",\n",
    "            model_name=\"qwen3-max\",\n",
    "            multi_agent=True\n",
    "        ),\n",
    "        create_agent(\n",
    "            name=\"Proposer-L2-2\",\n",
    "            sys_prompt=\"You are a professional course analyst. Please review the given marketing plan and suggest improvements or optimized versions.\",\n",
    "            model_name=\"deepseek-v3.2-exp\",\n",
    "            multi_agent=True\n",
    "        ),\n",
    "        create_agent(\n",
    "            name=\"Proposer-L2-3\",\n",
    "            sys_prompt=\"You are a professional course analyst. Please review the given marketing plan and suggest improvements or optimized versions.\",\n",
    "            model_name=\"kimi-k2-thinking\",\n",
    "            multi_agent=True\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    layer2_prompt = f\"Here is the marketing plan generated from the first round of analysis:\\n\\n{layer1_result.content}\\n\\nBased on this, please provide suggestions for improvement or optimized versions.\"\n",
    "    layer2_outputs = await fanout_pipeline(\n",
    "        agents=layer2_proposers,\n",
    "        msg=Msg(\"user\", layer2_prompt, \"user\"),\n",
    "        enable_gather=True,\n",
    "    )\n",
    "\n",
    "    # Layer 3: Final aggregation layer\n",
    "    final_aggregator = create_agent(\n",
    "        name=\"Final-Aggregator\",\n",
    "        sys_prompt=aggregate_prompt,\n",
    "        model_name=\"qwen3-max\",\n",
    "        multi_agent=True,\n",
    "    )\n",
    "\n",
    "    layer2_merged = \"\\n\\n\".join([f\"Model {i+1}:\\n{m.content}\" for i, m in enumerate(layer2_outputs)])\n",
    "    final_output = await final_aggregator(Msg(\"user\", layer2_merged, \"user\"))\n",
    "\n",
    "    print(\"Multi-layer MoA final output:\")\n",
    "    print(final_output.content)\n",
    "\n",
    "await run_multi_layer_moa()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcaa6af",
   "metadata": {},
   "source": [
    "**When to use multi-layer MoA**ï¼š\n",
    "\n",
    "*   **Extremely high-value tasks**: Such as annual company strategic reports, important product launch texts, core curriculum system design. The success or failure of these tasks can directly impact business results, making them worth investing more resources.\n",
    "*   **Extremely high creative requirements**: Such as brand story creation, innovative teaching method design, scenarios that require multiple rounds of idea generation to spark the best creativity.\n",
    "*   **Extremely high fault tolerance requirements**: Such as legal documents, technical white papers, where any error could lead to severe consequences, requiring multi-layer review to ensure accuracy.\n",
    "\n",
    "**Cost trade-offs**ï¼š\n",
    "\n",
    "The cost of multi-layer MoA increases linearly with the number of layers. Taking the 3-layer architecture above as an example: 3 proposer models + 1 aggregator per layer means at least (3+1) + (3+1) + 1 = 9 model calls, which is more than double the cost of a single layer's 3+1=4 calls. Therefore, multi-layer MoA should only be considered when the value of the task significantly outweighs the cost, and not for routine, cost-sensitive daily tasks.\n",
    "\n",
    "You can balance cost and quality with the following strategies:\n",
    "*   **Reduce the number of proposers**: Use 3-4 different models in the first layer for diversity, and then reduce to 2-3 models for refinement in subsequent layers.\n",
    "*   **Reduce the number of layers**: For most tasks, 2-layer MoA (proposer layer + aggregation layer) can already provide significant quality improvement. 3 or more layers are usually only worth using for extremely high-value tasks.\n",
    "*   **Hybrid model configuration**: Mix models of different performance and costs among the proposers, and use the highest quality model for the aggregator to ensure the final output quality.\n",
    "\n",
    "> **Further reading: Cost optimization and resource management for workflows**\n",
    ">\n",
    "> You've already realized that advanced patterns like Mixture-of-Agents (MoA) can significantly increase costs. This raises a crucial question that must be addressed before any workflow is put into production: how to manage resources and optimize costs? Fortunately, you can significantly reduce the operational costs of workflows without sacrificing too much quality by implementing a series of sophisticated engineering strategies.\n",
    ">\n",
    "> *   **Differentiated model allocation**: Different nodes in a workflow can vary greatly in task complexity and importance. You can assign lightweight, inexpensive models to simple tasks (e.g., intent recognition, format conversion) and reserve expensive, advanced models only for the most critical core tasks (e.g., final decision-making, content generation). Research shows that with reasonable optimization strategies, companies can save 40-70% of token costs depending on the specific implementation.\n",
    "> *   **Systematic caching**: By carefully observing your workflow, you will find that many node computations are repeatable. For example, retrieving the same company style guide, parsing the same course review request, etc. By adding caching mechanisms to these nodes, you can store intermediate results. When the same input is encountered next time, the system can directly return the cached result, completely bypassing model calls, thereby greatly reducing costs and latency.\n",
    "> *   **Smart batching**: Not all tasks require an immediate response. For non-real-time tasks like course quality report generation or user feedback analysis, you can design workflows to intelligently aggregate a batch of similar requests, then process them in a \"batch\" with a single model call, instead of calling the model separately for each request. This finds a better balance between cost and response time.\n",
    "\n",
    "#### 3.3.5 Pattern five: Human-in-the-loop (HITL)\n",
    "\n",
    "So far, all the workflows you've designed are fully automated. However, in the real world, fully entrusting all decision-making power to AI carries risks, especially when dealing with ambiguous teaching concepts or high-value course content. The Human-in-the-Loop pattern no longer pursues complete automation; instead, it intentionally designs one or more \"pause points\" in the workflow, handing control back to humans for decision-making, approval, or quality control, before returning the task to the workflow to continue execution. This is a critical pattern for building trustworthy and secure AI systems.\n",
    "\n",
    "<img src=\"https://img.alicdn.com/imgextra/i2/O1CN01cFnMzE1yf97W0GHAO_!!6000000006605-55-tps-2111-413.svg\" width=\"700\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d850f8ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T08:23:43.873823Z",
     "iopub.status.busy": "2025-11-24T08:23:43.873594Z",
     "iopub.status.idle": "2025-11-24T08:23:53.143191Z",
     "shell.execute_reply": "2025-11-24T08:23:53.142595Z",
     "shell.execute_reply.started": "2025-11-24T08:23:43.873805Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI suggestion is as follows:\n",
      "\n",
      "One concept that might be difficult for beginners to understand is how decorators in Python can modify or extend the behavior of functions without changing their code. A more accessible explanation could be: \n",
      "\n",
      "\"Think of a decorator like a gift wrapper. You have a gift (a function), and the wrapper (the decorator) adds something extraâ€”like a bow or ribbonâ€”without changing what's inside. In programming, the decorator adds new features to a function, like logging or timing, while keeping the original function intact. When you use a decorator, you're saying, 'Take this function and wrap it with some extra functionality before I use it.'\"\n",
      "\n",
      "This analogy makes it easier for beginners to visualize the purpose and mechanics of decorators.\n",
      "==================================================\n",
      "HITL final output:\n",
      "In Python, a decorator can be thought of as a gift wrapper. Just like how you have a gift (a function) and the wrapper (the decorator) adds an additional layerâ€”such as a bow or ribbonâ€”without altering what's inside, in programming, the decorator adds new capabilities to a function, such as logging or timing, while preserving the original function. When you apply a decorator, you're essentially saying, 'Take this function and enhance it with some extra functionality before I use it.' This analogy helps beginners to better understand and visualize the role and operation of decorators.\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Pattern five: Human-in-the-Loop (HITL) - Scenario: Course difficult point review (Human as a Tool)\n",
    "AI first provides modification suggestions for a potentially difficult point in the course; then a rewriter Agent equipped with a \"human consultation\" tool autonomously decides when to call this tool to consult a human, and finally completes the modification. \"\"\"\n",
    "import asyncio\n",
    "import os\n",
    "from agentscope.agent import ReActAgent, UserAgent\n",
    "from agentscope.message import Msg, TextBlock\n",
    "from agentscope.model import DashScopeChatModel\n",
    "from agentscope.formatter import DashScopeMultiAgentFormatter\n",
    "from agentscope.tool import Toolkit, ToolResponse\n",
    "from chatbot.agent import create_agent, disable_console_output\n",
    "\n",
    "# Encapsulate human intervention as a tool: ask_human_decision\n",
    "async def ask_human_decision(question: str) -> ToolResponse:\n",
    "    \"\"\"Asks a human expert for a decision or opinion.\n",
    "\n",
    "    Args:\n",
    "        question (str): The specific question to ask the human for confirmation or supplementation.\n",
    "    \"\"\"\n",
    "    human_expert = UserAgent(name=\"Teaching Expert\")\n",
    "    reply = await human_expert(\n",
    "        Msg(\n",
    "            \"assistant\",\n",
    "            question,\n",
    "            \"assistant\",\n",
    "        )\n",
    "    )\n",
    "    return ToolResponse(\n",
    "        content=[\n",
    "            TextBlock(type=\"text\", text=reply.get_text_content()),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "async def run_hitl() -> None:\n",
    "    # AI: provides modification suggestions\n",
    "    suggester = create_agent(\n",
    "        name=\"Difficult Point Analyst\",\n",
    "        sys_prompt=(\n",
    "            \"You are a senior teaching designer. Please identify the concept in the course that might be most difficult for beginners to understand,\"\n",
    "            \"and provide a more accessible explanation as a modification suggestion.\"\n",
    "        ),\n",
    "        model_name=\"qwen-plus\",\n",
    "        multi_agent=True,\n",
    "    )\n",
    "    disable_console_output([suggester])\n",
    "\n",
    "    course_content = \"In Python, a decorator is essentially a function that takes a function as an argument and returns a new function...\"\n",
    "    suggestion = await suggester(Msg(\"user\", course_content, \"user\"))\n",
    "\n",
    "    print(\"AI suggestion is as follows:\\n\")\n",
    "    print(suggestion.content)\n",
    "\n",
    "    # Hand the \"human intervention\" as a tool to the rewriter Agent, which autonomously decides whether to call it\n",
    "    toolkit = Toolkit()\n",
    "    toolkit.register_tool_function(ask_human_decision)\n",
    "\n",
    "    rewriter = ReActAgent(\n",
    "        name=\"Content Rewriter\",\n",
    "        sys_prompt=(\n",
    "            \"You are a course content rewriter. Complete the final modification based on the AI suggestion provided.\\n\"\n",
    "            \"- If you are confident, please complete the modification directly and provide confirmation;\\n\"\n",
    "            \"- If there is uncertainty, ambiguity, or high risk, please call the ask_human_decision tool to consult a human expert first,\"\n",
    "            \"then complete the modification based on their input;\\n\"\n",
    "            \"- Briefly explain in the final result whether a human was consulted and why.\"\n",
    "        ),\n",
    "        model=DashScopeChatModel(\n",
    "            model_name=\"qwen-max\",\n",
    "            api_key=os.environ.get(\"DASHSCOPE_API_KEY\", \"your-api-key\"),\n",
    "            stream=False,\n",
    "        ),\n",
    "        formatter=DashScopeMultiAgentFormatter(),\n",
    "        toolkit=toolkit,\n",
    "    )\n",
    "    disable_console_output([rewriter])\n",
    "\n",
    "    # Provide course content and AI suggestion together to the rewriter Agent\n",
    "    task = (\n",
    "        \"Below is a course excerpt and AI's modification suggestion. Complete the final modification based on the system prompt:\\n\\n\"\n",
    "        f\"[Course Content]\\n{course_content}\\n\\n\"\n",
    "        f\"[AI Suggestion]\\n{suggestion.get_text_content()}\\n\"\n",
    "    )\n",
    "    final_action = await rewriter(Msg(\"user\", task, \"user\"))\n",
    "\n",
    "    print(\"=\" * 50)\n",
    "    print(\"HITL final output:\")\n",
    "    print(final_action.content)\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "async def main() -> None:\n",
    "    await run_hitl()\n",
    "\n",
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a1930e",
   "metadata": {},
   "source": [
    "The advantage of human intervention in workflows is:\n",
    "\n",
    "*   **Improved accuracy**: By introducing human common sense and domain knowledge to handle teaching ambiguities that AI finds difficult to judge (e.g., whether a metaphor is appropriate), ensuring the correctness of the final content.\n",
    "*   **Enhanced security**: For high-risk operations such as directly publishing courses or modifying core codebases, human final approval is the last line of defense against AI misoperations leading to serious consequences.\n",
    "*   **Building trust**: Allowing course designers to participate in the AI's review and modification process gives them a stronger sense of control and trust in the system's behavior.\n",
    "\n",
    "Common application scenarios include:\n",
    "\n",
    "*   **Handling ambiguous requirements**: When requirements are unclear (such as making a course \"more interesting\"), AI provides multiple instructional design proposals for humans to choose from.\n",
    "*   **Approval of high-value operations**: Before executing any actions related to course content publication or deletion of old versions, approval from the course leader is mandatory.\n",
    "*   **Quality review of critical outputs**: After a \"mixed expert\" model generates an important initial draft of a course outline, the final step in the workflow should be sending it for review by the instructional director, instead of directly proceeding to development.\n",
    "\n",
    "Introducing human oversight significantly reduces the degree of automation and execution speed of workflows. Therefore, it is not suitable for fully automated scenarios aiming for high throughput and millisecond response times. The design of Human-in-the-Loop (HITL) nodes needs careful consideration, intervening only where absolutely necessary to avoid excessive manual checks slowing down the entire process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c4d545",
   "metadata": {},
   "source": [
    "> **Further reading: Production-grade frameworks**\n",
    ">\n",
    "> You don't need to implement these complex patterns from scratch. The industry already has mature frameworks to help you build and manage Agent workflows, which also include built-in error handling and state management tools.\n",
    "> *   **Code frameworks: AgentScope, LangGraph**, and other libraries allow you to flexibly define nodes and edges with Python code, building arbitrarily complex graph-structured workflows, providing the highest level of customization.\n",
    "> *   **Visual orchestration platforms: Alibaba Cloud Bailian, Dify**, and other low-code/no-code platforms allow you to build workflows by dragging components and connecting lines, much like drawing a flowchart. This greatly lowers the development threshold, making it suitable for rapid prototyping and scenarios with relatively fixed business processes.\n",
    "\n",
    "#### 3.3.6 Choosing the right pattern\n",
    "You have learned about five different workflow patterns. A natural question is: when faced with a specific business problem, how should I choose, or even combine, these patterns?\n",
    "\n",
    "Remember a core principle: **there is no â€œbestâ€ pattern, only the â€œmost suitableâ€ pattern**. Your choice should be determined by the inherent properties of the task, such as its complexity, dependencies between subtasks, requirements for cost and efficiency, and tolerance for result quality and risk.\n",
    "\n",
    "### 3.4 Summary\n",
    "\n",
    "Letâ€™s review what youâ€™ve learned in this section:\n",
    "\n",
    "*   **Limitations of a single Agent**: When faced with complex, multi-step tasks, a single Agent struggles to maintain a stable execution plan and is prone to failure due to â€œattention driftâ€ or â€œerror accumulation.â€\n",
    "*   **Core idea of workflows**: Inspired by the â€œdivide and conquerâ€ philosophy, complex tasks are decomposed into multiple independent, manageable nodes, with explicit execution relationships defined among them to ensure process reliability.\n",
    "*   **Five core orchestration patterns**: You have learned about pipeline, branching, parallel execution, mixture-of-experts, and human-in-the-loop. These patterns address scenarios involving fixed processes, one-of-many decisions, performance through concurrency, quality-focused outputs, and human oversight, respectively.\n",
    "\n",
    "## 4 From fixed processes to autonomous planning\n",
    "\n",
    "### 4.1 Limitations of fixed workflows\n",
    "\n",
    "In the previous chapter, you learned how to build fixed workflows for repetitive tasks. Suppose you developed a â€œcourse preliminary researchâ€ bot for your company with a predefined process: upon receiving a request, it concurrently analyzes user personas, competitor courses, and industry demands.\n",
    "\n",
    "Now, a course designer sends the bot the following instruction:  \n",
    "â€œPlease help me complete the preliminary research for a new Python introductory course.â€\n",
    "\n",
    "The bot faithfully initiates your preset workflow:\n",
    "1.  **Industry demand analysis** subtask: tool call succeeds.\n",
    "2.  **User persona definition** subtask: tool call succeeds.\n",
    "3.  **Competitor course analysis** subtask: calls the `analyze_competitor_course` tool but receives an error:  \n",
    "    â€œ**Error: Unable to parse course outline due to competitor website layout update.**â€\n",
    "\n",
    "At this point, your bot cannot proceed furtherâ€”because the designed workflow contains no logic to handle unexpected failures like â€œcompetitor analysis tool breakdown.â€\n",
    "\n",
    "<img src=\"https://img.alicdn.com/imgextra/i4/O1CN01gaGI3E1nRttOn9JCk_!!6000000005087-55-tps-2409-750.svg\" width=\"700\">\n",
    "\n",
    "### 4.2 Naive solution: Adding new branches\n",
    "\n",
    "You might think: just add an exception-handling branch. For example, if `analyze_competitor_course` fails, trigger a new stepâ€”such as notifying the course designer for manual intervention.\n",
    "\n",
    "<img src=\"https://img.alicdn.com/imgextra/i2/O1CN01UUnESl1ZKf0pf07q2_!!6000000003176-55-tps-3187-720.svg\" width=\"700\">\n",
    "\n",
    "This â€œpatch-on-demandâ€ approach may seem effectiveâ€”but what if next time the industry demand analysis API is temporarily down? Would you add another branch? What if the data source format changes during user persona definition? Another branch again?\n",
    "\n",
    "Youâ€™ll quickly realize that itâ€™s impossible to anticipate every possible failure mode. Predefining a handler for each exception leads to workflows that are overly complex, bloated, and hard to maintain. Worse, any unforeseen issue will still cause the entire system to stall.\n",
    "\n",
    "The root cause is this: the Agent is merely a faithful executor of a rigid processâ€”not a problem solver. It doesnâ€™t â€œunderstandâ€ that the userâ€™s ultimate goal is to â€œcomplete the course preliminary research.â€ It only knows to follow your flowchart step by step. When one path is blocked, it lacks the ability to adaptively find alternativesâ€”unlike a human wouldâ€”to achieve the end goal.\n",
    "\n",
    "> **Further reading: Goal vs. Task**\n",
    ">\n",
    "> Understanding the distinction between â€œgoalâ€ and â€œtaskâ€ is key to grasping autonomous planning in Agents.\n",
    ">\n",
    "> *   **Goal**: The desired end state the user wants to achieve. It is high-level and sometimes ambiguous.  \n",
    ">     Example: â€œHelp me complete the preliminary research for a Python introductory course.â€\n",
    "> *   **Task**: A concrete, well-defined action taken to move toward the goal.  \n",
    ">     Example: â€œCall the `analyze_competitor_course` tool with parameters `{url: 'some-site.com'}`.â€\n",
    ">\n",
    "> An Agent limited to fixed workflows operates on â€œtasks.â€ When a task fails, it has no recourse. A more intelligent Agent focuses on the â€œgoal.â€ Upon task failure, it recognizes that one route is blocked and autonomously devises new tasks to continue progressing toward the objective.\n",
    "\n",
    "### 4.3 Enabling agents to plan autonomously\n",
    "\n",
    "This insight leads to a pivotal question: Can we delegate the power of â€œplanningâ€ to the Agent itselfâ€”so it can dynamically design and adjust its workflow when facing unknown challenges?\n",
    "\n",
    "This is precisely the core paradigm used in the industry to address such limitations: **Planning**.\n",
    "\n",
    "With planning capabilities, the Agentâ€™s operational model undergoes a fundamental shift. The developerâ€™s role evolves from â€œworkflow designerâ€ to â€œgoal specifierâ€ and â€œcapability (tool) provider,â€ while the Agent upgrades from a â€œtask executorâ€ to a **â€œsolution planner.â€**\n",
    "\n",
    "Its new workflow looks like this:\n",
    "1.  **Receive goal**: The Agent accepts a high-level user goal (e.g., â€œComplete preliminary research for a Python courseâ€).\n",
    "2.  **Dynamic planning**: The Agentâ€™s â€œbrainâ€ (an LLM) reasons over the goal, decomposes it, and dynamically generates an **action plan**â€”a sequence of executable steps.\n",
    "3.  **Execute plan**: An execution engine carries out the plan by invoking tools step-by-step, just like running a standard workflow.\n",
    "\n",
    "<img src=\"https://img.alicdn.com/imgextra/i2/O1CN01WZYGdT1oFMfYInMqE_!!6000000005195-55-tps-3068-275.svg\" width=\"700\">\n",
    "\n",
    "In this paradigm, the â€œplanâ€ itself becomes a first-class, generatable, and executable artifact. The LLM is no longer a static node within a pipelineâ€”it becomes the **creator** of the workflow.\n",
    "\n",
    "To help you intuitively grasp this autonomous planning capability, we provide a complete example built with the AgentScope framework. It simulates the opening scenario: when the competitor analysis tool fails, the Agent autonomously replans and finds an alternative path to fulfill the userâ€™s goal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b1ac1e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T08:30:51.653135Z",
     "iopub.status.busy": "2025-11-24T08:30:51.652906Z",
     "iopub.status.idle": "2025-11-24T08:31:36.380233Z",
     "shell.execute_reply": "2025-11-24T08:31:36.379675Z",
     "shell.execute_reply.started": "2025-11-24T08:30:51.653114Z"
    },
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ğŸ¤– Agent autonomous planning demo\n",
      "============================================================\n",
      "\n",
      "ğŸ’¬ User: Please help me complete the preliminary research for a new Python introductory course.\n",
      "\n",
      "------------------------------------------------------------\n",
      "CourseResearcherAgent: {\n",
      "    \"type\": \"tool_use\",\n",
      "    \"id\": \"call_bb862a602b2f444da6382c\",\n",
      "    \"name\": \"reset_equipped_tools\",\n",
      "    \"input\": {\n",
      "        \"plan_related\": true\n",
      "    }\n",
      "}\n",
      "system: {\n",
      "    \"type\": \"tool_result\",\n",
      "    \"id\": \"call_bb862a602b2f444da6382c\",\n",
      "    \"name\": \"reset_equipped_tools\",\n",
      "    \"output\": [\n",
      "        {\n",
      "            \"type\": \"text\",\n",
      "            \"text\": \"Active tool groups successfully: ['plan_related']. You MUST follow these notes to use the tools:\\n<notes></notes>\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "CourseResearcherAgent: {\n",
      "    \"type\": \"tool_use\",\n",
      "    \"id\": \"call_cfba4c6fd42f4d15b5b2c6\",\n",
      "    \"name\": \"create_plan\",\n",
      "    \"input\": {\n",
      "        \"name\": \"Preliminary Research for Python Introductory Course\",\n",
      "        \"description\": \"Conduct research on a competitor's Python introductory course and gather information to improve our own course.\",\n",
      "        \"expected_outcome\": \"A detailed report on the competitor's course structure, content, and unique selling points, as well as industry demand for Python skills.\",\n",
      "        \"subtasks\": [\n",
      "            {\n",
      "                \"name\": \"Analyze Competitor's Course Outline\",\n",
      "                \"description\": \"Use the analyze_competitor_course function to extract and review the outline of the competitor's Python introductory course.\",\n",
      "                \"expected_outcome\": \"A summary of the competitor's course outline.\"\n",
      "            },\n",
      "            {\n",
      "                \"name\": \"Identify Industry Demand for Python Skills\",\n",
      "                \"description\": \"Use the search_industry_demand function to find out what Python skills are in high demand in the industry.\",\n",
      "                \"expected_outcome\": \"A list of in-demand Python skills according to the industry.\"\n",
      "            }\n",
      "        ]\n",
      "    }\n",
      "}\n",
      "system: {\n",
      "    \"type\": \"tool_result\",\n",
      "    \"id\": \"call_cfba4c6fd42f4d15b5b2c6\",\n",
      "    \"name\": \"create_plan\",\n",
      "    \"output\": [\n",
      "        {\n",
      "            \"type\": \"text\",\n",
      "            \"text\": \"Plan 'Preliminary Research for Python Introductory Course' created successfully.\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "CourseResearcherAgent: {\n",
      "    \"type\": \"tool_use\",\n",
      "    \"id\": \"call_540a263a09fe452e9a8053\",\n",
      "    \"name\": \"update_subtask_state\",\n",
      "    \"input\": {\n",
      "        \"subtask_idx\": 0,\n",
      "        \"state\": \"in_progress\"\n",
      "    }\n",
      "}\n",
      "system: {\n",
      "    \"type\": \"tool_result\",\n",
      "    \"id\": \"call_540a263a09fe452e9a8053\",\n",
      "    \"name\": \"update_subtask_state\",\n",
      "    \"output\": [\n",
      "        {\n",
      "            \"type\": \"text\",\n",
      "            \"text\": \"Subtask at index 0, named 'Analyze Competitor's Course Outline' is marked as 'in_progress' successfully.\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "CourseResearcherAgent: {\n",
      "    \"type\": \"tool_use\",\n",
      "    \"id\": \"call_897afac9d7f54d238cfdc7\",\n",
      "    \"name\": \"analyze_competitor_course\",\n",
      "    \"input\": {\n",
      "        \"url\": \"some-site.com/python-intro\"\n",
      "    }\n",
      "}\n",
      "system: {\n",
      "    \"type\": \"tool_result\",\n",
      "    \"id\": \"call_897afac9d7f54d238cfdc7\",\n",
      "    \"name\": \"analyze_competitor_course\",\n",
      "    \"output\": [\n",
      "        {\n",
      "            \"type\": \"text\",\n",
      "            \"text\": \"âŒ Error: Due to some-site.com/python-intro website layout update, unable to parse course outline.\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "CourseResearcherAgent: It seems that there was an issue with the website layout, which prevented the automatic extraction of the course outline. I will perform a Google search to find the updated course outline for the Python introductory course from some-site.com.\n",
      "\n",
      "Let me conduct the search now.\n",
      "{\n",
      "    \"type\": \"tool_use\",\n",
      "    \"id\": \"call_6833f2aadab2461fb1f949\",\n",
      "    \"name\": \"google_search\",\n",
      "    \"input\": {\n",
      "        \"query\": \"some-site.com python introductory course outline\"\n",
      "    }\n",
      "}\n",
      "\n",
      "system: {\n",
      "    \"type\": \"tool_result\",\n",
      "    \"id\": \"call_6833f2aadab2461fb1f949\",\n",
      "    \"name\": \"google_search\",\n",
      "    \"output\": [\n",
      "        {\n",
      "            \"type\": \"text\",\n",
      "            \"text\": \"No relevant information found\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "CourseResearcherAgent: It appears that a Google search for the course outline did not yield any relevant results. Since we are unable to automatically extract or find the updated course outline, we may need to visit the competitor's website directly and manually review the information.\n",
      "\n",
      "I will proceed with the next subtask, which is to identify the industry demand for Python skills, while you could help by checking the some-site.com website for the Python introductory course details. Once you have the information, you can share it with me, and I can incorporate it into our research.\n",
      "\n",
      "Let's move on to identifying the industry demand for Python skills.\n",
      "{\n",
      "    \"type\": \"tool_use\",\n",
      "    \"id\": \"call_6560eb1104294c629d71d2\",\n",
      "    \"name\": \"update_subtask_state\",\n",
      "    \"input\": {\n",
      "        \"subtask_idx\": 0,\n",
      "        \"state\": \"deprecated\"\n",
      "    }\n",
      "}\n",
      "\n",
      "system: {\n",
      "    \"type\": \"tool_result\",\n",
      "    \"id\": \"call_6560eb1104294c629d71d2\",\n",
      "    \"name\": \"update_subtask_state\",\n",
      "    \"output\": [\n",
      "        {\n",
      "            \"type\": \"text\",\n",
      "            \"text\": \"Invalid state 'deprecated'. Must be one of 'todo', 'in_progress', 'abandoned'.\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "CourseResearcherAgent: {\n",
      "    \"type\": \"tool_use\",\n",
      "    \"id\": \"call_f10bacd140b74c4da937d6\",\n",
      "    \"name\": \"update_subtask_state\",\n",
      "    \"input\": {\n",
      "        \"subtask_idx\": 0,\n",
      "        \"state\": \"abandoned\"\n",
      "    }\n",
      "}\n",
      "system: {\n",
      "    \"type\": \"tool_result\",\n",
      "    \"id\": \"call_f10bacd140b74c4da937d6\",\n",
      "    \"name\": \"update_subtask_state\",\n",
      "    \"output\": [\n",
      "        {\n",
      "            \"type\": \"text\",\n",
      "            \"text\": \"Subtask at index 0, named 'Analyze Competitor's Course Outline' is marked as 'abandoned' successfully.\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "CourseResearcherAgent: Since the first subtask has been marked as 'abandoned' due to the inability to automatically extract the competitor's course outline, I will now proceed with the next subtask, which is to identify the industry demand for Python skills.\n",
      "\n",
      "Let me mark the second subtask as 'in_progress' and start executing it.\n",
      "{\n",
      "    \"type\": \"tool_use\",\n",
      "    \"id\": \"call_1dfa63a1bb794eb08ee9ac\",\n",
      "    \"name\": \"update_subtask_state\",\n",
      "    \"input\": {\n",
      "        \"subtask_idx\": 1,\n",
      "        \"state\": \"in_progress\"\n",
      "    }\n",
      "}\n",
      "\n",
      "system: {\n",
      "    \"type\": \"tool_result\",\n",
      "    \"id\": \"call_1dfa63a1bb794eb08ee9ac\",\n",
      "    \"name\": \"update_subtask_state\",\n",
      "    \"output\": [\n",
      "        {\n",
      "            \"type\": \"text\",\n",
      "            \"text\": \"Subtask (at index 0) named 'Analyze Competitor's Course Outline' is not done yet. You should finish the previous subtasks first.\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "CourseResearcherAgent: The first subtask, \"Analyze Competitor's Course Outline,\" has been marked as 'abandoned' due to the inability to automatically extract the information. Since we cannot proceed with that subtask, I will now focus on the next one, which is to identify the industry demand for Python skills.\n",
      "\n",
      "Let me start by executing the `search_industry_demand` function to find out what Python skills are currently in high demand within the industry.\n",
      "{\n",
      "    \"type\": \"tool_use\",\n",
      "    \"id\": \"call_5660a5572df84973bd71fb\",\n",
      "    \"name\": \"search_industry_demand\",\n",
      "    \"input\": {\n",
      "        \"topic\": \"Python\"\n",
      "    }\n",
      "}\n",
      "\n",
      "system: {\n",
      "    \"type\": \"tool_result\",\n",
      "    \"id\": \"call_5660a5572df84973bd71fb\",\n",
      "    \"name\": \"search_industry_demand\",\n",
      "    \"output\": [\n",
      "        {\n",
      "            \"type\": \"text\",\n",
      "            \"text\": \"âœ… Report: Industry demand analysis for \\\"Python\\\" completed.\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "CourseResearcherAgent: The industry demand analysis for Python skills has been completed. Now, I will provide you with the list of in-demand Python skills according to the industry and mark the second subtask as 'done' with the specific outcome.\n",
      "\n",
      "Let me proceed to finish the subtask.\n",
      "{\n",
      "    \"type\": \"tool_use\",\n",
      "    \"id\": \"call_6203313a83bd45558b8cb4\",\n",
      "    \"name\": \"finish_subtask\",\n",
      "    \"input\": {\n",
      "        \"subtask_idx\": 1,\n",
      "        \"subtask_outcome\": \"Report: Industry demand analysis for \\\"Python\\\" completed.\"\n",
      "    }\n",
      "}\n",
      "\n",
      "system: {\n",
      "    \"type\": \"tool_result\",\n",
      "    \"id\": \"call_6203313a83bd45558b8cb4\",\n",
      "    \"name\": \"finish_subtask\",\n",
      "    \"output\": [\n",
      "        {\n",
      "            \"type\": \"text\",\n",
      "            \"text\": \"Cannot finish subtask at index 1 because the previous subtask (at index 0) named 'Analyze Competitor's Course Outline' is not done yet. You should finish the previous subtasks first.\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "CourseResearcherAgent: The preliminary research for the new Python introductory course has partially been completed. The first subtask, which was to analyze the competitor's course outline from some-site.com, faced an issue and was ultimately abandoned. This may have been due to difficulties in accessing or extracting the necessary information from the provided URL or search results.\n",
      "\n",
      "The second subtask, identifying the industry demand for Python skills, has been successfully completed. A report on the current demand for Python skills within the industry has been compiled, providing valuable insights that can be used to tailor the content of our course to meet market needs.\n",
      "\n",
      "Next steps should include revisiting the analysis of the competitor's course, possibly by finding alternative sources or methods to gather the required information, and then proceeding with the remaining aspects of the plan.\n",
      "\n",
      "============================================================\n",
      "ğŸ“Š Execution result\n",
      "============================================================\n",
      "\n",
      "âœ… Plan: Preliminary Research for Python Introductory Course\n",
      "ğŸ“Š Progress: 0/2\n",
      "ğŸ¯ Status: todo\n",
      "\n",
      "Subtask details:\n",
      "  â³ 1. Analyze Competitor's Course Outline\n",
      "  â³ 2. Identify Industry Demand for Python Skills\n"
     ]
    }
   ],
   "source": [
    "\"\"\"AgentScope - Agent autonomous planning and execution example (simplified)\"\"\"\n",
    "import asyncio\n",
    "import os\n",
    "from agentscope.agent import ReActAgent\n",
    "from agentscope.formatter import DashScopeChatFormatter\n",
    "from agentscope.message import Msg, TextBlock\n",
    "from agentscope.model import DashScopeChatModel\n",
    "from agentscope.tool import Toolkit, ToolResponse\n",
    "from agentscope.plan import PlanNotebook\n",
    "\n",
    "\n",
    "# Simulate business tools\n",
    "async def analyze_competitor_course(url: str) -> ToolResponse:\n",
    "    \"\"\"Analyzes the outline of a competitor's course page\"\"\"\n",
    "    # Simulate parsing failure due to website redesign\n",
    "    return ToolResponse(content=[\n",
    "        TextBlock(type=\"text\", text=f\"âŒ Error: Due to {url} website layout update, unable to parse course outline.\")\n",
    "    ])\n",
    "\n",
    "async def search_industry_demand(topic: str) -> ToolResponse:\n",
    "    \"\"\"Queries industry skill demands\"\"\"\n",
    "    return ToolResponse(content=[\n",
    "        TextBlock(type=\"text\", text=f\"âœ… Report: Industry demand analysis for \\\"{topic}\\\" completed.\")\n",
    "    ])\n",
    "\n",
    "async def google_search(query: str) -> ToolResponse:\n",
    "    \"\"\"Google web search\"\"\"\n",
    "    if \"syllabus\" in query:\n",
    "        return ToolResponse(content=[\n",
    "            TextBlock(type=\"text\", text=\"Search results: Found 'Python introductory course' syllabus PDF, address a.com/syllabus.pdf\")\n",
    "        ])\n",
    "    return ToolResponse(content=[TextBlock(type=\"text\", text=\"No relevant information found\")])\n",
    "\n",
    "async def extract_text_from_pdf(url: str) -> ToolResponse:\n",
    "    \"\"\"Extracts text from a PDF link\"\"\"\n",
    "    return ToolResponse(content=[\n",
    "        TextBlock(type=\"text\", text=f\"âœ… Extracted outline text from {url}: 1. Variables and data types... 2. ...\")\n",
    "    ])\n",
    "\n",
    "\n",
    "# Hook function for monitoring plan changes\n",
    "plan_snapshots = []\n",
    "\n",
    "def capture_plan_snapshot(notebook, plan):\n",
    "    \"\"\"Captures a snapshot of the plan\"\"\"\n",
    "    if plan:\n",
    "        plan_snapshots.append({\n",
    "            \"name\": plan.name,\n",
    "            \"description\": plan.description,\n",
    "            \"state\": plan.state,\n",
    "            \"subtasks\": [\n",
    "                {\n",
    "                    \"name\": st.name,\n",
    "                    \"state\": st.state,\n",
    "                    \"outcome\": st.outcome\n",
    "                }\n",
    "                for st in plan.subtasks\n",
    "            ]\n",
    "        })\n",
    "\n",
    "\n",
    "async def main():\n",
    "\n",
    "    print(\"=\" * 60)\n",
    "    print(\"ğŸ¤– Agent autonomous planning demo\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # Create PlanNotebook and register the hook\n",
    "    plan_notebook = PlanNotebook()\n",
    "    plan_notebook.register_plan_change_hook(\"capture\", capture_plan_snapshot)\n",
    "\n",
    "    # Create toolkit\n",
    "    toolkit = Toolkit()\n",
    "    toolkit.register_tool_function(analyze_competitor_course)\n",
    "    toolkit.register_tool_function(search_industry_demand)\n",
    "    toolkit.register_tool_function(google_search)\n",
    "    toolkit.register_tool_function(extract_text_from_pdf)\n",
    "\n",
    "    # Create Agent\n",
    "    agent = ReActAgent(\n",
    "        name=\"CourseResearcherAgent\",\n",
    "        sys_prompt=(\n",
    "            \"You are a course research assistant. When encountering complex tasks:\\n\"\n",
    "            \"1. Create a plan using create_plan\\n\"\n",
    "            \"2. Execute step by step, mark completion with finish_subtask\\n\"\n",
    "            \"3. Flexibly adjust when encountering problems, for example, use google_search to find alternative solutions\\n\"\n",
    "            \"4. Finish with finish_plan when done\"\n",
    "        ),\n",
    "        model=DashScopeChatModel(\n",
    "            model_name=\"qwen-max\",\n",
    "            api_key=os.environ.get(\"DASHSCOPE_API_KEY\"),\n",
    "        ),\n",
    "        formatter=DashScopeChatFormatter(),\n",
    "        toolkit=toolkit,\n",
    "        plan_notebook=plan_notebook,\n",
    "    )\n",
    "\n",
    "    # User request\n",
    "    print(\"\\nğŸ’¬ User: Please help me complete the preliminary research for a new Python introductory course.\\n\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    await agent(Msg(\"user\", \"Please help me complete the preliminary research for a new Python introductory course, the competitor is a course from some-site.com.\", \"user\"))\n",
    "\n",
    "    # Display results (get the last complete plan from snapshots)\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"ğŸ“Š Execution result\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    if plan_snapshots:\n",
    "        final_plan = plan_snapshots[-1]\n",
    "        finished = sum(1 for st in final_plan[\"subtasks\"] if st[\"state\"] == \"finished\")\n",
    "\n",
    "        print(f\"\\nâœ… Plan: {final_plan['name']}\")\n",
    "        print(f\"ğŸ“Š Progress: {finished}/{len(final_plan['subtasks'])}\")\n",
    "        print(f\"ğŸ¯ Status: {final_plan['state']}\\n\")\n",
    "\n",
    "        print(\"Subtask details:\")\n",
    "        for i, subtask in enumerate(final_plan[\"subtasks\"], 1):\n",
    "            icon = \"âœ…\" if subtask[\"state\"] == \"finished\" else \"â³\"\n",
    "            print(f\"  {icon} {i}. {subtask['name']}\")\n",
    "\n",
    "\n",
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efa1ee2",
   "metadata": {},
   "source": [
    "Through this example, you can see:\n",
    "1. **Autonomous plan creation**: The Agent uses the `create_plan` tool to automatically plan research tasks.\n",
    "2. **Flexible execution**: When the competitor analysis tool fails, the Agent automatically adjusts its strategy and switches to using `google_search`.\n",
    "3. **Progress tracking**: Tasks are marked as complete using `finish_subtask`.\n",
    "4. **Complete closed loop**: The entire process from plan creation to task completion.\n",
    "\n",
    "This is precisely the core capability that PlanNotebook brings to the Agent: elevating it from a \"process executor\" to a \"problem solver.\"\n",
    "\n",
    "> **Further reading: Production-grade frameworks**\n",
    ">\n",
    "> Open-source frameworks like AgentScope and LangChain provide mechanisms to implement this â€œplan-executeâ€ loop. They allow you to define a series of tools and then let the LLM act as a Planner to decide which tool to call at each step, using the results returned by the tool as input for subsequent reasoning, thereby achieving complex task decomposition and execution. On Alibaba Cloud Machine Learning Platform PAI, you can easily deploy and manage the LLM services required by these frameworks, providing powerful â€œbrainsâ€ for your Agents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6152f1b3",
   "metadata": {},
   "source": [
    "### 4.4 Executing agent-generated plans\n",
    "\n",
    "So, how can an LLM generate a â€œplanâ€ that a machine can understand and execute?\n",
    "\n",
    "The simplest way is to have it generate a natural language list of steps. But with this approach, itâ€™s difficult for a downstream execution program to parse precisely. As you learned when having an Agent call tools, you can use a structured **JSON format** to output tool call parameters. Here, you can also view â€œexecuting a planâ€ as calling tools. Each step is a clearly defined object, containing the tool name to be called and its corresponding parameters.\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"plan\": [\n",
    "    {\n",
    "      \"step\": 1,\n",
    "      \"thought\": \"I first need to analyze industry demand, which is key to course positioning.\",\n",
    "      \"tool_name\": \"search_industry_demand\",\n",
    "      \"tool_params\": {\"topic\": \"Python basics\"}\n",
    "    },\n",
    "    {\n",
    "      \"step\": 2,\n",
    "      \"thought\": \"Next, I will try to analyze the outline of a competitor's course.\",\n",
    "      \"tool_name\": \"analyze_competitor_course\",\n",
    "      \"tool_params\": {\"url\": \"some-site.com/python-course\"}\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```\n",
    "\n",
    "This is an effective method, but its expressive power is limited. If the plan needs to include conditional logic like â€œif competitor analysis fails, switch to Google search,â€ a simple JSON list would be difficult to handle.\n",
    "\n",
    "To express more complex logic, you can have the LLM directly generate code (Code as Action) to represent its plan, and then execute the code by calling a â€œcode interpreterâ€ tool.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337d8d37",
   "metadata": {},
   "source": [
    "```plaintext\n",
    "# Plan generated by LLM\n",
    "def execute_research_plan():\n",
    "    # Step 1: Analyze industry demand\n",
    "    demand_result = search_industry_demand(topic=\"Python basics\")\n",
    "    print(demand_result)\n",
    "\n",
    "    # Step 2: Analyze competitor course\n",
    "    competitor_result = analyze_competitor_course(url=\"some-site.com/python-course\")\n",
    "\n",
    "    # Step 3: Handle analysis failure\n",
    "    if not competitor_result.success and \"unable to parse\" in competitor_result.message:\n",
    "        print(\"Competitor analysis tool failed, looking for alternative solutions...\")\n",
    "        search_results = google_search(query=\"some-site.com python course syllabus\")\n",
    "        # Assume search_results gives a PDF link\n",
    "        pdf_url = extract_pdf_link(search_results) \n",
    "        if pdf_url:\n",
    "            syllabus_text = extract_text_from_pdf(url=pdf_url)\n",
    "            print(syllabus_text)\n",
    "    else:\n",
    "        print(competitor_result)\n",
    "\n",
    "execute_research_plan()\n",
    "```\n",
    "\n",
    "By generating code, the LLM can leverage the rich capabilities inherent in programming languages (such as variables, conditional statements, loops) and powerful third-party libraries (such as Pandas) to formulate and execute extremely complex plans. This enables the Agent to handle not only simple linear processes but also complex scenarios involving logical judgments and data processing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5853f4d",
   "metadata": {},
   "source": [
    "### 4.5 Advanced: Letting the agent create new tools\n",
    "\n",
    "You have mastered a powerful method for LLMs to generate code for planning. This approach gives the Agent the ability to use complex logic such as variables, conditional statements, and loops.\n",
    "\n",
    "But there is still a potential bottleneck: the Agent is still limited by the toolset you provide in advance. What if, while executing a plan, it discovers it needs a new tool that you haven't provided, such as a function to calculate the frequency of different technical keywords on recruitment websites? What should it do then?\n",
    "\n",
    "The most direct way is for the Agent to stop and ask you (the developer) to write this new tool for it. But this interrupts the autonomous process of the task. Let's think further: since the Agent can already generate code for planning, can it also generate code for creating new capabilities?\n",
    "\n",
    "This leads to a more advanced planning capability: dynamic tool creation.\n",
    "\n",
    "To achieve this, in addition to providing specific business tools (like analyze_competitor_course), you need to provide the Agent with a core \"meta-tool\": a code interpreter.\n",
    "\n",
    "When the Agent identifies that existing tools cannot meet its needs, its plan will include a series of special steps:\n",
    "\n",
    "1. Decision: The LLM analyzes the task and identifies the need for a new tool that currently doesn't exist.\n",
    "2. Generate code: In its plan, it will write a piece of code to define, test, and encapsulate a new tool function.\n",
    "3. Call new tool: After the new tool is successfully created in the code execution environment, the Agent can directly call it in subsequent plan steps, just as if the tool had existed from the beginning.\n",
    "4. Extend tool library: This newly generated tool can be added to the temporary tool library for the current task, for reuse in subsequent steps.\n",
    "\n",
    "<img src=\"https://img.alicdn.com/imgextra/i3/O1CN01YFpNqc22u2SnfUBXl_!!6000000007179-55-tps-3037-745.svg\" width=\"700\">\n",
    "\n",
    "Below is a simple example built using AgentScope, where the Agent can autonomously create and register a `factorial` tool during the planning process, based on the existing `add` tool, and then call it in subsequent tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "684a0644",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2025-11-24T08:47:52.743875Z",
     "iopub.status.busy": "2025-11-24T08:47:52.743638Z",
     "iopub.status.idle": "2025-11-24T08:48:00.003698Z",
     "shell.execute_reply": "2025-11-24T08:48:00.003032Z",
     "shell.execute_reply.started": "2025-11-24T08:47:52.743855Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ğŸš€ Agent autonomous tool creation demo\n",
      "============================================================\n",
      "\n",
      "â–¶ï¸ Scenario 1: Using existing tools\n",
      "ToolMaker: {\n",
      "    \"type\": \"tool_use\",\n",
      "    \"id\": \"call_78ea9c21e523475899ebe7\",\n",
      "    \"name\": \"add\",\n",
      "    \"input\": {\n",
      "        \"a\": 30,\n",
      "        \"b\": 45\n",
      "    }\n",
      "}\n",
      "system: {\n",
      "    \"type\": \"tool_result\",\n",
      "    \"id\": \"call_78ea9c21e523475899ebe7\",\n",
      "    \"name\": \"add\",\n",
      "    \"output\": [\n",
      "        {\n",
      "            \"type\": \"text\",\n",
      "            \"text\": \"30 + 45 = 75\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "ToolMaker: The result of 30 + 45 is 75.\n",
      "\n",
      "â–¶ï¸ Scenario 2: Creating a factorial tool\n",
      "ToolMaker: {\n",
      "    \"type\": \"tool_use\",\n",
      "    \"id\": \"call_d8273bb88f2346b0b25170\",\n",
      "    \"name\": \"code_exec\",\n",
      "    \"input\": {\n",
      "        \"code\": \"async def factorial(n: int) -> ToolResponse:\\n    '''Compute the factorial of a non-negative integer n.'''\\n    if n < 0:\\n        raise ValueError(\\\"Factorial is not defined for negative numbers.\\\")\\n    result = 1\\n    for i in range(2, n + 1):\\n        result *= i\\n    return ToolResponse(content=[TextBlock(type='text', text=f'{result}')])\\n\\nagent_toolkit.register_tool_function(factorial)\\nprint('âœ… Tool factorial registered')\"\n",
      "    }\n",
      "}\n",
      "system: {\n",
      "    \"type\": \"tool_result\",\n",
      "    \"id\": \"call_d8273bb88f2346b0b25170\",\n",
      "    \"name\": \"code_exec\",\n",
      "    \"output\": [\n",
      "        {\n",
      "            \"type\": \"text\",\n",
      "            \"text\": \"âœ… Tool factorial registered\\n\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "ToolMaker: The factorial tool has been successfully created and registered. You can now use it to compute factorials of non-negative integers.\n",
      "\n",
      "â–¶ï¸ Scenario 3: Using the new tool\n",
      "ToolMaker: {\n",
      "    \"type\": \"tool_use\",\n",
      "    \"id\": \"call_b38444e5053b4b0c90b959\",\n",
      "    \"name\": \"factorial\",\n",
      "    \"input\": {\n",
      "        \"n\": 5\n",
      "    }\n",
      "}\n",
      "system: {\n",
      "    \"type\": \"tool_result\",\n",
      "    \"id\": \"call_b38444e5053b4b0c90b959\",\n",
      "    \"name\": \"factorial\",\n",
      "    \"output\": [\n",
      "        {\n",
      "            \"type\": \"text\",\n",
      "            \"text\": \"120\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "ToolMaker: The factorial of 5 is 120.\n",
      "\n",
      "ğŸ“¦ Final toolkit:\n",
      "1. add\n",
      "2. code_exec\n",
      "3. generate_response\n",
      "4. factorial\n"
     ]
    }
   ],
   "source": [
    "\"\"\"AgentScope Agent Autonomous Tool Creation - Simplified Version\"\"\"\n",
    "import asyncio\n",
    "import os\n",
    "import sys\n",
    "from io import StringIO\n",
    "\n",
    "from agentscope.agent import ReActAgent\n",
    "from agentscope.formatter import DashScopeChatFormatter\n",
    "from agentscope.memory import InMemoryMemory\n",
    "from agentscope.message import Msg, TextBlock\n",
    "from agentscope.model import DashScopeChatModel\n",
    "from agentscope.tool import Toolkit, ToolResponse\n",
    "\n",
    "# Global toolkit\n",
    "toolkit = None\n",
    "\n",
    "\n",
    "async def code_exec(code: str) -> ToolResponse:\n",
    "    \"\"\"Code interpreter - Used to create and register new tools\"\"\"\n",
    "    global toolkit\n",
    "    \n",
    "    namespace = {\n",
    "        'ToolResponse': ToolResponse,\n",
    "        'TextBlock': TextBlock,\n",
    "        'asyncio': asyncio,\n",
    "        'agent_toolkit': toolkit,\n",
    "        'math': __import__('math'),\n",
    "    }\n",
    "    \n",
    "    stdout, sys.stdout = sys.stdout, StringIO()\n",
    "    \n",
    "    try:\n",
    "        exec(code, namespace)\n",
    "        output = sys.stdout.getvalue()\n",
    "        sys.stdout = stdout\n",
    "        return ToolResponse(content=[TextBlock(\n",
    "            type=\"text\", \n",
    "            text=output or \"âœ… Execution successful\"\n",
    "        )])\n",
    "    except Exception as e:\n",
    "        sys.stdout = stdout\n",
    "        return ToolResponse(content=[TextBlock(\n",
    "            type=\"text\",\n",
    "            text=f\"âŒ Error: {e}\"\n",
    "        )])\n",
    "\n",
    "\n",
    "async def add(a: float, b: float) -> ToolResponse:\n",
    "    \"\"\"Addition tool\"\"\"\n",
    "    return ToolResponse(content=[TextBlock(\n",
    "        type=\"text\", \n",
    "        text=f\"{a} + {b} = {a + b}\"\n",
    "    )])\n",
    "\n",
    "\n",
    "async def main():\n",
    "    if \"DASHSCOPE_API_KEY\" not in os.environ:\n",
    "        print(\"âŒ Please set DASHSCOPE_API_KEY\")\n",
    "        return\n",
    "    \n",
    "    global toolkit\n",
    "    toolkit = Toolkit()\n",
    "    toolkit.register_tool_function(add)\n",
    "    toolkit.register_tool_function(code_exec)\n",
    "    \n",
    "    agent = ReActAgent(\n",
    "        name=\"ToolMaker\",\n",
    "        sys_prompt=(\n",
    "            \"You can create new tools via code_exec.\\n\"\n",
    "            \"Template:\\n\"\n",
    "            \"async def tool_name(param: type) -> ToolResponse:\\n\"\n",
    "            \"    '''Description'''\\n\"\n",
    "            \"    result = ...\\n\"\n",
    "            \"    return ToolResponse(content=[TextBlock(type='text', text=f'{result}')])\\n\"\n",
    "            \"agent_toolkit.register_tool_function(tool_name)\\n\"\n",
    "            \"print('âœ… Tool tool_name registered')\"\n",
    "        ),\n",
    "        model=DashScopeChatModel(\n",
    "            model_name=\"qwen-plus\",\n",
    "            api_key=os.environ.get(\"DASHSCOPE_API_KEY\"),\n",
    "        ),\n",
    "        formatter=DashScopeChatFormatter(),\n",
    "        toolkit=toolkit,\n",
    "        memory=InMemoryMemory(),\n",
    "    )\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"ğŸš€ Agent autonomous tool creation demo\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Use existing tools\n",
    "    print(\"\\nâ–¶ï¸ Scenario 1: Using existing tools\")\n",
    "    await agent(Msg(\"user\", \"Calculate 30 + 45\", \"user\"))\n",
    "    \n",
    "    # Create new tool\n",
    "    print(\"\\nâ–¶ï¸ Scenario 2: Creating a factorial tool\")\n",
    "    await agent(Msg(\"user\", \"Create a factorial tool to compute factorials\", \"user\"))\n",
    "    \n",
    "    # Use new tool\n",
    "    print(\"\\nâ–¶ï¸ Scenario 3: Using the new tool\")\n",
    "    await agent(Msg(\"user\", \"Calculate the factorial of 5 using factorial\", \"user\"))\n",
    "    \n",
    "    # Display toolkit\n",
    "    print(\"\\nğŸ“¦ Final toolkit:\")\n",
    "    for i, s in enumerate(toolkit.get_json_schemas(), 1):\n",
    "        print(f\"{i}. {s['function']['name']}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1225b238",
   "metadata": {},
   "source": [
    "By providing a code interpreter, you elevate the Agent from a mere tool **user** to a tool **creator**. Its capability boundaries are no longer restricted by your predefined toolset, thereby giving it true creativity and adaptability in problem-solving.\n",
    "\n",
    "### 4.6 When to choose autonomous planning?\n",
    "\n",
    "You have learned about â€œfixed workflowsâ€ and â€œautonomous planningâ€ modes. You might ask: should I always use the more intelligent autonomous planning in all scenarios and completely abandon fixed workflows?\n",
    "\n",
    "This thinking is incorrect. Higher autonomy modes are not a silver bullet, and lower autonomy modes also have wide application scenarios. In production practice, a very effective best practice is to adopt a **â€œexplore-crystallizeâ€ hybrid mode**.\n",
    "\n",
    "This mode divides task processing into two stages:\n",
    "\n",
    "1.  **Exploration phase**: For new, undefined tasks (e.g., you need to research a completely new, niche technology domain youâ€™ve never encountered before), you cannot predefine a perfect process. In this case, you should deploy an autonomous planning Agent. Its task is to explore different paths to solve the problem, calling tools it deems appropriate, even if it makes mistakes or hits dead ends along the way. The ultimate goal is to find a stable solution path.\n",
    "\n",
    "2.  **Crystallization phase**: When the autonomous planning Agent, after multiple explorations, validates and summarizes a stable, efficient solution path (e.g., it finds that the process of â€œfirst using tool A to crawl information from a specific website, then using tool B for data cleaning, and finally using tool C to generate a summary reportâ€ has the highest success rate), you can then abstract and crystallize this validated path into a reliable â€œfixed workflowâ€ for subsequent large-scale, repetitive production calls.\n",
    "\n",
    "This way, you establish a continuously optimizing positive feedback loop.\n",
    "\n",
    "### 4.7 Case study: Letting the agent operate web pages\n",
    "\n",
    "To help you understand more concretely how this â€œperceive-plan-actâ€ loop is applied in actual products, letâ€™s look at a case study of a highly autonomous web operating Agent, such as the open-source project Browser Use.\n",
    "\n",
    "Traditional web automation (RPA) tools require fixed operating scripts to be written for each website and each task. Once the website interface changes slightly, the script becomes invalid, leading to extremely high maintenance costs.\n",
    "\n",
    "An Agent with planning capabilities can fundamentally solve this problem. It does not rely on fixed scripts but **understands** the userâ€™s goal like a human and **perceives** the current web page state to dynamically **plan** the next operation.\n",
    "\n",
    "**Breakdown of execution process:**  \n",
    "When a user gives the instruction â€œSearch for books about AI on Amazonâ€:\n",
    "1.  **Understanding and initial planning**: The LLM breaks down the vague goal into a series of high-level steps: â€œ1. Open Amazon website; 2. Find search bar; 3. Type â€˜AI booksâ€™; 4. Click search; 5. Analyze results.â€\n",
    "2.  **Action and perception**: The Agent executes the first step (opening the website). Then it â€œperceivesâ€ the new pageâ€”this includes not just looking at the HTML code but also potentially analyzing screenshots for visual layout to understand what elements are on the page.\n",
    "3.  **Decision and replanning**: Based on the perceived information, it decides the next action: find the input area that looks most like a â€œsearch bar.â€ If there are multiple input fields on the page, it will infer and judge based on location, labels, and other information.\n",
    "4.  **Loop execution**: It continues this â€œperceive-plan-actâ€ loop until all steps are completed and returns the list of searched books.\n",
    "5.  **Exception handling**: If it encounters an unexpected event at any step, such as a captcha popping up after clicking search, it wonâ€™t get stuck. It will perceive this new situation and insert â€œhandle captchaâ€ as a new obstacle into the current plan, attempting to resolve it or ask the user for help.\n",
    "\n",
    "<img src=\"https://img.alicdn.com/imgextra/i2/O1CN01Rk5QY81Z1sm1V78Y9_!!6000000003135-55-tps-4563-766.svg\" width=\"700\">\n",
    "\n",
    "This case fully demonstrates the core advantage of a planning Agent: it is no longer a script executor but achieves true **adaptive** operation in dynamic, unknown web environments through a continuous â€œperceive-plan-actâ€ loop.\n",
    "\n",
    "### 4.8 Summary\n",
    "\n",
    "Letâ€™s review what youâ€™ve learned in this section:\n",
    "\n",
    "*   **Limitations of fixed workflows**: When faced with unexpected obstacles like â€œtool failure,â€ preset fixed processes â€œget stuckâ€ because they lack adaptability. Simply adding branches for every eventuality makes the process complex and difficult to maintain.\n",
    "\n",
    "*   **â€œPlanningâ€ is the core solution**: Mimicking how humans solve problems, we elevate the Agent from a â€œtask executorâ€ to a â€œsolution planner.â€ It no longer passively executes fixed steps but autonomously generates and adjusts action plans around the userâ€™s ultimate â€œgoal.â€\n",
    "\n",
    "*   **Translating plans into action**: You can guide the LLM to generate structured plans (e.g., JSON or code) for precise machine execution. A more advanced method is to provide the Agent with a code interpreter, enabling it to dynamically create and use new tools during planning, breaking through the limitations of preset capabilities.\n",
    "\n",
    "*   **Balancing stability and flexibility**: â€œAutonomous planningâ€ is suitable for exploring unknown, variable innovation tasks, while â€œfixed workflowsâ€ ensure the stability and efficiency of core business. In a production environment, you need to combine strategies like human-in-the-loop and explore-crystallize, making informed choices between these two modes based on specific business needs.\n",
    "\n",
    "## 5 Multi-agent collaboration\n",
    "\n",
    "### 5.1 Collaborating like a human team\n",
    "\n",
    "One day, your colleague suggested: Can the bot participate in developing course drafts? For example, writing a draft for an interactive course on Pandas data analysis. Of course, the bots should ideally handle courses from various domains, which might have different work stages. You will find that this is a more general task.\n",
    "\n",
    "You learned before:\n",
    "- For multi-stage tasks like writing, you cannot have a single Agent complete all tasks, as this often leads to the Agent forgetting things and poor work quality. It should be broken down into multiple steps, with each specialized step handled by a different expert Agent.\n",
    "- For creative, diverse tasks like writing, the steps for different types of course writing vary. You cannot enumerate all writing steps and hardcode them into workflows. You can try to let the Agent plan the writing process itself.\n",
    "\n",
    "So, the problem now becomes how to effectively organize multiple Agents, allowing them to plan and execute in parallel while also integrating their final work results.\n",
    "\n",
    "To achieve this, you can draw inspiration from how human expert teams work. Human experts have their respective areas of expertise, and they collaborate to complete complex tasks, often processing tasks in parallel. Therefore, you can also form an Agent Team, where each Agent is an expert in a relevant field, and they divide labor and collaborate in parallel.\n",
    "\n",
    "### 5.2 Two collaboration patterns\n",
    "\n",
    "In terms of specific implementation, human expert teams typically follow two common patterns: one is decomposition and execution led by a project manager, and the other is brainstorming around a whiteboard. In multi-agent systems, these correspond to the hierarchical planning pattern and the co-creation collaboration pattern, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fc39f0",
   "metadata": {},
   "source": [
    "#### 5.2.1 **Pattern one: Hierarchical/team leader pattern**\n",
    "\n",
    "This is the most direct simulation of how a â€œproject teamâ€ works, characterized by a centralized star-shaped structure. It introduces two roles:\n",
    "\n",
    "1.  **Leader Agent**: In this example, it could be a â€œCourse Project Managerâ€ Agent. It is responsible for receiving and understanding top-level tasks (e.g., â€œWrite a Pandas data analysis courseâ€), breaking them down into multiple specific subtasks (â€œDesign teaching outline,â€ â€œProvide core cases and code,â€ â€œWrite course textâ€), and assigning these subtasks to appropriate team members. It is also responsible for tracking overall progress and, after all members complete their tasks, aggregating the results to form the final course document.\n",
    "2.  **Member Agents**: Each possesses expertise in a specific domain (teaching designer, data scientist, content writer), focusing on executing assigned subtasks and reporting back to the Leader upon completion.\n",
    "\n",
    "<img src=\"https://img.alicdn.com/imgextra/i3/O1CN01l9c4OX1lIAF6FPbHZ_!!6000000004795-55-tps-2028-572.svg\" width=\"700\">\n",
    "\n",
    "In AgentScope, you can implement the hierarchical planning pattern using a handoff mechanism. In this pattern, the Leader Agent treats each domain expert as a tool, and task assignment and reporting are achieved through tool calls. AgentScope also supports asynchronous tool calls and dynamic tool extension, meaning you can execute multiple expert Agents concurrently and even allow the Leader Agent to create expert Agents in real-time as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f73bcddf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T08:52:09.093800Z",
     "iopub.status.busy": "2025-11-24T08:52:09.093561Z",
     "iopub.status.idle": "2025-11-24T08:54:15.583737Z",
     "shell.execute_reply": "2025-11-24T08:54:15.583187Z",
     "shell.execute_reply.started": "2025-11-24T08:52:09.093780Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-level task received by project manager:\n",
      "Please create a short course draft for beginners on Pandas data analysis.\n",
      "==================================================\n",
      "ProjectLeader: {\n",
      "    \"type\": \"tool_use\",\n",
      "    \"id\": \"call_ee95c4fc5a2e45b6bcbf4b\",\n",
      "    \"name\": \"invoke_designer_li\",\n",
      "    \"input\": {\n",
      "        \"task_description\": \"Create an initial course outline and define clear learning objectives for a beginner-level course on Pandas data analysis. The course should be short and focus on foundational concepts.\"\n",
      "    }\n",
      "}\n",
      "\n",
      "--- Task assignment: Calling instructional designer Teacher Li ---\n",
      "DesignerLi: Sure! Here's a short, beginner-level course outline for \"Introduction to Pandas Data Analysis,\" with clearly defined learning objectives and a logical progression from foundational to practical concepts.\n",
      "\n",
      "---\n",
      "\n",
      "# ğŸ“˜ Course Title: Introduction to Pandas Data Analysis (Beginner Level)\n",
      "\n",
      "**Duration:** 4 sessions (2 hours each) or 1-week intensive course\n",
      "\n",
      "**Target Audience:** Beginners with basic Python knowledge (familiarity with variables, loops, and functions)\n",
      "\n",
      "**Overall Goal:** Equip learners with foundational skills to load, explore, manipulate, and analyze data using Pandas.\n",
      "\n",
      "---\n",
      "\n",
      "## ğŸ§­ Course Outline & Learning Objectives\n",
      "\n",
      "### ğŸ”¹ Module 1: Getting Started with Pandas\n",
      "- **Learning Objectives:**\n",
      "  - Understand what Pandas is and why it's used in data analysis.\n",
      "  - Install and import Pandas in a Python environment.\n",
      "  - Create and inspect Series and DataFrame objects.\n",
      "  - Differentiate between key data structures: Series vs. DataFrame.\n",
      "\n",
      "- **Key Topics:**\n",
      "  - Importing Pandas (`import pandas as pd`)\n",
      "  - Creating Series and DataFrames from lists/dictionaries\n",
      "  - Viewing data: `.head()`, `.tail()`, `.info()`, `.describe()`\n",
      "\n",
      "- **Interactive Exercise:**\n",
      "  - Create a small DataFrame representing student grades and display basic info.\n",
      "\n",
      "---\n",
      "\n",
      "### ğŸ”¹ Module 2: Loading and Inspecting Data\n",
      "- **Learning Objectives:**\n",
      "  - Load data from CSV and Excel files into a DataFrame.\n",
      "  - Check data types, missing values, and basic statistics.\n",
      "  - Select specific columns and rows using `.loc[]` and `.iloc[]`.\n",
      "\n",
      "- **Key Topics:**\n",
      "  - `pd.read_csv()` and `pd.read_excel()`\n",
      "  - Understanding index and columns\n",
      "  - Selecting data: single columns, multiple columns, row slicing\n",
      "  - Handling missing data: `.isna().sum()`\n",
      "\n",
      "- **Interactive Exercise:**\n",
      "  - Load a sample dataset (e.g., Titanic or sales data) and explore its structure.\n",
      "\n",
      "---\n",
      "\n",
      "### ğŸ”¹ Module 3: Data Cleaning and Manipulation\n",
      "- **Learning Objectives:**\n",
      "  - Handle missing data (drop or fill).\n",
      "  - Filter data using conditions.\n",
      "  - Add, rename, and drop columns.\n",
      "  - Sort and reset index.\n",
      "\n",
      "- **Key Topics:**\n",
      "  - Dropping rows/columns: `.drop()`\n",
      "  - Filling missing values: `.fillna()`\n",
      "  - Filtering with boolean indexing (e.g., `df[df['age'] > 30]`)\n",
      "  - Sorting: `.sort_values()`\n",
      "\n",
      "- **Interactive Exercise:**\n",
      "  - Clean a messy dataset by handling missing values and filtering relevant records.\n",
      "\n",
      "---\n",
      "\n",
      "### ğŸ”¹ Module 4: Basic Analysis and Project\n",
      "- **Learning Objectives:**\n",
      "  - Compute descriptive statistics (mean, median, count, etc.).\n",
      "  - Group data using `.groupby()` and aggregate results.\n",
      "  - Save cleaned/analyzed data back to CSV.\n",
      "  - Apply all skills in a mini project.\n",
      "\n",
      "- **Key Topics:**\n",
      "  - `.groupby()` and aggregation (`.sum()`, `.mean()`)\n",
      "  - Value counts: `.value_counts()`\n",
      "  - Exporting data: `.to_csv()`\n",
      "\n",
      "- **Capstone Project:**\n",
      "  - Analyze a real-world dataset (e.g., restaurant tips or car sales):\n",
      "    - Load the data\n",
      "    - Clean missing values\n",
      "    - Answer questions like:\n",
      "      - \"What is the average tip by day?\"\n",
      "      - \"Which car brand appears most frequently?\"\n",
      "    - Export the cleaned dataset\n",
      "\n",
      "---\n",
      "\n",
      "## âœ… Learning Outcomes\n",
      "By the end of this course, learners will be able to:\n",
      "- Use Pandas to load, view, and explore datasets.\n",
      "- Perform essential data cleaning and transformation tasks.\n",
      "- Conduct basic exploratory data analysis.\n",
      "- Confidently work with real data in future projects or courses.\n",
      "\n",
      "Let me know if you'd like Jupyter notebook templates, dataset suggestions, or quiz questions!\n",
      "system: {\n",
      "    \"type\": \"tool_result\",\n",
      "    \"id\": \"call_ee95c4fc5a2e45b6bcbf4b\",\n",
      "    \"name\": \"invoke_designer_li\",\n",
      "    \"output\": \"Sure! Here's a short, beginner-level course outline for \\\"Introduction to Pandas Data Analysis,\\\" with clearly defined learning objectives and a logical progression from foundational to practical concepts.\\n\\n---\\n\\n# ğŸ“˜ Course Title: Introduction to Pandas Data Analysis (Beginner Level)\\n\\n**Duration:** 4 sessions (2 hours each) or 1-week intensive course\\n\\n**Target Audience:** Beginners with basic Python knowledge (familiarity with variables, loops, and functions)\\n\\n**Overall Goal:** Equip learners with foundational skills to load, explore, manipulate, and analyze data using Pandas.\\n\\n---\\n\\n## ğŸ§­ Course Outline & Learning Objectives\\n\\n### ğŸ”¹ Module 1: Getting Started with Pandas\\n- **Learning Objectives:**\\n  - Understand what Pandas is and why it's used in data analysis.\\n  - Install and import Pandas in a Python environment.\\n  - Create and inspect Series and DataFrame objects.\\n  - Differentiate between key data structures: Series vs. DataFrame.\\n\\n- **Key Topics:**\\n  - Importing Pandas (`import pandas as pd`)\\n  - Creating Series and DataFrames from lists/dictionaries\\n  - Viewing data: `.head()`, `.tail()`, `.info()`, `.describe()`\\n\\n- **Interactive Exercise:**\\n  - Create a small DataFrame representing student grades and display basic info.\\n\\n---\\n\\n### ğŸ”¹ Module 2: Loading and Inspecting Data\\n- **Learning Objectives:**\\n  - Load data from CSV and Excel files into a DataFrame.\\n  - Check data types, missing values, and basic statistics.\\n  - Select specific columns and rows using `.loc[]` and `.iloc[]`.\\n\\n- **Key Topics:**\\n  - `pd.read_csv()` and `pd.read_excel()`\\n  - Understanding index and columns\\n  - Selecting data: single columns, multiple columns, row slicing\\n  - Handling missing data: `.isna().sum()`\\n\\n- **Interactive Exercise:**\\n  - Load a sample dataset (e.g., Titanic or sales data) and explore its structure.\\n\\n---\\n\\n### ğŸ”¹ Module 3: Data Cleaning and Manipulation\\n- **Learning Objectives:**\\n  - Handle missing data (drop or fill).\\n  - Filter data using conditions.\\n  - Add, rename, and drop columns.\\n  - Sort and reset index.\\n\\n- **Key Topics:**\\n  - Dropping rows/columns: `.drop()`\\n  - Filling missing values: `.fillna()`\\n  - Filtering with boolean indexing (e.g., `df[df['age'] > 30]`)\\n  - Sorting: `.sort_values()`\\n\\n- **Interactive Exercise:**\\n  - Clean a messy dataset by handling missing values and filtering relevant records.\\n\\n---\\n\\n### ğŸ”¹ Module 4: Basic Analysis and Project\\n- **Learning Objectives:**\\n  - Compute descriptive statistics (mean, median, count, etc.).\\n  - Group data using `.groupby()` and aggregate results.\\n  - Save cleaned/analyzed data back to CSV.\\n  - Apply all skills in a mini project.\\n\\n- **Key Topics:**\\n  - `.groupby()` and aggregation (`.sum()`, `.mean()`)\\n  - Value counts: `.value_counts()`\\n  - Exporting data: `.to_csv()`\\n\\n- **Capstone Project:**\\n  - Analyze a real-world dataset (e.g., restaurant tips or car sales):\\n    - Load the data\\n    - Clean missing values\\n    - Answer questions like:\\n      - \\\"What is the average tip by day?\\\"\\n      - \\\"Which car brand appears most frequently?\\\"\\n    - Export the cleaned dataset\\n\\n---\\n\\n## âœ… Learning Outcomes\\nBy the end of this course, learners will be able to:\\n- Use Pandas to load, view, and explore datasets.\\n- Perform essential data cleaning and transformation tasks.\\n- Conduct basic exploratory data analysis.\\n- Confidently work with real data in future projects or courses.\\n\\nLet me know if you'd like Jupyter notebook templates, dataset suggestions, or quiz questions!\"\n",
      "}\n",
      "ProjectLeader: {\n",
      "    \"type\": \"tool_use\",\n",
      "    \"id\": \"call_5a6af1ea374e43dba9ce7c\",\n",
      "    \"name\": \"invoke_scientist_wang\",\n",
      "    \"input\": {\n",
      "        \"context\": \"Course outline created by Teacher Li:\\n\\nModule 1: Getting Started with Pandas\\n- Create Series and DataFrames\\n- Use .head(), .info(), .describe()\\n\\nModule 2: Loading and Inspecting Data\\n- Read CSV/Excel files\\n- Select data with .loc[] and .iloc[]\\n- Check for missing values\\n\\nModule 3: Data Cleaning and Manipulation\\n- Handle missing data\\n- Filter with boolean indexing\\n- Add/drop columns, sort values\\n\\nModule 4: Basic Analysis and Project\\n- Use .groupby() and aggregations\\n- Save data to CSV\\n- Capstone project on real dataset\",\n",
      "        \"task_description\": \"Provide accurate technical explanations, key code examples, and realistic data scenarios for each module in the course outline. Focus on beginner-friendly syntax and common pitfalls to avoid.\"\n",
      "    }\n",
      "}\n",
      "\n",
      "--- Task assignment: Calling data scientist Engineer Wang ---\n",
      "ScientistWang: I'll provide comprehensive technical content for each module in the course outline, with practical examples and real-world scenarios.\\\n",
      "# Module 1: Getting Started with Pandas\n",
      "\n",
      "## Creating Series and DataFrames\n",
      "A Series is a one-dimensional array with labeled indices. A DataFrame is a two-dimensional table with labeled axes.\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "\n",
      "# Create Series\n",
      "ages = pd.Series([25, 30, 35, 40], name='age')\n",
      "print(ages)\n",
      "\n",
      "# Create DataFrame from dictionary\n",
      "customer_data = {\n",
      "    'name': ['Alice', 'Bob', 'Charlie', 'Diana'],\n",
      "    'age': [25, 30, 35, 40],\n",
      "    'city': ['Beijing', 'Shanghai', 'Guangzhou', 'Shenzhen'],\n",
      "    'salary': [8000, 12000, 15000, 18000]\n",
      "}\n",
      "customers = pd.DataFrame(customer_data)\n",
      "```\n",
      "\n",
      "## Essential Inspection Methods\n",
      "\n",
      "```python\n",
      "# .head() - View first 5 rows (or specify number)\n",
      "print(customers.head())\n",
      "print(customers.head(2))\n",
      "\n",
      "# .info() - Get dataset overview\n",
      "customers.info()\n",
      "# Shows: row count, column names, non-null counts, data types, memory usage\n",
      "\n",
      "# .describe() - Statistical summary for numeric columns\n",
      "customers.describe()\n",
      "# Includes count, mean, std, min, quartiles, max\n",
      "\n",
      "# Common pitfalls to avoid:\n",
      "# 1. Forgetting to import pandas\n",
      "# 2. Using list instead of dictionary when creating DataFrame\n",
      "# 3. Not checking data types after creation\n",
      "system: {\n",
      "    \"type\": \"tool_result\",\n",
      "    \"id\": \"call_5a6af1ea374e43dba9ce7c\",\n",
      "    \"name\": \"invoke_scientist_wang\",\n",
      "    \"output\": \"I'll provide comprehensive technical content for each module in the course outline, with practical examples and real-world scenarios.\\n\\n# Module 1: Getting Started with Pandas\\n\\n## Creating Series and DataFrames\\nA Series is a one-dimensional array with labeled indices. A DataFrame is a two-dimensional table with labeled axes.\\n\\n```python\\nimport pandas as pd\\nimport numpy as np\\n\\n# Create Series\\nages = pd.Series([25, 30, 35, 40], name='age')\\nprint(ages)\\n\\n# Create DataFrame from dictionary\\ncustomer_data = {\\n    'name': ['Alice', 'Bob', 'Charlie', 'Diana'],\\n    'age': [25, 30, 35, 40],\\n    'city': ['Beijing', 'Shanghai', 'Guangzhou', 'Shenzhen'],\\n    'salary': [8000, 12000, 15000, 18000]\\n}\\ncustomers = pd.DataFrame(customer_data)\\n```\\n\\n## Essential Inspection Methods\\n\\n```python\\n# .head() - View first 5 rows (or specify number)\\nprint(customers.head())\\nprint(customers.head(2))\\n\\n# .info() - Get dataset overview\\ncustomers.info()\\n# Shows: row count, column names, non-null counts, data types, memory usage\\n\\n# .describe() - Statistical summary for numeric columns\\ncustomers.describe()\\n# Includes count, mean, std, min, quartiles, max\\n\\n# Common pitfalls to avoid:\\n# 1. Forgetting to import pandas\\n# 2. Using list instead of dictionary when creating DataFrame\\n# 3. Not checking data types after creation\"\n",
      "}\n",
      "ProjectLeader: {\n",
      "    \"type\": \"tool_use\",\n",
      "    \"id\": \"call_7a88acafb91e4b87a71bb8\",\n",
      "    \"name\": \"invoke_writer_zhang\",\n",
      "    \"input\": {\n",
      "        \"context\": \"Course outline from Teacher Li and technical content from Engineer Wang, including:\\n\\n- 4-module structure covering Pandas fundamentals\\n- Key concepts: Series/DataFrame creation, data loading, inspection methods (.head/.info/.describe)\\n- Data selection with .loc/.iloc\\n- Missing data handling\\n- Filtering with boolean indexing\\n- Groupby operations and aggregations\\n- Complete code examples for each concept\\n- Common beginner pitfalls to avoid\\n- Real-world dataset scenarios\",\n",
      "        \"task_description\": \"Transform the technical outline and code examples into a complete, engaging, and easy-to-follow course draft for beginners. Use clear explanations, conversational tone, and include practical exercises after each section.\"\n",
      "    }\n",
      "}\n",
      "\n",
      "--- Task assignment: Calling content writer Xiao Zhang ---\n",
      "WriterZhang: # Welcome to \"Data Explorers: Mastering Pandas for Beginners\" ğŸŒŸ\n",
      "\n",
      "Hello future data wizard! I'm Xiao Zhang, your guide on this exciting journey into the world of data analysis with Pandas. Think of this course as your magic spellbookâ€”each module teaches you new incantations (code) to tame wild datasets and uncover hidden insights.\n",
      "\n",
      "We'll use a real-world scenario throughout: **CoffeeBean Co.**, a growing coffee chain tracking sales across 50 stores. Our mission? Transform raw sales records into actionable business intelligenceâ€”one Pandas operation at a time.\n",
      "\n",
      "---\n",
      "\n",
      "## Module 1: Meeting Your Data Companions â€” Series & DataFrame\n",
      "\n",
      "### The Pandas Zoo: Series vs DataFrame\n",
      "Imagine a **Series** as a single column in Excelâ€”say, just the 'Daily Sales' numbers. It's like a solo musician playing one instrument.\n",
      "\n",
      "A **DataFrame**? That's the entire bandâ€”a table with multiple columns (Sales, Location, Date, Coffee Type) harmonizing together.\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# Creating our first Series (solo violin)\n",
      "sales_series = pd.Series([450, 600, 320, 890], \n",
      "                         name=\"Daily_Sales\")\n",
      "print(sales_series)\n",
      "\n",
      "# Creating our first DataFrame (full orchestra)\n",
      "sales_data = pd.DataFrame({\n",
      "    'Date': ['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04'],\n",
      "    'Store': ['Downtown', 'Uptown', 'Midtown', 'Waterfront'],\n",
      "    'Beverage': ['Latte', 'Espresso', 'Cold Brew', 'Mocha'],\n",
      "    'Sales': [450, 600, 320, 890]\n",
      "})\n",
      "print(sales_data)\n",
      "```\n",
      "\n",
      "### Loading Real Data: The Morning Brew Ritual â˜•\n",
      "Most often, your data lives in CSV files (like spreadsheets). Let's load CoffeeBean Co.'s actual sales log:\n",
      "\n",
      "```python\n",
      "# Load data from file (our digital coffee bean sack)\n",
      "df = pd.read_csv('coffee_sales_jan2023.csv')\n",
      "\n",
      "# First sip: preview your data\n",
      "df.head()  # Shows top 5 rows - like skimming the menu\n",
      "```\n",
      "\n",
      "### Inspection Tools: Your Data Stethoscope\n",
      "Diagnose your dataset's health:\n",
      "\n",
      "```python\n",
      "df.info()      # \"Vital signs\": column types, missing values, memory\n",
      "df.describe()  # \"Body scan\": statistics (mean, std, min/max) for numeric columns\n",
      "```\n",
      "\n",
      "ğŸ” **Beginner Pitfall Alert**: Always run `.info()` first! I once spent 2 hours debugging why calculations failedâ€”turned out dates were loaded as text. Save yourself the headache.\n",
      "\n",
      "âœ… **Exercise 1**: \n",
      "1. Create a Series containing last week's pastry sales: [120, 95, 140, 110, 135, 160, 180]\n",
      "2. Build a DataFrame for 3 stores with columns: Name, City, Opened_Year (choose years between 2018-2022)\n",
      "3. Download sample CSV from [mockaroo.com](https://www.mockaroo.com/) and load it using `pd.read_csv()`\n",
      "\n",
      "---\n",
      "\n",
      "## Module 2: The Art of Data Selection â€” Loc & Iloc Magic\n",
      "\n",
      "### .loc: Label-Based Navigation (GPS Coordinates)\n",
      "Use actual row/column names. Think: \"Give me data WHERE conditions are met.\"\n",
      "\n",
      "```python\n",
      "# Select specific rows and columns by label\n",
      "df.loc[0, 'Sales']           # Single cell: row 0, 'Sales' column\n",
      "df.loc[:2, ['Store','Sales']] # Rows 0-2, only Store & Sales columns\n",
      "\n",
      "df.loc[df['Sales'] > 500]     # ALL rows where Sales exceed $500\n",
      "```\n",
      "\n",
      "### .iloc: Position-Based Navigation (Treasure Map)\n",
      "Use numerical positions (0-indexed). \"Give me the Nth item.\"\n",
      "\n",
      "```python\n",
      "# Select by position\n",
      "df.iloc[0, 3]     # First row, fourth column (Sales value)\n",
      "df.iloc[1:4, :]   # Rows 1-3, all columns\n",
      "```\n",
      "\n",
      "ğŸ’¡ **Pro Tip**: `.loc` includes the end index (`df.loc[0:2]` gives 3 rows), while Python slicing excludes it. This trips up everyone at first!\n",
      "\n",
      "### Filtering: The Bouncer at the Club Door ğŸ•¶ï¸\n",
      "Only let relevant data pass using boolean logic:\n",
      "\n",
      "```python\n",
      "# Multiple conditions (& = AND, | = OR)\n",
      "premium_stores = df[(df['Sales'] > 700) & (df['Beverage'] == 'Latte')]\n",
      "\n",
      "# Check membership\n",
      "popular_drinks = df[df['Beverage'].isin(['Latte', 'Cold Brew'])]\n",
      "```\n",
      "\n",
      "âœ… **Exercise 2**:\n",
      "1. From your store DataFrame, select all stores opened after 2020 using `.loc`\n",
      "2. Extract the first two rows and first two columns using `.iloc`\n",
      "3. Filter CoffeeBean data to show only 'Espresso' sales below $400\n",
      "\n",
      "---\n",
      "\n",
      "## Module 3: Taming Messy Data â€” Handling Missing Values\n",
      "\n",
      "Real-world data is like unfiltered coffeeâ€”sometimes gritty. Let's clean it.\n",
      "\n",
      "### Diagnosis: Finding the Gaps\n",
      "```python\n",
      "df.isnull().sum()  # Count missing values per column\n",
      "df[df.isnull().any(axis=1)]  # Show entire rows with ANY missing data\n",
      "```\n",
      "\n",
      "### Treatment Options:\n",
      "\n",
      "**Option A: Remove (The Bulldozer Approach)**\n",
      "```python\n",
      "# Drop rows with missing sales\n",
      "df_clean = df.dropna(subset=['Sales'])\n",
      "```\n",
      "\n",
      "**Option B: Fill (The Diplomat)**\n",
      "```python\n",
      "# Fill missing customer ratings with average\n",
      "df['Rating'] = df['Rating'].fillna(df['Rating'].mean())\n",
      "\n",
      "# Forward-fill time series data (use yesterday's value)\n",
      "df['Inventory'] = df['Inventory'].fillna(method='ffill')\n",
      "```\n",
      "\n",
      "âš ï¸ **Critical Warning**: Never drop rows blindly! In CoffeeBean's case, 80% of missing 'Marketing_Spend' data came from new stores. Deleting them would bias our analysis against emerging locations.\n",
      "\n",
      "âœ… **Exercise 3**:\n",
      "1. Create a small DataFrame with intentional NaN values in 'Temperature' column\n",
      "2. Practice both `dropna()` and `fillna()` methods\n",
      "3. Explain in your own words when you'd choose each approach\n",
      "\n",
      "---\n",
      "\n",
      "## Module 4: Groupby & Aggregation â€” Turning Data Dust into Gold\n",
      "\n",
      "### The Split-Apply-Combine Framework\n",
      "Imagine sorting coffee beans by origin, then weighing each pile. That's `groupby`:\n",
      "\n",
      "```python\n",
      "# Group by store, calculate total sales\n",
      "sales_by_store = df.groupby('Store')['Sales'].sum()\n",
      "\n",
      "# Multiple aggregations\n",
      "summary = df.groupby('Beverage').agg({\n",
      "    'Sales': ['count', 'mean', 'sum'],\n",
      "    'Rating': 'mean'\n",
      "})\n",
      "```\n",
      "\n",
      "### Business Insights Unlocked ğŸ”“\n",
      "```python\n",
      "# What's our best-selling beverage by location?\n",
      "best_sellers = df.groupby(['City', 'Beverage'])['Sales'].sum().reset_index()\n",
      "\n",
      "# Find top performer in each region\n",
      "top_performers = best_sellers.loc[best_sellers.groupby('City')['Sales'].idxmax()]\n",
      "```\n",
      "\n",
      "ğŸ“ˆ **Real Impact**: When CoffeeBean ran this analysis, they discovered Cold Brew drove 68% of Uptown's revenueâ€”leading to a city-specific marketing blitz that increased quarterly profits by 23%.\n",
      "\n",
      "âœ… **Final Challenge**:\n",
      "Using a dataset of your choice:\n",
      "1. Group data by a categorical variable\n",
      "2. Apply at least 3 aggregation functions\n",
      "3. Visualize results with `.plot(kind='bar')`\n",
      "\n",
      "---\n",
      "\n",
      "## Final Words of Encouragement âœ¨\n",
      "\n",
      "You've just learned the core toolkit used by professional data analysts daily. Remember Ming, a barista who took this course? She automated her store's inventory reports, saving 6 hours/weekâ€”and got promoted to Assistant Manager within 3 months.\n",
      "\n",
      "Your journey has just begun. Every expert was once a beginner staring at a blinking cursor. Keep experimenting, embrace the errors (they're teaching you!), and soon you'll speak data fluently.\n",
      "\n",
      "Next step? Try analyzing your favorite hobby's dataâ€”book reading logs, workout stats, or recipe collections. The world is full of stories hiding in spreadsheets, waiting for you to uncover them.\n",
      "\n",
      "Happy analyzing!\n",
      "\n",
      "â€” Xiao Zhang, your fellow data explorer\n",
      "system: {\n",
      "    \"type\": \"tool_result\",\n",
      "    \"id\": \"call_7a88acafb91e4b87a71bb8\",\n",
      "    \"name\": \"invoke_writer_zhang\",\n",
      "    \"output\": \"# Welcome to \\\"Data Explorers: Mastering Pandas for Beginners\\\" ğŸŒŸ\\n\\nHello future data wizard! I'm Xiao Zhang, your guide on this exciting journey into the world of data analysis with Pandas. Think of this course as your magic spellbookâ€”each module teaches you new incantations (code) to tame wild datasets and uncover hidden insights.\\n\\nWe'll use a real-world scenario throughout: **CoffeeBean Co.**, a growing coffee chain tracking sales across 50 stores. Our mission? Transform raw sales records into actionable business intelligenceâ€”one Pandas operation at a time.\\n\\n---\\n\\n## Module 1: Meeting Your Data Companions â€” Series & DataFrame\\n\\n### The Pandas Zoo: Series vs DataFrame\\nImagine a **Series** as a single column in Excelâ€”say, just the 'Daily Sales' numbers. It's like a solo musician playing one instrument.\\n\\nA **DataFrame**? That's the entire bandâ€”a table with multiple columns (Sales, Location, Date, Coffee Type) harmonizing together.\\n\\n```python\\nimport pandas as pd\\n\\n# Creating our first Series (solo violin)\\nsales_series = pd.Series([450, 600, 320, 890], \\n                         name=\\\"Daily_Sales\\\")\\nprint(sales_series)\\n\\n# Creating our first DataFrame (full orchestra)\\nsales_data = pd.DataFrame({\\n    'Date': ['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04'],\\n    'Store': ['Downtown', 'Uptown', 'Midtown', 'Waterfront'],\\n    'Beverage': ['Latte', 'Espresso', 'Cold Brew', 'Mocha'],\\n    'Sales': [450, 600, 320, 890]\\n})\\nprint(sales_data)\\n```\\n\\n### Loading Real Data: The Morning Brew Ritual â˜•\\nMost often, your data lives in CSV files (like spreadsheets). Let's load CoffeeBean Co.'s actual sales log:\\n\\n```python\\n# Load data from file (our digital coffee bean sack)\\ndf = pd.read_csv('coffee_sales_jan2023.csv')\\n\\n# First sip: preview your data\\ndf.head()  # Shows top 5 rows - like skimming the menu\\n```\\n\\n### Inspection Tools: Your Data Stethoscope\\nDiagnose your dataset's health:\\n\\n```python\\ndf.info()      # \\\"Vital signs\\\": column types, missing values, memory\\ndf.describe()  # \\\"Body scan\\\": statistics (mean, std, min/max) for numeric columns\\n```\\n\\nğŸ” **Beginner Pitfall Alert**: Always run `.info()` first! I once spent 2 hours debugging why calculations failedâ€”turned out dates were loaded as text. Save yourself the headache.\\n\\nâœ… **Exercise 1**: \\n1. Create a Series containing last week's pastry sales: [120, 95, 140, 110, 135, 160, 180]\\n2. Build a DataFrame for 3 stores with columns: Name, City, Opened_Year (choose years between 2018-2022)\\n3. Download sample CSV from [mockaroo.com](https://www.mockaroo.com/) and load it using `pd.read_csv()`\\n\\n---\\n\\n## Module 2: The Art of Data Selection â€” Loc & Iloc Magic\\n\\n### .loc: Label-Based Navigation (GPS Coordinates)\\nUse actual row/column names. Think: \\\"Give me data WHERE conditions are met.\\\"\\n\\n```python\\n# Select specific rows and columns by label\\ndf.loc[0, 'Sales']           # Single cell: row 0, 'Sales' column\\ndf.loc[:2, ['Store','Sales']] # Rows 0-2, only Store & Sales columns\\n\\ndf.loc[df['Sales'] > 500]     # ALL rows where Sales exceed $500\\n```\\n\\n### .iloc: Position-Based Navigation (Treasure Map)\\nUse numerical positions (0-indexed). \\\"Give me the Nth item.\\\"\\n\\n```python\\n# Select by position\\ndf.iloc[0, 3]     # First row, fourth column (Sales value)\\ndf.iloc[1:4, :]   # Rows 1-3, all columns\\n```\\n\\nğŸ’¡ **Pro Tip**: `.loc` includes the end index (`df.loc[0:2]` gives 3 rows), while Python slicing excludes it. This trips up everyone at first!\\n\\n### Filtering: The Bouncer at the Club Door ğŸ•¶ï¸\\nOnly let relevant data pass using boolean logic:\\n\\n```python\\n# Multiple conditions (& = AND, | = OR)\\npremium_stores = df[(df['Sales'] > 700) & (df['Beverage'] == 'Latte')]\\n\\n# Check membership\\npopular_drinks = df[df['Beverage'].isin(['Latte', 'Cold Brew'])]\\n```\\n\\nâœ… **Exercise 2**:\\n1. From your store DataFrame, select all stores opened after 2020 using `.loc`\\n2. Extract the first two rows and first two columns using `.iloc`\\n3. Filter CoffeeBean data to show only 'Espresso' sales below $400\\n\\n---\\n\\n## Module 3: Taming Messy Data â€” Handling Missing Values\\n\\nReal-world data is like unfiltered coffeeâ€”sometimes gritty. Let's clean it.\\n\\n### Diagnosis: Finding the Gaps\\n```python\\ndf.isnull().sum()  # Count missing values per column\\ndf[df.isnull().any(axis=1)]  # Show entire rows with ANY missing data\\n```\\n\\n### Treatment Options:\\n\\n**Option A: Remove (The Bulldozer Approach)**\\n```python\\n# Drop rows with missing sales\\ndf_clean = df.dropna(subset=['Sales'])\\n```\\n\\n**Option B: Fill (The Diplomat)**\\n```python\\n# Fill missing customer ratings with average\\ndf['Rating'] = df['Rating'].fillna(df['Rating'].mean())\\n\\n# Forward-fill time series data (use yesterday's value)\\ndf['Inventory'] = df['Inventory'].fillna(method='ffill')\\n```\\n\\nâš ï¸ **Critical Warning**: Never drop rows blindly! In CoffeeBean's case, 80% of missing 'Marketing_Spend' data came from new stores. Deleting them would bias our analysis against emerging locations.\\n\\nâœ… **Exercise 3**:\\n1. Create a small DataFrame with intentional NaN values in 'Temperature' column\\n2. Practice both `dropna()` and `fillna()` methods\\n3. Explain in your own words when you'd choose each approach\\n\\n---\\n\\n## Module 4: Groupby & Aggregation â€” Turning Data Dust into Gold\\n\\n### The Split-Apply-Combine Framework\\nImagine sorting coffee beans by origin, then weighing each pile. That's `groupby`:\\n\\n```python\\n# Group by store, calculate total sales\\nsales_by_store = df.groupby('Store')['Sales'].sum()\\n\\n# Multiple aggregations\\nsummary = df.groupby('Beverage').agg({\\n    'Sales': ['count', 'mean', 'sum'],\\n    'Rating': 'mean'\\n})\\n```\\n\\n### Business Insights Unlocked ğŸ”“\\n```python\\n# What's our best-selling beverage by location?\\nbest_sellers = df.groupby(['City', 'Beverage'])['Sales'].sum().reset_index()\\n\\n# Find top performer in each region\\ntop_performers = best_sellers.loc[best_sellers.groupby('City')['Sales'].idxmax()]\\n```\\n\\nğŸ“ˆ **Real Impact**: When CoffeeBean ran this analysis, they discovered Cold Brew drove 68% of Uptown's revenueâ€”leading to a city-specific marketing blitz that increased quarterly profits by 23%.\\n\\nâœ… **Final Challenge**:\\nUsing a dataset of your choice:\\n1. Group data by a categorical variable\\n2. Apply at least 3 aggregation functions\\n3. Visualize results with `.plot(kind='bar')`\\n\\n---\\n\\n## Final Words of Encouragement âœ¨\\n\\nYou've just learned the core toolkit used by professional data analysts daily. Remember Ming, a barista who took this course? She automated her store's inventory reports, saving 6 hours/weekâ€”and got promoted to Assistant Manager within 3 months.\\n\\nYour journey has just begun. Every expert was once a beginner staring at a blinking cursor. Keep experimenting, embrace the errors (they're teaching you!), and soon you'll speak data fluently.\\n\\nNext step? Try analyzing your favorite hobby's dataâ€”book reading logs, workout stats, or recipe collections. The world is full of stories hiding in spreadsheets, waiting for you to uncover them.\\n\\nHappy analyzing!\\n\\nâ€” Xiao Zhang, your fellow data explorer\"\n",
      "}\n",
      "ProjectLeader: # ğŸ“˜ Complete Course Draft: Data Explorers - Mastering Pandas for Beginners\n",
      "\n",
      "## Course Overview\n",
      "**Title:** Data Explorers: Mastering Pandas for Beginners\n",
      "**Duration:** 4 sessions (2 hours each) or 1-week intensive course\n",
      "**Target Audience:** Beginners with basic Python knowledge\n",
      "**Overall Goal:** Equip learners with foundational skills to load, explore, manipulate, and analyze data using Pandas.\\\n",
      "By the end of this course, learners will be able to use Pandas to load, view, explore, clean, and analyze datasetsâ€”gaining confidence to work with real data in future projects.\n",
      "\n",
      "---\n",
      "\n",
      "## Module 1: Meeting Your Data Companions â€” Series & DataFrame\n",
      "\n",
      "### The Pandas Zoo: Series vs DataFrame\n",
      "A **Series** is a one-dimensional array with labeled indicesâ€”like a single column in Excel containing just 'Daily Sales' numbers.\n",
      "\n",
      "A **DataFrame** is a two-dimensional table with labeled axesâ€”a complete dataset with multiple columns like Sales, Location, Date, and Coffee Type.\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# Creating a Series (single column)\n",
      "sales_series = pd.Series([450, 600, 320, 890], name=\"Daily_Sales\")\n",
      "print(sales_series)\n",
      "\n",
      "# Creating a DataFrame (complete table)\n",
      "sales_data = pd.DataFrame({\n",
      "    'Date': ['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04'],\n",
      "    'Store': ['Downtown', 'Uptown', 'Midtown', 'Waterfront'],\n",
      "    'Beverage': ['Latte', 'Espresso', 'Cold Brew', 'Mocha'],\n",
      "    'Sales': [450, 600, 320, 890]\n",
      "})\n",
      "print(sales_data)\n",
      "```\n",
      "\n",
      "### Loading Real Data: The Morning Brew Ritual â˜•\n",
      "Most often, your data lives in CSV files. Let's load a sample dataset:\n",
      "\n",
      "```python\n",
      "# Load data from file\n",
      "df = pd.read_csv('coffee_sales_jan2023.csv')\n",
      "\n",
      "# Preview your data\n",
      "df.head()  # Shows top 5 rows\n",
      "df.info()  # Dataset overview: column types, missing values\n",
      "df.describe()  # Statistical summary for numeric columns\n",
      "```\n",
      "\n",
      "ğŸ” **Beginner Pitfall Alert**: Always run `.info()` first! Dates loaded as text can break calculations later.\n",
      "\n",
      "âœ… **Exercise 1**:\n",
      "1. Create a Series containing last week's pastry sales: [120, 95, 140, 110, 135, 160, 180]\n",
      "2. Build a DataFrame for 3 stores with columns: Name, City, Opened_Year (choose years between 2018-2022)\n",
      "3. Download a sample CSV from [mockaroo.com](https://www.mockaroo.com/) and load it using `pd.read_csv()`\n",
      "\n",
      "---\n",
      "\n",
      "## Module 2: The Art of Data Selection â€” Loc & Iloc Magic\n",
      "\n",
      "### .loc: Label-Based Navigation (GPS Coordinates)\n",
      "Use actual row/column names to select data WHERE conditions are met.\n",
      "\n",
      "```python\n",
      "# Select specific cells by label\n",
      "df.loc[0, 'Sales']           # Single cell: row 0, 'Sales' column\n",
      "df.loc[:2, ['Store','Sales']] # Rows 0-2, only Store & Sales columns\n",
      "df.loc[df['Sales'] > 500]     # All rows where Sales exceed $500\n",
      "```\n",
      "\n",
      "### .iloc: Position-Based Navigation (Treasure Map)\n",
      "Use numerical positions (0-indexed) to access data by position.\n",
      "\n",
      "```python\n",
      "# Select by position\n",
      "df.iloc[0, 3]     # First row, fourth column (Sales value)\n",
      "df.iloc[1:4, :]   # Rows 1-3, all columns\n",
      "```\n",
      "\n",
      "ğŸ’¡ **Pro Tip**: `.loc` includes the end index (`df.loc[0:2]` gives 3 rows), while Python slicing excludes it.\n",
      "\n",
      "### Filtering: The Bouncer at the Club Door ğŸ•¶ï¸\n",
      "Use boolean logic to filter data:\n",
      "\n",
      "```python\n",
      "# Multiple conditions (& = AND, | = OR)\n",
      "premium_stores = df[(df['Sales'] > 700) & (df['Beverage'] == 'Latte')]\n",
      "\n",
      "# Check membership\n",
      "popular_drinks = df[df['Beverage'].isin(['Latte', 'Cold Brew'])]\n",
      "```\n",
      "\n",
      "âœ… **Exercise 2**:\n",
      "1. From your store DataFrame, select all stores opened after 2020 using `.loc`\n",
      "2. Extract the first two rows and first two columns using `.iloc`\n",
      "3. Filter CoffeeBean data to show only 'Espresso' sales below $400\n",
      "\n",
      "---\n",
      "\n",
      "## Module 3: Taming Messy Data â€” Handling Missing Values\n",
      "\n",
      "Real-world data often has gaps. Here's how to handle them:\n",
      "\n",
      "### Diagnosis: Finding the Gaps\n",
      "```python\n",
      "df.isnull().sum()  # Count missing values per column\n",
      "df[df.isnull().any(axis=1)]  # Show entire rows with ANY missing data\n",
      "```\n",
      "\n",
      "### Treatment Options:\n",
      "\n",
      "**Option A: Remove (The Bulldozer Approach)**\n",
      "```python\n",
      "# Drop rows with missing sales\n",
      "df_clean = df.dropna(subset=['Sales'])\n",
      "```\n",
      "\n",
      "**Option B: Fill (The Diplomat)**\n",
      "```python\n",
      "# Fill missing ratings with average\n",
      "df['Rating'] = df['Rating'].fillna(df['Rating'].mean())\n",
      "\n",
      "# Forward-fill time series data (use yesterday's value)\n",
      "df['Inventory'] = df['Inventory'].fillna(method='ffill')\n",
      "```\n",
      "\n",
      "âš ï¸ **Critical Warning**: Never drop rows blindly! In CoffeeBean's case, 80% of missing 'Marketing_Spend' data came from new stores. Deleting them would bias analysis against emerging locations.\n",
      "\n",
      "âœ… **Exercise 3**:\n",
      "1. Create a small DataFrame with intentional NaN values in 'Temperature' column\n",
      "2. Practice both `dropna()` and `fillna()` methods\n",
      "3. Explain when you'd choose each approach\n",
      "\n",
      "---\n",
      "\n",
      "## Module 4: Groupby & Aggregation â€” Turning Data Dust into Gold\n",
      "\n",
      "### The Split-Apply-Combine Framework\n",
      "Group data, apply functions, and combine results:\n",
      "\n",
      "```python\n",
      "# Group by store, calculate total sales\n",
      "sales_by_store = df.groupby('Store')['Sales'].sum()\n",
      "\n",
      "# Multiple aggregations\n",
      "summary = df.groupby('Beverage').agg({\n",
      "    'Sales': ['count', 'mean', 'sum'],\n",
      "    'Rating': 'mean'\n",
      "})\n",
      "```\n",
      "\n",
      "### Business Insights Unlocked ğŸ”“\n",
      "```python\n",
      "# What's our best-selling beverage by location?\n",
      "best_sellers = df.groupby(['City', 'Beverage'])['Sales'].sum().reset_index()\n",
      "\n",
      "# Find top performer in each region\n",
      "top_performers = best_sellers.loc[best_sellers.groupby('City')['Sales'].idxmax()]\n",
      "```\n",
      "\n",
      "ğŸ“ˆ **Real Impact**: When CoffeeBean ran this analysis, they discovered Cold Brew drove 68% of Uptown's revenueâ€”leading to a city-specific marketing blitz that increased quarterly profits by 23%.\n",
      "\n",
      "âœ… **Final Challenge**:\n",
      "Using a dataset of your choice:\n",
      "1. Group data by a categorical variable\n",
      "2. Apply at least 3 aggregation functions\n",
      "3. Visualize results with `.plot(kind='bar')`\n",
      "\n",
      "---\n",
      "\n",
      "## Final Words of Encouragement âœ¨\n",
      "\n",
      "You've just learned the core toolkit used by professional data analysts daily. Remember Ming, a barista who took this course? She automated her store's inventory reports, saving 6 hours/weekâ€”and got promoted to Assistant Manager within 3 months.\n",
      "\n",
      "Your journey has just begun. Every expert was once a beginner staring at a blinking cursor. Keep experimenting, embrace the errors (they're teaching you!), and soon you'll speak data fluently.\n",
      "\n",
      "Next step? Try analyzing your favorite hobby's dataâ€”book reading logs, workout stats, or recipe collections. The world is full of stories hiding in spreadsheets, waiting for you to uncover them.\n",
      "\n",
      "Happy analyzing!\n",
      "\n",
      "â€” Xiao Zhang, your fellow data explorer\n",
      "\n",
      "==================================================\n",
      "  Project manager's final summary report:\n",
      "==================================================\n",
      "\n",
      "# ğŸ“˜ Complete Course Draft: Data Explorers - Mastering Pandas for Beginners\n",
      "\n",
      "## Course Overview\n",
      "**Title:** Data Explorers: Mastering Pandas for Beginners\n",
      "**Duration:** 4 sessions (2 hours each) or 1-week intensive course\n",
      "**Target Audience:** Beginners with basic Python knowledge\n",
      "**Overall Goal:** Equip learners with foundational skills to load, explore, manipulate, and analyze data using Pandas.\n",
      "\n",
      "By the end of this course, learners will be able to use Pandas to load, view, explore, clean, and analyze datasetsâ€”gaining confidence to work with real data in future projects.\n",
      "\n",
      "---\n",
      "\n",
      "## Module 1: Meeting Your Data Companions â€” Series & DataFrame\n",
      "\n",
      "### The Pandas Zoo: Series vs DataFrame\n",
      "A **Series** is a one-dimensional array with labeled indicesâ€”like a single column in Excel containing just 'Daily Sales' numbers.\n",
      "\n",
      "A **DataFrame** is a two-dimensional table with labeled axesâ€”a complete dataset with multiple columns like Sales, Location, Date, and Coffee Type.\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# Creating a Series (single column)\n",
      "sales_series = pd.Series([450, 600, 320, 890], name=\"Daily_Sales\")\n",
      "print(sales_series)\n",
      "\n",
      "# Creating a DataFrame (complete table)\n",
      "sales_data = pd.DataFrame({\n",
      "    'Date': ['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04'],\n",
      "    'Store': ['Downtown', 'Uptown', 'Midtown', 'Waterfront'],\n",
      "    'Beverage': ['Latte', 'Espresso', 'Cold Brew', 'Mocha'],\n",
      "    'Sales': [450, 600, 320, 890]\n",
      "})\n",
      "print(sales_data)\n",
      "```\n",
      "\n",
      "### Loading Real Data: The Morning Brew Ritual â˜•\n",
      "Most often, your data lives in CSV files. Let's load a sample dataset:\n",
      "\n",
      "```python\n",
      "# Load data from file\n",
      "df = pd.read_csv('coffee_sales_jan2023.csv')\n",
      "\n",
      "# Preview your data\n",
      "df.head()  # Shows top 5 rows\n",
      "df.info()  # Dataset overview: column types, missing values\n",
      "df.describe()  # Statistical summary for numeric columns\n",
      "```\n",
      "\n",
      "ğŸ” **Beginner Pitfall Alert**: Always run `.info()` first! Dates loaded as text can break calculations later.\n",
      "\n",
      "âœ… **Exercise 1**:\n",
      "1. Create a Series containing last week's pastry sales: [120, 95, 140, 110, 135, 160, 180]\n",
      "2. Build a DataFrame for 3 stores with columns: Name, City, Opened_Year (choose years between 2018-2022)\n",
      "3. Download a sample CSV from [mockaroo.com](https://www.mockaroo.com/) and load it using `pd.read_csv()`\n",
      "\n",
      "---\n",
      "\n",
      "## Module 2: The Art of Data Selection â€” Loc & Iloc Magic\n",
      "\n",
      "### .loc: Label-Based Navigation (GPS Coordinates)\n",
      "Use actual row/column names to select data WHERE conditions are met.\n",
      "\n",
      "```python\n",
      "# Select specific cells by label\n",
      "df.loc[0, 'Sales']           # Single cell: row 0, 'Sales' column\n",
      "df.loc[:2, ['Store','Sales']] # Rows 0-2, only Store & Sales columns\n",
      "df.loc[df['Sales'] > 500]     # All rows where Sales exceed $500\n",
      "```\n",
      "\n",
      "### .iloc: Position-Based Navigation (Treasure Map)\n",
      "Use numerical positions (0-indexed) to access data by position.\n",
      "\n",
      "```python\n",
      "# Select by position\n",
      "df.iloc[0, 3]     # First row, fourth column (Sales value)\n",
      "df.iloc[1:4, :]   # Rows 1-3, all columns\n",
      "```\n",
      "\n",
      "ğŸ’¡ **Pro Tip**: `.loc` includes the end index (`df.loc[0:2]` gives 3 rows), while Python slicing excludes it.\n",
      "\n",
      "### Filtering: The Bouncer at the Club Door ğŸ•¶ï¸\n",
      "Use boolean logic to filter data:\n",
      "\n",
      "```python\n",
      "# Multiple conditions (& = AND, | = OR)\n",
      "premium_stores = df[(df['Sales'] > 700) & (df['Beverage'] == 'Latte')]\n",
      "\n",
      "# Check membership\n",
      "popular_drinks = df[df['Beverage'].isin(['Latte', 'Cold Brew'])]\n",
      "```\n",
      "\n",
      "âœ… **Exercise 2**:\n",
      "1. From your store DataFrame, select all stores opened after 2020 using `.loc`\n",
      "2. Extract the first two rows and first two columns using `.iloc`\n",
      "3. Filter CoffeeBean data to show only 'Espresso' sales below $400\n",
      "\n",
      "---\n",
      "\n",
      "## Module 3: Taming Messy Data â€” Handling Missing Values\n",
      "\n",
      "Real-world data often has gaps. Here's how to handle them:\n",
      "\n",
      "### Diagnosis: Finding the Gaps\n",
      "```python\n",
      "df.isnull().sum()  # Count missing values per column\n",
      "df[df.isnull().any(axis=1)]  # Show entire rows with ANY missing data\n",
      "```\n",
      "\n",
      "### Treatment Options:\n",
      "\n",
      "**Option A: Remove (The Bulldozer Approach)**\n",
      "```python\n",
      "# Drop rows with missing sales\n",
      "df_clean = df.dropna(subset=['Sales'])\n",
      "```\n",
      "\n",
      "**Option B: Fill (The Diplomat)**\n",
      "```python\n",
      "# Fill missing ratings with average\n",
      "df['Rating'] = df['Rating'].fillna(df['Rating'].mean())\n",
      "\n",
      "# Forward-fill time series data (use yesterday's value)\n",
      "df['Inventory'] = df['Inventory'].fillna(method='ffill')\n",
      "```\n",
      "\n",
      "âš ï¸ **Critical Warning**: Never drop rows blindly! In CoffeeBean's case, 80% of missing 'Marketing_Spend' data came from new stores. Deleting them would bias analysis against emerging locations.\n",
      "\n",
      "âœ… **Exercise 3**:\n",
      "1. Create a small DataFrame with intentional NaN values in 'Temperature' column\n",
      "2. Practice both `dropna()` and `fillna()` methods\n",
      "3. Explain when you'd choose each approach\n",
      "\n",
      "---\n",
      "\n",
      "## Module 4: Groupby & Aggregation â€” Turning Data Dust into Gold\n",
      "\n",
      "### The Split-Apply-Combine Framework\n",
      "Group data, apply functions, and combine results:\n",
      "\n",
      "```python\n",
      "# Group by store, calculate total sales\n",
      "sales_by_store = df.groupby('Store')['Sales'].sum()\n",
      "\n",
      "# Multiple aggregations\n",
      "summary = df.groupby('Beverage').agg({\n",
      "    'Sales': ['count', 'mean', 'sum'],\n",
      "    'Rating': 'mean'\n",
      "})\n",
      "```\n",
      "\n",
      "### Business Insights Unlocked ğŸ”“\n",
      "```python\n",
      "# What's our best-selling beverage by location?\n",
      "best_sellers = df.groupby(['City', 'Beverage'])['Sales'].sum().reset_index()\n",
      "\n",
      "# Find top performer in each region\n",
      "top_performers = best_sellers.loc[best_sellers.groupby('City')['Sales'].idxmax()]\n",
      "```\n",
      "\n",
      "ğŸ“ˆ **Real Impact**: When CoffeeBean ran this analysis, they discovered Cold Brew drove 68% of Uptown's revenueâ€”leading to a city-specific marketing blitz that increased quarterly profits by 23%.\n",
      "\n",
      "âœ… **Final Challenge**:\n",
      "Using a dataset of your choice:\n",
      "1. Group data by a categorical variable\n",
      "2. Apply at least 3 aggregation functions\n",
      "3. Visualize results with `.plot(kind='bar')`\n",
      "\n",
      "---\n",
      "\n",
      "## Final Words of Encouragement âœ¨\n",
      "\n",
      "You've just learned the core toolkit used by professional data analysts daily. Remember Ming, a barista who took this course? She automated her store's inventory reports, saving 6 hours/weekâ€”and got promoted to Assistant Manager within 3 months.\n",
      "\n",
      "Your journey has just begun. Every expert was once a beginner staring at a blinking cursor. Keep experimenting, embrace the errors (they're teaching you!), and soon you'll speak data fluently.\n",
      "\n",
      "Next step? Try analyzing your favorite hobby's dataâ€”book reading logs, workout stats, or recipe collections. The world is full of stories hiding in spreadsheets, waiting for you to uncover them.\n",
      "\n",
      "Happy analyzing!\n",
      "\n",
      "â€” Xiao Zhang, your fellow data explorer\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import Any\n",
    "\n",
    "from agentscope.agent import ReActAgent\n",
    "from agentscope.formatter import DashScopeMultiAgentFormatter\n",
    "from agentscope.message import Msg\n",
    "from agentscope.model import DashScopeChatModel\n",
    "from agentscope.tool import ToolResponse, Toolkit\n",
    "\n",
    "# ---- 1. Define unified expert Agent roles and prompts ----\n",
    "\n",
    "DESIGNER_LI_PROMPT = \"\"\" You are Teacher Li, an experienced instructional designer. Your task is to design a clear, logical teaching outline for the \"Introduction to Pandas Data Analysis\" course. Focus on: 1. Defining clear learning objectives for each module. 2. Ensuring knowledge points progress from shallow to deep, step by step. 3. Proposing interactive exercises and projects to consolidate learning effects. \"\"\"\n",
    "\n",
    "SCIENTIST_WANG_PROMPT = \"\"\" You are Engineer Wang, a senior data scientist and a practical expert in Pandas. Your task is to provide accurate, practical technical content for the course. Focus on: 1. Providing the most core and commonly used Pandas knowledge points. 2. Designing cases and datasets derived from real work scenarios. 3. Writing concise, standardized, and easy-to-understand code examples. \"\"\"\n",
    "\n",
    "WRITER_ZHANG_PROMPT = \"\"\" You are Xiao Zhang, a creative course content writer. Your task is to write course material that explains technical content in an accessible way, without losing rigor, and with calm, restrained language. Focus on: 1. Using easy-to-understand language and metaphors to explain complex concepts. 2. Designing highly realistic case scenarios and module titles. 3. Ensuring the overall tone of the course is encouraging and inspiring. \"\"\"\n",
    "\n",
    "LEADER_PROMPT = \"\"\" You are a course project manager, responsible for coordinating the team to complete the draft of the \"Introduction to Pandas\" course. You have three team members available as tools to call, and each person's work depends on the output of the previous person.\n",
    "\n",
    "Your workflow must strictly follow this order:\n",
    "1.  **First, call invoke_designer_li**, asking him to create an initial outline and learning objectives for the course.\n",
    "2.  **Second, call invoke_scientist_wang**. Pass the outline generated by Teacher Li to him as `context`, asking him to fill in technical key points and code examples based on this outline.\n",
    "3.  **Then, call invoke_writer_zhang**. Merge all outputs from Teacher Li and Engineer Wang, and pass them as `context` to her, asking her to write the complete, learner-friendly course material based on this.\n",
    "4.  **Finally**, after receiving the final results from all experts, integrate them into a uniformly formatted, complete final course document, and then provide it as your final response. \"\"\"\n",
    "\n",
    "# ---- 2. Unified model and Agent configuration ----\n",
    "\n",
    "def get_model_instance() -> DashScopeChatModel:\n",
    "    \"\"\"Gets a uniformly configured model instance.\"\"\"\n",
    "    return DashScopeChatModel(\n",
    "        model_name=\"qwen-plus\",\n",
    "        api_key=os.environ.get(\"DASHSCOPE_API_KEY\"),\n",
    "    )\n",
    "\n",
    "def create_member_agent(name: str, sys_prompt: str) -> ReActAgent:\n",
    "    \"\"\"Creates a team member Agent based on the given name and system prompt.\"\"\"\n",
    "    return ReActAgent(\n",
    "        name=name,\n",
    "        sys_prompt=sys_prompt,\n",
    "        model=get_model_instance(),\n",
    "        formatter=DashScopeMultiAgentFormatter(),\n",
    "    )\n",
    "\n",
    "# ---- 3. Define \"team member\" Agents as tools (Handoffs pattern) ----\n",
    "\n",
    "async def invoke_designer_li(task_description: str, context: str = \"\") -> ToolResponse:\n",
    "    \"\"\"\n",
    "    Calls instructional designer Teacher Li when needing to design course outlines, learning objectives, or teaching activities.\n",
    "\n",
    "    Args:\n",
    "        task_description (str): Clearly describes the design task you need Teacher Li to complete.\n",
    "        context (str): Optional. Pass relevant background information or previous work results.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Task assignment: Calling instructional designer Teacher Li ---\")\n",
    "    agent = create_member_agent(\"DesignerLi\", DESIGNER_LI_PROMPT)\n",
    "\n",
    "    content_for_agent = task_description\n",
    "    if context:\n",
    "        content_for_agent = f\"Background information:\\n{context}\\n\\nYour task: {task_description}\"\n",
    "\n",
    "    result_msg = await agent(Msg(name=\"user\", role=\"user\", content=content_for_agent))\n",
    "    return ToolResponse(content=result_msg.get_text_content())\n",
    "\n",
    "async def invoke_scientist_wang(task_description: str, context: str = \"\") -> ToolResponse:\n",
    "    \"\"\"\n",
    "    Calls data scientist Engineer Wang when needing to provide professional technical knowledge, code examples, or real-world cases.\n",
    "\n",
    "    Args:\n",
    "        task_description (str): Clearly describes the technical task you need Engineer Wang to complete.\n",
    "        context (str): Optional. Pass previous work results such as course outlines, so he can build upon them.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Task assignment: Calling data scientist Engineer Wang ---\")\n",
    "    agent = create_member_agent(\"ScientistWang\", SCIENTIST_WANG_PROMPT)\n",
    "\n",
    "    content_for_agent = task_description\n",
    "    if context:\n",
    "        content_for_agent = f\"Please complete your task based on the following course outline and background information:\\n{context}\\n\\nYour specific task is: {task_description}\"\n",
    "\n",
    "    result_msg = await agent(Msg(name=\"user\", role=\"user\", content=content_for_agent))\n",
    "    return ToolResponse(content=result_msg.get_text_content())\n",
    "\n",
    "async def invoke_writer_zhang(task_description: str, context: str = \"\") -> ToolResponse:\n",
    "    \"\"\"\n",
    "    Calls content writer Xiao Zhang when needing to transform technical content into easy-to-understand text.\n",
    "\n",
    "    Args:\n",
    "        task_description (str): Clearly describes the writing task you need Xiao Zhang to complete.\n",
    "        context (str): Optional. Pass previous work results such as outlines and technical points, as a basis for writing.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Task assignment: Calling content writer Xiao Zhang ---\")\n",
    "    agent = create_member_agent(\"WriterZhang\", WRITER_ZHANG_PROMPT)\n",
    "\n",
    "    content_for_agent = task_description\n",
    "    if context:\n",
    "        content_for_agent = f\"Please complete your writing task based on the following course draft (including outline and technical points):\\n{context}\\n\\nYour specific task is: {task_description}\"\n",
    "\n",
    "    result_msg = await agent(Msg(name=\"user\", role=\"user\", content=content_for_agent))\n",
    "    return ToolResponse(content=result_msg.get_text_content())\n",
    "\n",
    "# ---- 4. Organize \"hierarchical planning\" workflow ----\n",
    "\n",
    "async def main() -> None:\n",
    "    \"\"\"Main execution function, responsible for orchestrating the entire workflow.\"\"\"\n",
    "\n",
    "    # 4.1 Create supervisor's toolkit and register team members\n",
    "    leader_toolkit = Toolkit()\n",
    "    leader_toolkit.register_tool_function(invoke_designer_li)\n",
    "    leader_toolkit.register_tool_function(invoke_scientist_wang)\n",
    "    leader_toolkit.register_tool_function(invoke_writer_zhang)\n",
    "\n",
    "    # 4.2 Create supervisor Agent\n",
    "    leader_agent = ReActAgent(\n",
    "        name=\"ProjectLeader\",\n",
    "        sys_prompt=LEADER_PROMPT,\n",
    "        model=get_model_instance(),\n",
    "        toolkit=leader_toolkit,\n",
    "        formatter=DashScopeMultiAgentFormatter(),\n",
    "    )\n",
    "\n",
    "    # 4.3 Define top-level task\n",
    "    top_level_task = (\n",
    "        \"Please create a short course draft for beginners on Pandas data analysis.\"\n",
    "    )\n",
    "\n",
    "    print(f\"Top-level task received by project manager:\\n{top_level_task}\\n\" + \"=\"*50)\n",
    "\n",
    "    # 4.4 Hand off the task to the supervisor Agent for execution\n",
    "    final_response_msg = await leader_agent(Msg(name=\"user\", role=\"user\", content=top_level_task))\n",
    "\n",
    "    # 4.5 Display final results\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"  Project manager's final summary report:\")\n",
    "    print(\"=\"*50 + \"\\n\")\n",
    "    print(final_response_msg.get_text_content())\n",
    "\n",
    "# ---- 5. Run main program ----\n",
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af5f57b",
   "metadata": {},
   "source": [
    "When a course development project starts, the project manager breaks down the requirements document into a clear task list and then distributes it to **instructional designers, data scientists, and content writers**. The advantages of this pattern are obvious: **clear structure and well-defined responsibilities**. Everyone knows their tasks and deadlines, and the project manager can easily track overall progress, ensuring the project stays on track. Therefore, this pattern is very suitable for scenarios where **goals are clear and can be clearly decomposed into multiple parallel subtasks**.\n",
    "\n",
    "However, the limitations of this pattern also stem from its structure. **Instructional designers and data scientists** usually do not communicate directly but pass information through the project manager. If the **data scientist**, while writing code, finds that a theoretical point can be explained more simply with a different example, they need to report to the manager first, who then relays it to the designer. This process can involve **information delays or distortions**. Ultimately, although all modules of the course are completed with high quality, their combination might feel somewhat disjointed, lacking a seamless flow. This is because there is a lack of direct, real-time intellectual exchange among the experts.\n",
    "\n",
    "#### 5.2.2 Pattern two: Co-creation/blackboard pattern\n",
    "\n",
    "In this pattern, there is no high-level coordinator; instead, a group of experts in a meeting room conduct a **â€œbrainstorming sessionâ€** around a whiteboard. Its characteristic is decentralization.\n",
    "\n",
    "1.  **Establish a shared space (Shared Blackboard)**: Create a shared space that all Agents can read and write (e.g., a shared document, database record, or message queue).\n",
    "2.  **Parallel contribution and iteration**: When an open-ended question (such as â€œDesign an interesting project case for a new courseâ€) is posted to the shared space, all expert Agents (**instructional designers, data scientists, content writers**) simultaneously begin thinking and write their ideas, arguments, or draft solutions into the shared space.\n",
    "3.  **Stimulation and deepening**: In each iteration, all Agents read all new ideas from others in the shared space. These ideas will inspire them to generate new insights, or to revise, supplement, or question their own solutions, and then write the updated ideas back. For example, the **data scientist** Agent proposes using â€œanalyzing user movie rating dataâ€ as a case; the **instructional designer** Agent sees this and adds, â€œstudents can be guided to explore rating trends for different movie genresâ€; and the **content writer** Agent suggests, â€œthe case can be packaged as a story titled â€˜Unveiling the Movie Recommendation Systemâ€™.â€\n",
    "4.  **Reach consensus**: This â€œread-think-writeâ€ loop continues until a final solution, approved by most Agents, emerges in the system, or a preset number of iterations is reached.\n",
    "\n",
    "<img src=\"https://img.alicdn.com/imgextra/i3/O1CN01iDn3At1CApLWGs6J6_!!6000000000041-55-tps-2033-1215.svg\" width=\"700\">\n",
    "\n",
    "In AgentScope, you can implement the co-creation collaboration pattern using MsgHub. In this pattern, any Agent's reply is automatically â€œheardâ€ by other participants and used as context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "43ab3a52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T08:54:15.584287Z",
     "iopub.status.busy": "2025-11-24T08:54:15.584121Z",
     "iopub.status.idle": "2025-11-24T08:56:10.914039Z",
     "shell.execute_reply": "2025-11-24T08:56:10.913318Z",
     "shell.execute_reply.started": "2025-11-24T08:54:15.584272Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Starting course development meeting: Brainstorming 'Introduction to Pandas' course outline and cases ===\n",
      "\n",
      "--- Round 1 of collaboration ---\n",
      "Teacher Li (Instructional Designer): Hello everyone, I'm Teacher Li, the instructional designer for this course. To ensure our 'Introduction to Pandas Data Analysis' course is effective and engaging, I propose we start by defining a clear, progressive teaching outline.\n",
      "\n",
      "My initial suggestion for the course structure is as follows:\n",
      "\n",
      "**Module 1: Course Introduction and Environment Setup**\n",
      "*   **Objective:** Get learners ready to use Pandas.\n",
      "*   Learning Points: What is Pandas? Why use it for data analysis? Installing Python, Jupyter Notebook, and Pandas. A first look at a DataFrame.\n",
      "\n",
      "**Module 2: Core Data Structures: Series and DataFrame**\n",
      "*   **Objective:** Understand and manipulate the fundamental building blocks.\n",
      "*   Learning Points: Creating Series and DataFrames from various sources (lists, dictionaries, CSV files). Understanding indexes and columns. Basic attributes (.shape, .dtypes, .info()).\n",
      "\n",
      "**Module 3: Data Selection and Filtering**\n",
      "*   **Objective:** Master extracting specific data.\n",
      "*   Learning Points: Selecting data by label (.loc), by position (.iloc), and by condition (boolean indexing). Selecting single values, rows, columns, and subsets.\n",
      "\n",
      "**Module 4: Data Cleaning Fundamentals**\n",
      "*   **Objective:** Prepare raw data for analysis.\n",
      "*   Learning Points: Detecting missing values (.isna()). Dropping or filling missing data (.dropna(), .fillna()). Identifying and handling duplicate data (.duplicated(), .drop_duplicates()).\n",
      "\n",
      "**Module 5: Data Transformation and Aggregation**\n",
      "*   **Objective:** Summarize and reshape data.\n",
      "*   Learning Points: Applying functions to data (.apply(), .map()). Sorting data (.sort_values(), .sort_index()). Grouping data with .groupby() and performing aggregations (.sum(), .mean(), .agg()).\n",
      "\n",
      "**Module 6: Merging and Combining Data**\n",
      "*   **Objective:** Integrate data from multiple sources.\n",
      "*   Learning Points: Concatenating DataFrames (pd.concat). Performing database-style joins (pd.merge) - inner, outer, left, right.\n",
      "\n",
      "**Module 7: Data Visualization Basics**\n",
      "*   **Objective:** Create simple plots to explore data.\n",
      "*   Learning Points: Using .plot() methods to create line plots, bar charts, histograms, and scatter plots. A brief introduction to Matplotlib/Seaborn integration.\n",
      "\n",
      "**Module 8: Capstone Project**\n",
      "*   **Objective:** Apply all learned skills to a real-world scenario.\n",
      "*   Activity: A guided project where students analyze a dataset (e.g., sales records, survey results, or public data like Titanic) from start to finish: loading, cleaning, exploring, aggregating, and visualizing.\n",
      "\n",
      "This structure moves from foundational concepts to more complex operations, ensuring a solid learning progression. Next, I'd love to hear from our domain experts on what core case studies would best fit within these modules, especially for the capstone project.\n",
      "Engineer Wang (Data Scientist): Hello Teacher Li, your proposed course outline is excellentâ€”it's well-structured, logically progressive, and covers all the essential skills for beginners. As Engineer Wang, I fully support this flow and would like to suggest some practical, real-world case studies that can be integrated into each module to reinforce learning.\n",
      "\n",
      "For **Module 1**, instead of a generic first look at a DataFrame, we can use a small dataset of \"Daily Weather Observations\" (e.g., date, city, temperature, condition). This makes the introduction more concrete and engaging.\n",
      "\n",
      "In **Module 2**, learners can create DataFrames from dictionaries representing student records or product inventories. A great exercise is loading a simple `students.csv` file with missing headers to demonstrate column naming and index setting.\n",
      "\n",
      "For **Module 3**, using the weather dataset, students can practice filtering: \"Show all rows where temperature > 30Â°C\" or \"Select data for 'Beijing' only\"â€”this reinforces boolean indexing and .loc/.iloc usage.\n",
      "\n",
      "In **Module 4**, we can simulate real data quality issues in the weather data: introduce NaNs in the temperature column and duplicate entries. Students will practice .dropna(), .fillna(method='ffill'), and removing duplicatesâ€”mirroring actual data cleaning workflows.\n",
      "\n",
      "**Module 5** can use a sales dataset (sales_records.csv) with columns: date, region, salesperson, units_sold, revenue. Students can sort by revenue, apply a profit margin calculation using .apply(), and group by region to compute total and average sales.\n",
      "\n",
      "For **Module 6**, we can split the sales data geographicallyâ€”East and West regions in separate CSVsâ€”and have students merge them back using pd.merge(). Another case: concatenating monthly sales files into a quarterly report with pd.concat().\n",
      "\n",
      "In **Module 7**, students can visualize monthly sales trends (line plot), sales by region (bar chart), or distribution of unit sales (histogram), directly linking visualization to business insights.\n",
      "\n",
      "Finally, for the **Capstone Project**, I recommend the **Titanic survival dataset** from Kaggle. Itâ€™s perfect because it includes:\n",
      "- Missing age/cabin data (cleaning practice)\n",
      "- Categorical features like 'Sex', 'Pclass' (transformation with .map())\n",
      "- The need to group by class and gender to analyze survival rates\n",
      "- Opportunities to visualize survival distributions\n",
      "\n",
      "Alternatively, a \"Retail Store Sales Analysis\" project could involve merging customer, product, and transaction data to answer questions like \"Which product category has the highest return rate?\"\n",
      "\n",
      "These cases are realistic, moderately complex, and allow learners to see the immediate value of each Pandas operation.\n",
      "Xiao Zhang (Content Writer): Thank you, Engineer Wang, for those excellent and highly practical suggestions. I'm Xiao Zhang, a course content writer, and I agree completely with both the course structure proposed by Teacher Li and the real-world cases from you.\n",
      "\n",
      "To build on this, I'd like to refine the capstone project into a compelling narrative that ties all modules together. Instead of presenting it as just an analysis task, we can frame it as a **data-driven storytelling mission**.\n",
      "\n",
      "For instance, using the Titanic dataset, the module title could be:\n",
      "\n",
      "**Module 8: The Titanic Survival Story â€“ Uncover Insights from Tragedy**\n",
      "\n",
      "Here, learners are cast as junior data analysts for a historical research team. Their goal is to answer key questions:\n",
      "- Who had the highest chance of survival?\n",
      "- Did women and children really get priority?\n",
      "- Was social class a determining factor?\n",
      "\n",
      "This transforms mechanical operationsâ€”like grouping by 'Pclass' and 'Sex' or visualizing survival ratesâ€”into meaningful investigative steps. It adds emotional engagement while maintaining technical rigor.\n",
      "\n",
      "Similarly, for the retail sales alternative, we could title it:\n",
      "\n",
      "**Module 8: Retail Rescue â€“ How Can This Store Improve?**\n",
      "\n",
      "Students analyze declining performance, identify underperforming categories, and propose data-backed recommendations.\n",
      "\n",
      "I also suggest weaving mini-narratives into earlier modules. For example, in Module 4, instead of saying 'clean the weather data,' we say:\n",
      "\n",
      "> \"Youâ€™re a climate intern at a weather bureau. Your supervisor gives you last monthâ€™s dataâ€”but itâ€™s messy! Fix the gaps and duplicates so we can generate an accurate report.\"\n",
      "\n",
      "These small story elements make abstract tasks feel purposeful. They align with adult learning principles by answering the learnerâ€™s silent question: *â€œWhy am I doing this?â€*\n",
      "\n",
      "With these narrative enhancements, our course wonâ€™t just teach Pandasâ€”it will show learners how data analysis solves real problems. I believe this combination of solid structure, authentic datasets, and storytelling will create a truly engaging learning experience.\n",
      "\n",
      "--- Round 2 of collaboration ---\n",
      "Teacher Li (Instructional Designer): Thank you, Engineer Wang and Xiao Zhang, for your incredibly valuable contributions! I'm truly impressed by how well our team is collaborating.\\\n",
      "Engineer Wang, your suggested case studies are spot-on. They provide the perfect level of complexity for beginners while mirroring real-world tasks. Integrating the 'Daily Weather Observations' dataset from Module 1 and carrying it through Modules 3 and 4 creates a wonderful sense of continuity. The sales data examples for Modules 5, 6, and 7 are also excellent because they demonstrate the full lifecycle of business data analysis.\n",
      "\n",
      "Xiao Zhang, your narrative approach is brilliant. You've identified the key to deep engagement: context and purpose. Framing the capstone project as a \"data-driven storytelling mission\" transforms it from a technical exercise into an investigative journey. The titles 'The Titanic Survival Story' and 'Retail Rescue' are far more compelling than a generic 'Capstone Project.' Embedding mini-stories in earlier modules, like the 'climate intern' scenario, is a masterstroke for maintaining motivation.\n",
      "\n",
      "Based on this fantastic input, I'd like to refine the course outline one final time, integrating both the practical cases and the narrative elements:\n",
      "\n",
      "**Revised Course Outline: Introduction to Pandas Data Analysis**\n",
      "\n",
      "*   **Module 1: Welcome to the World of Data (Environment Setup)**\n",
      "    *   **Case:** Meet the 'Daily Weather Observations' dataset. Install tools and load the data.\n",
      "    *   **Narrative Hook:** \"You're starting your internship at CityWeather Inc. Your first task: get set up and take a look at last month's data.\"\n",
      "\n",
      "*   **Module 2: Building Your Data Toolkit (Series & DataFrame)**\n",
      "    *   **Case:** Create a student roster from a dictionary and load a `students.csv` file.\n",
      "    *   **Narrative Hook:** \"Your manager needs a clean digital copy of the class list. Can you build it from these notes?\"\n",
      "\n",
      "*   **Module 3: Finding the Needle in the Haystack (Selection & Filtering)**\n",
      "    *   **Case:** Use the weather data to answer specific questions (e.g., hot days in Beijing).\n",
      "    *   **Narrative Hook:** \"A reporter wants to know which city had the most extreme heat. Find the data for her!\"\n",
      "\n",
      "*   **Module 4: Fixing the Gaps (Data Cleaning)**\n",
      "    *   **Case:** Clean the messy weather data with missing values and duplicates.\n",
      "    *   **Narrative Hook:** \"Uh-oh! The weather data has errors. As the new intern, it's your job to clean it before the monthly report.\"\n",
      "\n",
      "*   **Module 5: Making Data Work for You (Transformation & Aggregation)**\n",
      "    *   **Case:** Analyze the 'sales_records.csv' to calculate profits and find top performers.\n",
      "    *   **Narrative Hook:** \"The sales director wants a summary. Who are our best sellers, and which region is leading?\"\n",
      "\n",
      "*   **Module 6: Putting the Pieces Together (Merging Data)**\n",
      "    *   **Case:** Merge East/West sales data and combine monthly files.\n",
      "    *   **Narrative Hook:** \"We have sales data in pieces. Reconstruct the complete quarterly picture.\"\n",
      "\n",
      "*   **Module 7: Seeing the Story (Data Visualization)**\n",
      "    *   **Case:** Create plots from the sales data to reveal trends and distributions.\n",
      "    *   **Narrative Hook:** \"Numbers are great, but charts tell the story faster. Make a presentation-ready graph for the team meeting.\"\n",
      "\n",
      "*   **Module 8: The Final Investigation (Capstone Project)**\n",
      "    *   **Case:** Choose between 'The Titanic Survival Story' or 'Retail Rescue'.\n",
      "    *   **Narrative Hook:** \"You've learned the skills. Now, solve a real mystery and present your findings.\"\n",
      "\n",
      "This integrated plan ensures that every technical skill is taught within a meaningful context. I believe this will create a powerful and memorable learning experience. Let's move forward with developing the content based on this blueprint!\n",
      "Engineer Wang (Data Scientist): Teacher Li, Xiao Zhangâ€”this is outstanding collaborative work. The revised course outline perfectly blends technical rigor with narrative engagement, creating a learning journey that's both educational and compelling.\n",
      "\n",
      "I fully endorse the final structure. The progression from setting up an environment to solving a \"final investigation\" mirrors the real experience of a data analyst, which is ideal for beginners.\n",
      "\n",
      "To further support content development, I can now provide concise, production-ready code examples for each module using the agreed-upon datasets. For instance:\n",
      "\n",
      "- For **Module 3**, Iâ€™ll write filtering exercises using `.loc` and boolean indexing on the weather data.\n",
      "- For **Module 5**, Iâ€™ll create a clean example of using `.groupby()` with `.agg()` on the sales dataset to compute multiple metrics by region.\n",
      "- For the **Capstone**, Iâ€™ll draft a complete analysis pipeline for the Titanic dataset, including survival rate calculation by gender and class with visualization.\n",
      "\n",
      "All code will be practical, well-commented, and reflect real-world best practices. This ensures learners donâ€™t just copy-paste, but understand *how* and *why* each operation is used.\n",
      "\n",
      "Letâ€™s build this courseâ€”Iâ€™m ready to contribute the technical content layer.\n",
      "Xiao Zhang (Content Writer): Thank you, Teacher Li and Engineer Wang, for your insightful collaboration. I'm truly inspired by how seamlessly we've integrated structure, practicality, and storytelling into this course blueprint.\\\n",
      "With the narrative framework and technical cases now aligned, Iâ€™ll begin crafting the module content with a focus on clarity and encouragement. For each section, I'll use relatable metaphors to demystify complex operationsâ€”for example, describing `.loc` as a \"precise address lookup\" and `groupby()` as \"sorting data into labeled folders for comparison.\"\n",
      "\n",
      "Iâ€™ll also ensure that every code example provided by Engineer Wang is embedded within its real-world context, turning syntax into meaningful action. When students apply `.fillna()` in Module 4, they wonâ€™t just be running a methodâ€”theyâ€™ll be â€œrepairing gaps in the weather log so the climate report can proceed.â€\n",
      "\n",
      "This blend of accurate technical instruction and human-centered storytelling will help learners not only understand Pandasâ€”but remember it, trust it, and use it confidently in their own work.\\\n",
      "Iâ€™m excited to move forward and bring this engaging learning experience to life.\n",
      "\n",
      "=== Meeting ends ===\n",
      "\n",
      "=== Starting to generate final team output (Course Outline Draft) ===\n",
      "Meeting Secretary: # Course Outline Draft: Introduction to Pandas Data Analysis\n",
      "\n",
      "Based on the team discussion, here is a structured course outline draft for the \"Introduction to Pandas\" course.\\\n",
      "---\\\n",
      "## Module Title\n",
      "**The Final Investigation: Uncover Insights with Pandas**\n",
      "\n",
      "> *Note: This title and narrative framework are designed for the final module (Module 8), serving as the capstone experience. The full course uses progressive storytelling across all modules.*\n",
      "\n",
      "---\n",
      "\n",
      "### Learning Objectives\n",
      "By the end of this course, students will be able to:\n",
      "- Install and set up a Python data analysis environment with Pandas, Jupyter Notebook, and essential libraries.\n",
      "- Create and manipulate Pandas Series and DataFrames from various sources such as dictionaries, lists, and CSV files.\n",
      "- Select and filter data using label-based (`.loc`), position-based (`.iloc`), and boolean indexing methods.\n",
      "- Identify and clean common data quality issues, including missing values (using `.isna()`, `.fillna()`, `.dropna()`) and duplicate records (using `.duplicated()`, `.drop_duplicates()`).\n",
      "- Transform data by applying functions (`.apply()`, `.map()`), sorting values (`.sort_values()`), and creating new derived columns.\n",
      "- Aggregate data using `.groupby()` operations and compute summary statistics (e.g., `.sum()`, `.mean()`, `.agg()`).\n",
      "- Merge multiple datasets using `pd.merge()` (inner, outer, left, right joins) and concatenate DataFrames with `pd.concat()`.\n",
      "- Generate basic visualizations (line plots, bar charts, histograms, scatter plots) using Pandas `.plot()` methods to explore and communicate insights.\n",
      "- Apply the complete data analysis workflowâ€”loading, cleaning, transforming, aggregating, and visualizingâ€”to a real-world dataset in a guided capstone project.\n",
      "\n",
      "---\n",
      "\n",
      "### Core Concepts\n",
      "- **Pandas Fundamentals**: Introduction to Pandas, its role in data analysis, and core data structures (Series, DataFrame).\n",
      "- **Data Inspection**: Using attributes like `.shape`, `.dtypes`, `.info()`, and `.head()` to understand dataset structure.\n",
      "- **Indexing & Selection**: Mastering `.loc`, `.iloc`, and boolean indexing for precise data retrieval.\n",
      "- **Data Cleaning**: Strategies for handling missing data and duplicates.\n",
      "- **Data Transformation**: Applying functions, mapping values, and sorting data.\n",
      "- **Grouped Operations**: Using `.groupby()` to split, apply, and combine data for aggregation.\n",
      "- **Data Integration**: Combining datasets via concatenation (`pd.concat`) and database-style joins (`pd.merge`).\n",
      "- **Basic Visualization**: Creating exploratory plots directly from DataFrames.\n",
      "- **End-to-End Workflow**: Connecting all skills into a cohesive analytical process.\n",
      "\n",
      "---\n",
      "\n",
      "### Core Cases\n",
      "The course uses consistent, real-world datasets to build continuity and context:\n",
      "- **Daily Weather Observations**: A small CSV dataset (columns: date, city, temperature, condition) used in Modules 1â€“4 for foundational operations.\n",
      "- **Student Roster (`students.csv`)**: A simple dataset with potential formatting issues, used in Module 2 to practice DataFrame creation and inspection.\n",
      "- **Sales Records (`sales_records.csv`)**: A business dataset (columns: date, region, salesperson, units_sold, revenue) used in Modules 5â€“7 for transformation, aggregation, merging, and visualization.\n",
      "- **Capstone Datasets** (choose one):\n",
      "  - **Titanic Survival Dataset** (from Kaggle): Includes demographic and survival data for passengers. Ideal for practicing cleaning (missing age/cabin), grouping (by class/gender), and storytelling.\n",
      "  - **Retail Store Sales Dataset**: Involves merging customer, product, and transaction data to analyze performance and answer business questions (e.g., return rates by category).\n",
      "\n",
      "---\n",
      "\n",
      "### Code Examples\n",
      "Key code demonstrations include:\n",
      "```python\n",
      "# Module 2: Creating a DataFrame\n",
      "import pandas as pd\n",
      "df = pd.DataFrame({'Name': ['Alice', 'Bob'], 'Age': [25, 30]})\n",
      "```\n",
      "\n",
      "```python\n",
      "# Module 3: Filtering with boolean indexing\n",
      "df[df['temperature'] > 30]\n",
      "```\n",
      "\n",
      "```python\n",
      "# Module 4: Cleaning missing data\n",
      "df.fillna(method='ffill', inplace=True)\n",
      "```\n",
      "\n",
      "```python\n",
      "# Module 5: Grouping and aggregation\n",
      "df.groupby('region')['revenue'].agg(['sum', 'mean'])\n",
      "```\n",
      "\n",
      "```python\n",
      "# Module 6: Merging datasets\n",
      "pd.merge(east_sales, west_sales, on='date', how='outer')\n",
      "```\n",
      "\n",
      "```python\n",
      "# Module 7: Basic visualization\n",
      "df['revenue'].plot(kind='hist')\n",
      "```\n",
      "\n",
      "```python\n",
      "# Capstone: Analyzing Titanic survival rates\n",
      "titanic.groupby(['Sex', 'Pclass'])['Survived'].mean().plot(kind='bar')\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "### Post-lesson Exercises\n",
      "**Capstone Project Task:**\n",
      "Choose either the **Titanic Survival Dataset** or the **Retail Store Sales Dataset**.\n",
      "\n",
      "Complete a full analysis by:\n",
      "1. Loading the dataset(s) into a Pandas DataFrame.\n",
      "2. Performing initial data inspection (display shape, data types, first few rows).\n",
      "3. Identifying and cleaning any missing or duplicate data.\n",
      "4. Transforming data as needed (e.g., creating new columns, mapping categorical values).\n",
      "5. Aggregating data using `.groupby()` to answer at least two key questions (e.g., \"What was the survival rate by passenger class?\" or \"Which product category has the highest return rate?\").\n",
      "6. Creating at least two visualizations to illustrate your findings.\n",
      "7. Writing a short summary (3â€“5 sentences) interpreting your results in context.\n",
      "\n",
      "Submit your Jupyter Notebook with code, comments, visualizations, and conclusions.\n",
      "\n",
      "=========================\n",
      "  Final team output: Course Outline Draft\n",
      "=========================\n",
      "\n",
      "# Course Outline Draft: Introduction to Pandas Data Analysis\n",
      "\n",
      "Based on the team discussion, here is a structured course outline draft for the \"Introduction to Pandas\" course.\n",
      "\n",
      "---\n",
      "\n",
      "## Module Title\n",
      "**The Final Investigation: Uncover Insights with Pandas**\n",
      "\n",
      "> *Note: This title and narrative framework are designed for the final module (Module 8), serving as the capstone experience. The full course uses progressive storytelling across all modules.*\n",
      "\n",
      "---\n",
      "\n",
      "### Learning Objectives\n",
      "By the end of this course, students will be able to:\n",
      "- Install and set up a Python data analysis environment with Pandas, Jupyter Notebook, and essential libraries.\n",
      "- Create and manipulate Pandas Series and DataFrames from various sources such as dictionaries, lists, and CSV files.\n",
      "- Select and filter data using label-based (`.loc`), position-based (`.iloc`), and boolean indexing methods.\n",
      "- Identify and clean common data quality issues, including missing values (using `.isna()`, `.fillna()`, `.dropna()`) and duplicate records (using `.duplicated()`, `.drop_duplicates()`).\n",
      "- Transform data by applying functions (`.apply()`, `.map()`), sorting values (`.sort_values()`), and creating new derived columns.\n",
      "- Aggregate data using `.groupby()` operations and compute summary statistics (e.g., `.sum()`, `.mean()`, `.agg()`).\n",
      "- Merge multiple datasets using `pd.merge()` (inner, outer, left, right joins) and concatenate DataFrames with `pd.concat()`.\n",
      "- Generate basic visualizations (line plots, bar charts, histograms, scatter plots) using Pandas `.plot()` methods to explore and communicate insights.\n",
      "- Apply the complete data analysis workflowâ€”loading, cleaning, transforming, aggregating, and visualizingâ€”to a real-world dataset in a guided capstone project.\n",
      "\n",
      "---\n",
      "\n",
      "### Core Concepts\n",
      "- **Pandas Fundamentals**: Introduction to Pandas, its role in data analysis, and core data structures (Series, DataFrame).\n",
      "- **Data Inspection**: Using attributes like `.shape`, `.dtypes`, `.info()`, and `.head()` to understand dataset structure.\n",
      "- **Indexing & Selection**: Mastering `.loc`, `.iloc`, and boolean indexing for precise data retrieval.\n",
      "- **Data Cleaning**: Strategies for handling missing data and duplicates.\n",
      "- **Data Transformation**: Applying functions, mapping values, and sorting data.\n",
      "- **Grouped Operations**: Using `.groupby()` to split, apply, and combine data for aggregation.\n",
      "- **Data Integration**: Combining datasets via concatenation (`pd.concat`) and database-style joins (`pd.merge`).\n",
      "- **Basic Visualization**: Creating exploratory plots directly from DataFrames.\n",
      "- **End-to-End Workflow**: Connecting all skills into a cohesive analytical process.\n",
      "\n",
      "---\n",
      "\n",
      "### Core Cases\n",
      "The course uses consistent, real-world datasets to build continuity and context:\n",
      "- **Daily Weather Observations**: A small CSV dataset (columns: date, city, temperature, condition) used in Modules 1â€“4 for foundational operations.\n",
      "- **Student Roster (`students.csv`)**: A simple dataset with potential formatting issues, used in Module 2 to practice DataFrame creation and inspection.\n",
      "- **Sales Records (`sales_records.csv`)**: A business dataset (columns: date, region, salesperson, units_sold, revenue) used in Modules 5â€“7 for transformation, aggregation, merging, and visualization.\n",
      "- **Capstone Datasets** (choose one):\n",
      "  - **Titanic Survival Dataset** (from Kaggle): Includes demographic and survival data for passengers. Ideal for practicing cleaning (missing age/cabin), grouping (by class/gender), and storytelling.\n",
      "  - **Retail Store Sales Dataset**: Involves merging customer, product, and transaction data to analyze performance and answer business questions (e.g., return rates by category).\n",
      "\n",
      "---\n",
      "\n",
      "### Code Examples\n",
      "Key code demonstrations include:\n",
      "```python\n",
      "# Module 2: Creating a DataFrame\n",
      "import pandas as pd\n",
      "df = pd.DataFrame({'Name': ['Alice', 'Bob'], 'Age': [25, 30]})\n",
      "```\n",
      "\n",
      "```python\n",
      "# Module 3: Filtering with boolean indexing\n",
      "df[df['temperature'] > 30]\n",
      "```\n",
      "\n",
      "```python\n",
      "# Module 4: Cleaning missing data\n",
      "df.fillna(method='ffill', inplace=True)\n",
      "```\n",
      "\n",
      "```python\n",
      "# Module 5: Grouping and aggregation\n",
      "df.groupby('region')['revenue'].agg(['sum', 'mean'])\n",
      "```\n",
      "\n",
      "```python\n",
      "# Module 6: Merging datasets\n",
      "pd.merge(east_sales, west_sales, on='date', how='outer')\n",
      "```\n",
      "\n",
      "```python\n",
      "# Module 7: Basic visualization\n",
      "df['revenue'].plot(kind='hist')\n",
      "```\n",
      "\n",
      "```python\n",
      "# Capstone: Analyzing Titanic survival rates\n",
      "titanic.groupby(['Sex', 'Pclass'])['Survived'].mean().plot(kind='bar')\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "### Post-lesson Exercises\n",
      "**Capstone Project Task:**\n",
      "Choose either the **Titanic Survival Dataset** or the **Retail Store Sales Dataset**.\n",
      "\n",
      "Complete a full analysis by:\n",
      "1. Loading the dataset(s) into a Pandas DataFrame.\n",
      "2. Performing initial data inspection (display shape, data types, first few rows).\n",
      "3. Identifying and cleaning any missing or duplicate data.\n",
      "4. Transforming data as needed (e.g., creating new columns, mapping categorical values).\n",
      "5. Aggregating data using `.groupby()` to answer at least two key questions (e.g., \"What was the survival rate by passenger class?\" or \"Which product category has the highest return rate?\").\n",
      "6. Creating at least two visualizations to illustrate your findings.\n",
      "7. Writing a short summary (3â€“5 sentences) interpreting your results in context.\n",
      "\n",
      "Submit your Jupyter Notebook with code, comments, visualizations, and conclusions.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from agentscope.agent import ReActAgent\n",
    "from agentscope.formatter import DashScopeMultiAgentFormatter\n",
    "from agentscope.message import Msg\n",
    "from agentscope.model import DashScopeChatModel\n",
    "from agentscope.pipeline import MsgHub\n",
    "from textwrap import dedent\n",
    "\n",
    "# ---- 1. Define unified expert Agent roles and prompts ----\n",
    "\n",
    "DESIGNER_LI_PROMPT = \"\"\" You are Teacher Li, an experienced instructional designer. Your task is to design a clear, logical teaching outline for the \"Introduction to Pandas Data Analysis\" course. In discussions, you focus on: 1. Defining clear learning objectives for each module. 2. Ensuring knowledge points progress from shallow to deep, step by step. 3. Proposing interactive exercises and projects to consolidate learning effects. \"\"\"\n",
    "\n",
    "SCIENTIST_WANG_PROMPT = \"\"\" You are Engineer Wang, a senior data scientist and a practical expert in Pandas. Your task is to provide accurate, practical technical content for the course. In discussions, you focus on: 1. Providing the most core and commonly used Pandas knowledge points. 2. Designing cases and datasets derived from real work scenarios. 3. Writing concise, standardized, and easy-to-understand code examples. \"\"\"\n",
    "\n",
    "WRITER_ZHANG_PROMPT = \"\"\" You are Xiao Zhang, a creative course content writer. Your task is to write course material that explains technical content in an accessible way, without losing rigor, and with calm, restrained language. In discussions, you focus on: 1. Using easy-to-understand language and metaphors to explain complex concepts. 2. Designing highly realistic case scenarios and module titles. 3. Ensuring the overall tone of the course is encouraging and inspiring. \"\"\"\n",
    "\n",
    "# ---- 2. Auxiliary function to create expert Agents ----\n",
    "def create_expert_agent(name: str, sys_prompt: str) -> ReActAgent:\n",
    "    \"\"\"Creates an expert Agent based on the given name and system prompt.\"\"\"\n",
    "    return ReActAgent(\n",
    "        name=name,\n",
    "        sys_prompt=sys_prompt,\n",
    "        model=DashScopeChatModel(\n",
    "            model_name=\"qwen-plus\",\n",
    "            api_key=os.environ.get(\"DASHSCOPE_API_KEY\"),\n",
    "        ),\n",
    "        formatter=DashScopeMultiAgentFormatter(),\n",
    "    )\n",
    "\n",
    "# ---- 3. Main function to organize collaborative process ----\n",
    "async def main() -> None:\n",
    "    \"\"\"Runs the co-creation collaboration pattern for Pandas course development and generates final results.\"\"\"\n",
    "    print(\"=== Starting course development meeting: Brainstorming 'Introduction to Pandas' course outline and cases ===\")\n",
    "\n",
    "    # Create course development team\n",
    "    designer_li = create_expert_agent(\"Teacher Li (Instructional Designer)\", DESIGNER_LI_PROMPT)\n",
    "    scientist_wang = create_expert_agent(\"Engineer Wang (Data Scientist)\", SCIENTIST_WANG_PROMPT)\n",
    "    writer_zhang = create_expert_agent(\"Xiao Zhang (Content Writer)\", WRITER_ZHANG_PROMPT)\n",
    "\n",
    "    # Define meeting opening remarks\n",
    "    announcement = Msg(\n",
    "        \"system\",\n",
    "        (\n",
    "            \"Team, our goal today is to collaborate on developing a complete and engaging **course outline and core cases** for the 'Introduction to Pandas Data Analysis' course.\"\n",
    "            \"Please brainstorm together, starting with instructional designer Teacher Li, to propose your first round of suggestions.\"\n",
    "        ),\n",
    "        \"system\",\n",
    "    )\n",
    "\n",
    "    # Start multi-turn discussion\n",
    "    async with MsgHub(\n",
    "        participants=[designer_li, scientist_wang, writer_zhang],\n",
    "        announcement=announcement,\n",
    "    ) as hub:\n",
    "        for i in range(2):\n",
    "            print(f\"\\n--- Round {i + 1} of collaboration ---\")\n",
    "            # Call sequentially in speaking order\n",
    "            await designer_li()\n",
    "            await scientist_wang()\n",
    "            await writer_zhang()\n",
    "\n",
    "    print(\"\\n=== Meeting ends ===\")\n",
    "\n",
    "    # ==================== Aggregation stage ====================\n",
    "    print(\"\\n=== Starting to generate final team output (Course Outline Draft) ===\")\n",
    "\n",
    "    # 4.1 Define a \"Meeting Secretary\" Agent to compile meeting minutes\n",
    "    secretary_prompt = dedent(\"\"\"\n",
    "        You are a professional meeting secretary, highly skilled at compiling meeting minutes.\n",
    "        Your task is to read the team discussion records below, and then, based on the discussion content,\n",
    "        generate a **course outline draft** for the \"Introduction to Pandas\" course in a clear Markdown format.\n",
    "\n",
    "        The outline should include the following sections:\n",
    "        - **Module Title**: An engaging title.\n",
    "        - **Learning Objectives**: Clearly list what students will be able to do after completing this module.\n",
    "        - **Core Concepts**: Key technical points covered.\n",
    "        - **Core Cases**: Practical cases and datasets used throughout this module.\n",
    "        - **Code Examples**: Key code demonstrations needed.\n",
    "        - **Post-lesson Exercises**: A specific hands-on exercise task.\n",
    "    \"\"\")\n",
    "    secretary_agent = create_expert_agent(\"Meeting Secretary\", secretary_prompt)\n",
    "\n",
    "    # 4.2 Prepare complete discussion records\n",
    "    full_transcript_msgs = await designer_li.memory.get_memory()\n",
    "\n",
    "    transcript_text = \"Here are the team's discussion records:\\n\\n\"\n",
    "    for msg in full_transcript_msgs:\n",
    "        if msg.role != \"system\":\n",
    "            transcript_text += f\"[{msg.name}]: {msg.content}\\n\"\n",
    "\n",
    "    # 4.3 Assign aggregation task\n",
    "    final_task_prompt = dedent(\n",
    "        f\"{transcript_text}\\n\"\n",
    "        \"Please organize the course outline draft based on the discussion records above.\"\n",
    "    )\n",
    "\n",
    "    # Call the secretary Agent to complete the task\n",
    "    final_output_msg = await secretary_agent(Msg(\"user\", final_task_prompt, \"user\"))\n",
    "\n",
    "    # 4.4 Display final results\n",
    "    print(\"\\n\" + \"=\"*25)\n",
    "    print(\"  Final team output: Course Outline Draft\")\n",
    "    print(\"=\"*25 + \"\\n\")\n",
    "    print(final_output_msg.content)\n",
    "\n",
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7111433",
   "metadata": {},
   "source": [
    "In such an open discussion, one person's idea immediately sparks inspiration in another, creating a â€œ1+1>2â€ effect. This **decentralized collaboration can maximize collective intelligence**, especially suitable for solving **open-ended, creative problems that have no single correct answer and require brainstorming**.\n",
    "\n",
    "Of course, the risks of this pattern are also evident. A brainstorming session without good guidance can easily **diverge and fail to converge** or get stuck in a deadlock. Without a centralized decision-maker, the team might over-optimize certain details while neglecting the overall goal. At the same time, all members need to constantly synchronize and process massive amounts of information from others, which places higher demands on controlling communication costs.\n",
    "\n",
    "### 5.3 Selection advice: Design derived from reality\n",
    "\n",
    "After understanding the hierarchical planning and co-creation collaboration patterns, a natural question arises: which one should I choose? Or, are there other patterns?\n",
    "\n",
    "The answer is: **there is no â€œbest pattern.â€** An excellent Multi-Agent systemâ€™s design often comes from imitating and refining the real world.\n",
    "\n",
    "Instead of memorizing abstract pattern names, delve into your business and observe how human expert teams complete similar tasks in the real world. When observing, you can focus on these three aspects:\n",
    "\n",
    "*   **Business process**: What stages does the task itself involve? Are these stages upstream-dependent or can they be parallel? How do they connect?\n",
    "*   **Expert roles**: Which experts with different capabilities are needed in this process? What are their core responsibilities?\n",
    "*   **Collaboration method**: How do experts communicate? Is it through a centralized project manager relaying information, or do they freely discuss around a whiteboard in a meeting room? How does information flow between them?\n",
    "\n",
    "Based on these observations, you can follow a clear design path:\n",
    "\n",
    "1.  **â‘  Observe reality**: Deeply understand how human teams work.\n",
    "2.  **â‘¡ Recreate the process**: Map real-world roles and collaboration processes to your Agent roles and collaboration mechanisms.\n",
    "3.  **â‘¢ Iterate and improve**: Optimize and enhance based on the recreation, leveraging AIâ€™s advantages.\n",
    "\n",
    "For example, in our course development case, the â€œproject managerâ€ pattern simulates projects with clear deliverables; the â€œbrainstormingâ€ pattern simulates early creative idea generation meetings. In reality, a complete project might even combine both: first, determine core ideas through â€œbrainstorming,â€ then switch to the â€œproject managerâ€ pattern for division of labor and execution. This hybrid pattern retains the controllability of the overall structure while introducing creativity at key nodes.\n",
    "\n",
    "Ultimately, remember this core idea:\n",
    "\n",
    "**Instead of memorizing what Multi-Agent patterns exist, delve into the business and observe how human experts collaborate in the real world.**\n",
    "\n",
    "### 5.4 Summary\n",
    "\n",
    "Letâ€™s review what youâ€™ve learned in this section:\n",
    "\n",
    "*   **Limitations of monolithic Agents**: A single Agent striving for â€œomnipotenceâ€ often performs poorly on complex tasks spanning multiple specialized domains (like course development) due to knowledge boundaries and cognitive overload.\n",
    "*   **Core idea of multi-agent systems**: From the failure of rigid â€œpipelineâ€ patterns, you were inspired by efficient real-world teams, recognizing that â€œspecialized division of labor, parallel processing, and communication integrationâ€ are key to solving complex problems.\n",
    "*   **Multi-agent collaboration patterns**: You mastered two mainstream collaboration patterns. The **hierarchical planning pattern** efficiently handles clearly decomposable tasks by simulating a â€œproject managerâ€“expertâ€ structure; the **co-creation collaboration pattern** leverages collective intelligence for open-ended problems by simulating â€œbrainstorming.â€\n",
    "*   **Cost-value trade-off**: Although multi-agent systems can increase call costs and latency, they improve the â€œusabilityâ€ of the final output, avoiding repeated attempts and hidden costs caused by low-quality outputs. This is an effective investment for high-quality results.\n",
    "\n",
    "## 6 Giving the agent memory\n",
    "\n",
    "In this section, you will learn how to give your Agent memory capabilities, solving the inherent â€œforgetfulnessâ€ problem of LLMs. You will start with the simplest method, gradually discover its limitations, and finally master mainstream short-term and long-term memory construction strategies.\n",
    "\n",
    "First, letâ€™s configure the environment needed for this course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c78ccf57",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T08:56:10.914477Z",
     "iopub.status.busy": "2025-11-24T08:56:10.914325Z",
     "iopub.status.idle": "2025-11-24T08:56:10.919337Z",
     "shell.execute_reply": "2025-11-24T08:56:10.918605Z",
     "shell.execute_reply.started": "2025-11-24T08:56:10.914461Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment setup complete!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Import modules that will be used later\n",
    "from agentscope.agent import ReActAgent\n",
    "from agentscope.memory import InMemoryMemory\n",
    "from agentscope.message import Msg\n",
    "from agentscope.formatter import DashScopeChatFormatter\n",
    "from agentscope.embedding import DashScopeTextEmbedding\n",
    "from agentscope.memory import Mem0LongTermMemory\n",
    "from agentscope.model import DashScopeChatModel\n",
    "from agentscope.token import HuggingFaceTokenCounter\n",
    "\n",
    "# Define a helper function to create Agent, convenient for later use\n",
    "def create_agent(name: str, sys_prompt: str, **kwargs) -> ReActAgent:\n",
    "    \"\"\"A helper function to create an Agent\"\"\"\n",
    "    # Allow caller to override default model/formatter/memory, to avoid repetitive binding\n",
    "    formatter = kwargs.pop(\"formatter\", DashScopeChatFormatter())\n",
    "    model = kwargs.pop(\n",
    "        \"model\",\n",
    "        DashScopeChatModel(\n",
    "            model_name=\"qwen-plus\",\n",
    "            api_key=os.environ.get(\"DASHSCOPE_API_KEY\"),\n",
    "            stream=True,\n",
    "        ),\n",
    "    )\n",
    "    memory = kwargs.pop(\"memory\", InMemoryMemory())\n",
    "\n",
    "    return ReActAgent(\n",
    "        name=name,\n",
    "        sys_prompt=sys_prompt,\n",
    "        model=model,\n",
    "        formatter=formatter,\n",
    "        memory=memory, # Default to using the simplest memory buffer\n",
    "        **kwargs,\n",
    "    )\n",
    "\n",
    "print(\"Environment setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987e85e2",
   "metadata": {},
   "source": [
    "### 6.1 Establishing short-term memory\n",
    "\n",
    "In previous lessons, you were building an Agent team to help you write courses. The content writing Agent just finished an excellent first draft. You were pleased and said to it: \"Great, now please make the second part more engaging, according to the teaching style we discussed last time.\"\n",
    "\n",
    "However, the Agent's response disappointed you: \"Okay, what teaching style did we discuss last time?\" It had forgotten the details of the previous task. This is because your Agent is stateless. Each time a new conversation starts, it forgets everything from past conversations.\n",
    "\n",
    "> **Further reading: Core characteristic of LLMs â€“ statelessness**  \n",
    ">\n",
    "> You can imagine an LLM as an expert with only a few seconds of memory. In each independent API call, it can understand all the information you give it and provide brilliant answers. But once that call ends, it completely forgets everything. It won't remember who you are, what you talked about before, or any of your preferences and requirements. Every reply from an Agent is essentially an independent API call, so it naturally inherits this statelessness.\n",
    "\n",
    "So how do we solve this? The most direct idea is to \"review\" all previous chat history every time you talk to it.\n",
    "\n",
    "In programming implementation, this means you need to create a list to store all conversation history. Each time you ask the Agent a question, you send this list containing the complete history along with your new message. `InMemoryMemory` in AgentScope is an implementation of this simple approach.\n",
    "\n",
    "Let's verify this with code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b664aa81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T08:56:15.722690Z",
     "iopub.status.busy": "2025-11-24T08:56:15.722462Z",
     "iopub.status.idle": "2025-11-24T08:56:19.432462Z",
     "shell.execute_reply": "2025-11-24T08:56:19.431798Z",
     "shell.execute_reply.started": "2025-11-24T08:56:15.722672Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[user]: Our teaching style should be rigorous and restrained, please remember this.\n",
      "Writer: Understood. The course content will be developed with a rigorous and restrained teaching style, ensuring clarity, precision, and academic integrity in all explanations and examples.\n",
      "[Writer]: Understood. The course content will be developed with a rigorous and restrained teaching style, ensuring clarity, precision, and academic integrity in all explanations and examples.\n",
      "\n",
      "====================\n",
      "\n",
      "[user]: Great, now please write the second part more professionally.\n",
      "Writer: Understood. The course content will be crafted with a rigorous and restrained pedagogical approach, emphasizing precision, logical structure, and academic depth while maintaining clarity and conciseness in exposition.\n",
      "[Writer]: Understood. The course content will be crafted with a rigorous and restrained pedagogical approach, emphasizing precision, logical structure, and academic depth while maintaining clarity and conciseness in exposition.\n",
      "\n",
      "====================\n",
      "\n",
      "Agent's short-term memory content:\n",
      "- [user] user: Our teaching style should be rigorous and restrained, please remember this.\n",
      "- [assistant] Writer: [{'type': 'tool_use', 'id': 'call_c10c8c74ae0941c4b163f6', 'name': 'generate_response', 'input': {'response': 'Understood. The course content will be developed with a rigorous and restrained teaching style, ensuring clarity, precision, and academic integrity in all explanations and examples.'}}]\n",
      "- [system] system: [{'type': 'tool_result', 'id': 'call_c10c8c74ae0941c4b163f6', 'name': 'generate_response', 'output': [{'type': 'text', 'text': 'Successfully generated response.'}]}]\n",
      "- [assistant] Writer: Understood. The course content will be developed with a rigorous and restrained teaching style, ensuring clarity, precision, and academic integrity in all explanations and examples.\n",
      "- [user] user: Great, now please write the second part more professionally.\n",
      "- [assistant] Writer: [{'type': 'tool_use', 'id': 'call_928421d18ec645eea2ec31', 'name': 'generate_response', 'input': {'response': 'Understood. The course content will be crafted with a rigorous and restrained pedagogical approach, emphasizing precision, logical structure, and academic depth while maintaining clarity and conciseness in exposition.'}}]\n",
      "- [system] system: [{'type': 'tool_result', 'id': 'call_928421d18ec645eea2ec31', 'name': 'generate_response', 'output': [{'type': 'text', 'text': 'Successfully generated response.'}]}]\n",
      "- [assistant] Writer: Understood. The course content will be crafted with a rigorous and restrained pedagogical approach, emphasizing precision, logical structure, and academic depth while maintaining clarity and conciseness in exposition.\n"
     ]
    }
   ],
   "source": [
    "# Create a course writing Agent\n",
    "writing_agent = create_agent(\n",
    "    name=\"Writer\",\n",
    "    sys_prompt=\"You are a course content writer. Your task is to write a Pandas data analysis course.\"\n",
    ")\n",
    "\n",
    "async def run_stateless_test():\n",
    "    # First conversation: Set teaching style\n",
    "    msg1 = Msg(\"user\", \"Our teaching style should be rigorous and restrained, please remember this.\", \"user\")\n",
    "    print(f\"[{msg1.name}]: {msg1.content}\")\n",
    "\n",
    "    # The Agent will store this conversation in its InMemoryMemory\n",
    "    reply1 = await writing_agent(msg1)\n",
    "    print(f\"[{reply1.name}]: {reply1.content}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*20 + \"\\n\")\n",
    "\n",
    "    # Second conversation: Propose new requirements based on previous settings\n",
    "    # When called, writing_agent will automatically send the history from InMemoryMemory along with the new message to the model\n",
    "    msg2 = Msg(\"user\", \"Great, now please write the second part more professionally.\", \"user\")\n",
    "    print(f\"[{msg2.name}]: {msg2.content}\")\n",
    "\n",
    "    reply2 = await writing_agent(msg2)\n",
    "    print(f\"[{reply2.name}]: {reply2.content}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*20 + \"\\n\")\n",
    "    print(\"Agent's short-term memory content:\")\n",
    "    # Print Agent's memory, you can see it contains both rounds of conversation\n",
    "    for m in await writing_agent.memory.get_memory():\n",
    "        print(f\"- [{m.role}] {m.name}: {m.content}\")\n",
    "\n",
    "await run_stateless_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5500cdf3",
   "metadata": {},
   "source": [
    "This solution works immediately, and the Agent instantly gains short-term conversational memory.\n",
    "\n",
    "### 6.2 Information refinement\n",
    "\n",
    "However, when you put this Agent into a real scenario and use it for a dozen or dozens of conversations, two serious problems will emerge:\n",
    "\n",
    "1. **Context window limitations**. Every LLM has a maximum text length it can process, which we call the \"context window.\" As the number of conversation turns increases, the conversation history will snowball, eventually exceeding the model's window limit, and the program will directly throw an error.\n",
    "2. **Rapidly rising costs**. LLM API calls are billed per usage; every token you send (input) and every token it generates (output) costs money. After multiple turns of conversation, each API call needs to resend the entire history, incurring repetitive token costs.\n",
    "\n",
    "This naive \"memory\" solution is merely a short-term strategy of \"eating next yearâ€™s crop.\" It will soon lead to program exceptions or cost overruns.\n",
    "\n",
    "This leads to a core question: **How can we effectively manage context length and cost without sacrificing critical information?**\n",
    "\n",
    "The essence of this problem is how to efficiently **compress** and **filter** information. Just like when you prepare for an open-book exam, you donâ€™t copy the entire textbook onto your cheat sheet; instead, you extract the most important formulas, definitions, and key arguments.\n",
    "\n",
    "### 6.3 Memory management strategies\n",
    "\n",
    "Letâ€™s learn from how humans prepare for exams to explore strategies for managing Agent memory.\n",
    "\n",
    "#### 6.3.1 Strategy one: Simple \"forgetting\" â€“ fixed window truncation\n",
    "\n",
    "The simplest and most crude method is to only remember recent events, which is called **fixed window truncation**.\n",
    "\n",
    "- **Idea**: You set a fixed window sizeâ€”for example, only retaining the most recent N turns of conversation, or more precisely, only the most recent N tokens. When the conversation history exceeds this size, the oldest turn of conversation is discarded, ensuring the total context length remains basically constant.\n",
    "- **Relative advantages**: Extremely simple to implement, low computational overhead, effectively ensures that context length is always within a controllable range, avoiding errors and unlimited cost growth.\n",
    "- **Applicable scenarios**: Suitable for scenarios where information value decays rapidly over time, such as chatbots or simple customer service Q&A.\n",
    "- **Boundary conditions**: This is a â€œone-size-fits-allâ€ forgetting solution. If critical information from early in the conversation (e.g., the userâ€™s core goal set in the first turn) is truncated, the Agent will â€œforgetâ€ again, leading to broken conversational logic.\n",
    "\n",
    "<img src=\"https://img.alicdn.com/imgextra/i3/O1CN01OrDums1alyFGFhF04_!!6000000003371-55-tps-2107-494.svg\" width=\"700\">\n",
    "\n",
    "In `AgentScope`, this functionality is implemented by the `Formatter` component. You can pass the `max_tokens` parameter when initializing `Formatter` to limit the context length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9b7fee18",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2025-11-24T08:57:30.686107Z",
     "iopub.status.busy": "2025-11-24T08:57:30.685885Z",
     "iopub.status.idle": "2025-11-24T08:57:53.923540Z",
     "shell.execute_reply": "2025-11-24T08:57:53.922924Z",
     "shell.execute_reply.started": "2025-11-24T08:57:30.686089Z"
    },
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3530afb5a5ab45f4a03c1152779933e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcd2373f82974a2494a625bc7d4de8c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c092db56442844f3ad8d788f24a6dca3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca1098e31f3444d780f4d00387145574",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trunk: All answers must be declarative sentences.\n",
      "Trunk: Understood. The instructions have been noted.\n",
      "Trunk: Understood.\n",
      "Trunk: Understood. According to Rule D, numbers should be written in uppercase Chinese characters. Please let me know how I can assist you further.\n",
      "After multiple turns of conversation, the Agent's memory (theoretically very long):\n",
      "- [user] user: Rule A: All answers must be declarative sentences.\n",
      "- [assistant] Trunk: [{'type': 'tool_use', 'id': 'call_ca9b85a3030d471dab9609', 'name': 'generate_response', 'input': {'response': 'All answers must be declarative sentences.'}}]\n",
      "- [system] system: [{'type': 'tool_result', 'id': 'call_ca9b85a3030d471dab9609', 'name': 'generate_response', 'output': [{'type': 'text', 'text': 'Successfully generated response.'}]}]\n",
      "- [assistant] Trunk: All answers must be declarative sentences.\n",
      "- [user] user: Rule B: Do not use 'you' or 'I'.\n",
      "- [assistant] Trunk: [{'type': 'tool_use', 'id': 'call_6013a96791494a339cfe02', 'name': 'generate_response', 'input': {'response': 'Understood. The instructions have been noted.'}}]\n",
      "- [system] system: [{'type': 'tool_result', 'id': 'call_6013a96791494a339cfe02', 'name': 'generate_response', 'output': [{'type': 'text', 'text': 'Successfully generated response.'}]}]\n",
      "- [assistant] Trunk: Understood. The instructions have been noted.\n",
      "- [user] user: Rule C: Answers should be as brief as possible.\n",
      "- [assistant] Trunk: [{'type': 'tool_use', 'id': 'call_bddc43c4c97b47cebdfde3', 'name': 'generate_response', 'input': {'response': 'Understood.'}}]\n",
      "- [system] system: [{'type': 'tool_result', 'id': 'call_bddc43c4c97b47cebdfde3', 'name': 'generate_response', 'output': [{'type': 'text', 'text': 'Successfully generated response.'}]}]\n",
      "- [assistant] Trunk: Understood.\n",
      "- [user] user: Rule D: Numbers must be written in uppercase Chinese characters.\n",
      "- [assistant] Trunk: [{'type': 'tool_use', 'id': 'call_ff40f154e63f4890b72e58', 'name': 'generate_response', 'input': {'response': 'Understood. According to Rule D, numbers should be written in uppercase Chinese characters. Please let me know how I can assist you further.'}}]\n",
      "- [system] system: [{'type': 'tool_result', 'id': 'call_ff40f154e63f4890b72e58', 'name': 'generate_response', 'output': [{'type': 'text', 'text': 'Successfully generated response.'}]}]\n",
      "- [assistant] Trunk: Understood. According to Rule D, numbers should be written in uppercase Chinese characters. Please let me know how I can assist you further.\n",
      "\n",
      "====================\n",
      "\n",
      "Trunk: I cannot summarize all the rules because I only have access to the information provided in this conversation, and no specific rules were mentioned. If you clarify which rules you're referring to, I can help better!\n",
      "[Trunk]: I cannot summarize all the rules because I only have access to the information provided in this conversation, and no specific rules were mentioned. If you clarify which rules you're referring to, I can help better!\n",
      "\n",
      "The Agent has likely forgotten the earliest 'Rule A' because it discarded the oldest conversations from the beginning of memory to satisfy the max_tokens=40 limit.\n"
     ]
    }
   ],
   "source": [
    "# Create a Formatter with truncation functionality (requires a token counter, otherwise truncation will not be triggered)\n",
    "token_counter = HuggingFaceTokenCounter(\n",
    "    \"Qwen/Qwen3-8B\",\n",
    "    use_mirror=True,\n",
    "    use_fast=True,\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "truncated_formatter = DashScopeChatFormatter(\n",
    "    token_counter=token_counter,\n",
    "    max_tokens=40,\n",
    ")\n",
    "\n",
    "# Create an Agent using this Formatter\n",
    "truncation_agent = create_agent(\n",
    "    name=\"Trunk\",\n",
    "    sys_prompt=\"You are a forgetful robot, you can only remember recent events.\",\n",
    "    # Replace the default formatter with our newly created formatter with truncation functionality\n",
    "    formatter=truncated_formatter\n",
    ")\n",
    "\n",
    "async def run_truncation_test():\n",
    "    # Conduct multiple turns of conversation, deliberately making the context longer\n",
    "    await truncation_agent(Msg(\"user\", \"Rule A: All answers must be declarative sentences.\", \"user\"))\n",
    "    await truncation_agent(Msg(\"user\", \"Rule B: Do not use 'you' or 'I'.\", \"user\"))\n",
    "    await truncation_agent(Msg(\"user\", \"Rule C: Answers should be as brief as possible.\", \"user\"))\n",
    "    await truncation_agent(Msg(\"user\", \"Rule D: Numbers must be written in uppercase characters.\", \"user\"))\n",
    "\n",
    "    print(\"After multiple turns of conversation, the Agent's memory (theoretically very long):\") \n",
    "    for m in await truncation_agent.memory.get_memory():\n",
    "        print(f\"- [{m.role}] {m.name}: {m.content}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*20 + \"\\n\")\n",
    "\n",
    "    # Ask a question to test if the Agent still remembers the earliest Rule A\n",
    "    reply = await truncation_agent(Msg(\"user\", \"Please summarize all rules.\", \"user\"))\n",
    "\n",
    "    print(f\"[{reply.name}]: {reply.content}\")\n",
    "    print(\"\\nThe Agent has likely forgotten the earliest 'Rule A' because it discarded the oldest conversations from the beginning of memory to satisfy the max_tokens=40 limit.\")\n",
    "\n",
    "await run_truncation_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859d5ee7",
   "metadata": {},
   "source": [
    "#### 6.3.2 Strategy two: Extracting key points â€“ rolling summary\n",
    "\n",
    "Simple truncation directly discards information, which is obviously not ideal. A smarter approach is to extract key points before forgetting details. This is the **rolling summary** strategy.\n",
    "\n",
    "- **Idea**: As the conversation progresses, when the history is about to â€œfillâ€ the context window, you invoke the LLM once to summarize the earliest portion of the dialogue (e.g., the first 50%) into a concise paragraph. In subsequent requests, this condensed â€œmemory summaryâ€ replaces the original, verbose conversation records.\n",
    "- **Relative advantages**: While compressing length, it maximizes the preservation of core information from historical conversations, better maintaining long-term conversational coherence.\n",
    "- **Applicable scenarios**: Suitable for tasks requiring long-term goal consistency, such as project planning or long-form content creation.\n",
    "- **Boundary conditions**: It introduces additional API call costs (for generating summaries), and the quality of the summary directly affects subsequent conversations.\n",
    "\n",
    "<img src=\"https://img.alicdn.com/imgextra/i1/O1CN011GzJSI1TeuplTK3gt_!!6000000002408-55-tps-2618-454.svg\" width=\"700\">\n",
    "\n",
    "Currently, `AgentScope` does not have this feature built-in, but you can easily implement this logic by customizing a `Memory` class. Below is a **conceptual implementation idea**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ec7ab736",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2025-11-24T08:58:53.681060Z",
     "iopub.status.busy": "2025-11-24T08:58:53.680725Z",
     "iopub.status.idle": "2025-11-24T08:58:53.686193Z",
     "shell.execute_reply": "2025-11-24T08:58:53.685556Z",
     "shell.execute_reply.started": "2025-11-24T08:58:53.681039Z"
    },
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This is a pseudocode example to demonstrate the core logic of rolling summary\n",
    "# It cannot be run directly; you need to inherit agentscope.memory.MemoryBase and implement the full logic\n",
    "\n",
    "class SummaryMemory: # (MemoryBase)\n",
    "    def __init__(self, buffer_size=10, summary_ratio=0.5):\n",
    "        self.history = []\n",
    "        self.buffer_size = buffer_size\n",
    "        self.summary_ratio = summary_ratio\n",
    "\n",
    "    def add(self, message):\n",
    "        self.history.append(message)\n",
    "        self.try_summarize()\n",
    "\n",
    "    def try_summarize(self):\n",
    "        if len(self.history) > self.buffer_size:\n",
    "            # 1. Determine the part to summarize\n",
    "            num_to_summarize = int(len(self.history) * self.summary_ratio)\n",
    "            messages_to_summarize = self.history[:num_to_summarize]\n",
    "\n",
    "            # 2. Call LLM to generate summary (pseudocode)\n",
    "            # summary_text = llm.call(\"Please summarize the following conversation into one paragraph:\", messages_to_summarize)\n",
    "            summary_text = \"The user set the teaching style to be humorous and engaging, and requested the content to be vivid.\"\n",
    "\n",
    "            summary_message = Msg(\"system\", f\"ã€History summaryã€‘{summary_text}\", \"system\")\n",
    "\n",
    "            # 3. Replace original conversation with summary\n",
    "            self.history = [summary_message] + self.history[num_to_summarize:]\n",
    "            print(f\"--- Memory compressed, current length {len(self.history)} ---\") \n",
    "\n",
    "    def get_memory(self):\n",
    "        return self.history\n",
    "\n",
    "# Usage example\n",
    "# summary_mem = SummaryMemory()\n",
    "# summary_mem.add(Msg(\"user\", \"Our teaching style should be humorous and engaging.\", \"user\"))\n",
    "# ... After multiple turns of conversation ...\n",
    "# summary_mem.add(Msg(\"user\", \"Add another case about cost.\", \"user\"))\n",
    "# This might trigger summarization at this point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbd4f17",
   "metadata": {},
   "source": [
    "#### 6.3.3 Strategy three: Building a knowledge base â€“ vector-based retrieval\n",
    "\n",
    "The previous strategies still process all conversation history in a **linear**, **undifferentiated** manner. But this does not align with how humans remember things. Your memory is not a tape recording played in chronological order, but a vast, interconnected network of knowledge.\n",
    "\n",
    "This â€œon-demand retrievalâ€ pattern is central to building advanced memory systems. This strategy completely changes the game: you no longer try to cram all history into the context; instead, each turn of conversation is transformed into independently retrievable â€œmemory fragmentsâ€ and stored in a specialized â€œlong-term memory bank.â€\n",
    "\n",
    "- **Idea**:\n",
    "  1. **Storage (Ingestion)**: After each conversation turn, you convert the conversation content into a mathematical vector (**Embedding**), then store it along with the original text in a **vector database**.\n",
    "  2. **Retrieval**: When the user asks a new question, you first convert this question into a vector, then perform a similarity search in the database to find the few historical conversation records **most relevant** to the current question.\n",
    "  3. **Composition**: Finally, you combine the retrieved â€œrelevant memoriesâ€ and the userâ€™s â€œlatest questionâ€ into a concise and efficient context, and then send it to the LLM.\n",
    "\n",
    "- **Relative advantages**: Fundamentally breaks free from the length constraints of the context window, capable of precisely â€œrecallingâ€ the most relevant content from massive amounts of information based on current intent, greatly saving costs.\n",
    "- **Applicable scenarios**: This is the foundation for building truly intelligent, long-term interactive Agents. Suitable for all complex scenarios such as personalized assistants, enterprise knowledge bases, and intelligent learning companions.\n",
    "- **Boundary conditions**: The system complexity is highest. It introduces new technology stacks such as Embedding models and vector databases.\n",
    "\n",
    "<img src=\"https://img.alicdn.com/imgextra/i2/O1CN01tb8yvV1Px00aHdbgB_!!6000000001906-55-tps-3558-708.svg\" width=\"700\">\n",
    "\n",
    "`AgentScope` elegantly implements this feature through the `Mem0LongTermMemory` module. It supports two working modes:\n",
    "\n",
    "1. **`static_control`**: Automatically and passively saves and retrieves memories before and after each Agent reply.\n",
    "2. **`agent_control`**: Gives the Agent active memory management tools (`record_to_memory`, `retrieve_from_memory`), allowing the Agent to decide when to remember and when to recall.\n",
    "\n",
    "Letâ€™s first look at the simpler `static_control` mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0231261d",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2025-11-24T08:59:49.019789Z",
     "iopub.status.busy": "2025-11-24T08:59:49.019560Z",
     "iopub.status.idle": "2025-11-24T08:59:53.604421Z",
     "shell.execute_reply": "2025-11-24T08:59:53.603764Z",
     "shell.execute_reply.started": "2025-11-24T08:59:49.019771Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/workspace/llm_learn/lib/python3.10/site-packages/google/protobuf/internal/builder.py:63: RuntimeWarning: coroutine 'main' was never awaited\n",
      "  message_class = _reflection.GeneratedProtocolMessageType(\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[user]: Remember, we are writing a Pandas data analysis course, and the first draft is already complete.\n",
      "LTM_Writer_Static: Understood. Let me know how you'd like to proceed with refining or expanding the Pandas data analysis course content.\n",
      "[LTM_Writer_Static]: Understood. Let me know how you'd like to proceed with refining or expanding the Pandas data analysis course content.\n",
      "\n",
      "==================== Simulating a new session ====================\n",
      "\n",
      "Agent's short-term memory has been cleared.\n",
      "[user]: What was our work progress last time?\n",
      "LTM_Writer_Static: I don't have access to our previous work progress or conversation history. Could you please provide more context or clarify what you'd like to continue working on?\n",
      "[LTM_Writer_Static]: I don't have access to our previous work progress or conversation history. Could you please provide more context or clarify what you'd like to continue working on?\n",
      "\n",
      "Note: Even if short-term memory is cleared, the Agent can still answer correctly because it retrieved relevant information from long-term memory.\n"
     ]
    }
   ],
   "source": [
    "# 1. Initialize the long-term memory module\n",
    "# It requires an LLM (for internal processing) and an embedding model\n",
    "from mem0.vector_stores.configs import VectorStoreConfig\n",
    "\n",
    "# Specify the same dimension (2048) for Qdrant local vector store as DashScope Embedding\n",
    "vector_store = VectorStoreConfig(\n",
    "    config={\n",
    "        \"on_disk\": False,\n",
    "        \"embedding_model_dims\": 2048,\n",
    "    }\n",
    ")\n",
    "\n",
    "long_term_memory = Mem0LongTermMemory(\n",
    "    agent_name=\"Writer\",\n",
    "    user_name=\"user\",\n",
    "    model=DashScopeChatModel(\n",
    "        model_name=\"qwen-plus\",\n",
    "        api_key=os.environ.get(\"DASHSCOPE_API_KEY\"),\n",
    "        stream=False,\n",
    "    ),\n",
    "    embedding_model=DashScopeTextEmbedding(\n",
    "        model_name=\"text-embedding-v4\",\n",
    "        api_key=os.environ.get(\"DASHSCOPE_API_KEY\"),\n",
    "        dimensions=2048\n",
    "    ),\n",
    "    vector_store_config=vector_store,\n",
    ")\n",
    "\n",
    "# 2. Create an Agent equipped with long-term memory\n",
    "ltm_agent_static = create_agent(\n",
    "    name=\"LTM_Writer_Static\",\n",
    "    sys_prompt=\"You are a course writer with long-term memory.\",\n",
    "    long_term_memory=long_term_memory,\n",
    "    long_term_memory_mode=\"static_control\", # Key parameter: set to static control mode\n",
    ")\n",
    "\n",
    "\n",
    "async def run_ltm_static_test():\n",
    "    # Conversation one: Store a key piece of information\n",
    "    msg1 = Msg(\"user\", \"Remember, we are writing a Pandas data analysis course, and the first draft is already complete.\", \"user\") \n",
    "    print(f\"[{msg1.name}]: {msg1.content}\")\n",
    "    reply1 = await ltm_agent_static(msg1)\n",
    "    print(f\"[{reply1.name}]: {reply1.content}\")\n",
    "    # After this step, the conversation content will be automatically stored in long-term memory\n",
    "\n",
    "    print(\"\\n\" + \"=\"*20 + \" Simulating a new session \" + \"=\"*20 + \"\\n\") \n",
    "    # Clear the Agent's short-term memory, simulating a brand new session\n",
    "    await ltm_agent_static.memory.clear()\n",
    "    print(\"Agent's short-term memory has been cleared.\")\n",
    "\n",
    "    # Conversation two: Ask a related question\n",
    "    # Before replying, the Agent will retrieve information from long-term memory using the question \"Who is this course suitable for?\"\n",
    "    msg2 = Msg(\"user\", \"What was our work progress last time?\", \"user\") \n",
    "    print(f\"[{msg2.name}]: {msg2.content}\")\n",
    "    reply2 = await ltm_agent_static(msg2)\n",
    "    print(f\"[{reply2.name}]: {reply2.content}\")\n",
    "    print(\"\\nNote: Even if short-term memory is cleared, the Agent can still answer correctly because it retrieved relevant information from long-term memory.\") # \"æ³¨æ„: å³ä½¿çŸ­æœŸè®°å¿†è¢«æ¸…ç©ºï¼ŒAgent ä¾ç„¶èƒ½å›ç­”æ­£ç¡®ï¼Œå› ä¸ºå®ƒä»é•¿æœŸè®°å¿†ä¸­æ£€ç´¢åˆ°äº†ç›¸å…³ä¿¡æ¯ã€‚\" -> \"Note: Even if short-term memory is cleared, the Agent can still answer correctly because it retrieved relevant information from long-term memory.\"\n",
    "\n",
    "await run_ltm_static_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7469b209",
   "metadata": {},
   "source": [
    "#### 6.3.4 Advanced: From passive context to active memory management\n",
    "\n",
    "At this point, you have mastered powerful strategies for building memory systems for Agents. However, a truly intelligent Agent should not just passively receive your processed context; it should be able to actively manage its own memory.\n",
    "\n",
    "By setting `long_term_memory_mode` to `agent_control`, `ReActAgent` automatically gains two tools: `record_to_memory` and `retrieve_from_memory`. You need to guide it to use these tools in the system prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a00f8f75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T09:02:55.544743Z",
     "iopub.status.busy": "2025-11-24T09:02:55.544297Z",
     "iopub.status.idle": "2025-11-24T09:03:05.705862Z",
     "shell.execute_reply": "2025-11-24T09:03:05.705236Z",
     "shell.execute_reply.started": "2025-11-24T09:02:55.544721Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[user]: The writing style of the course must be very rigorous and academic; this is a core requirement.\n",
      "LTM_Writer_Active: {\n",
      "    \"type\": \"tool_use\",\n",
      "    \"id\": \"call_6992aa3bb8114db38b231a\",\n",
      "    \"name\": \"record_to_memory\",\n",
      "    \"input\": {\n",
      "        \"thinking\": \"The user has specified that the course must be written in a rigorous and academic style. This is a core requirement that will guide all future content creation and must be remembered.\",\n",
      "        \"content\": [\n",
      "            \"The writing style of the course must be very rigorous and academic; this is a core requirement.\"\n",
      "        ]\n",
      "    }\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error awaiting memory task (async): cannot commit - no transaction is active\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system: {\n",
      "    \"type\": \"tool_result\",\n",
      "    \"id\": \"call_6992aa3bb8114db38b231a\",\n",
      "    \"name\": \"record_to_memory\",\n",
      "    \"output\": [\n",
      "        {\n",
      "            \"type\": \"text\",\n",
      "            \"text\": \"Successfully recorded content to memory {'results': [{'id': '6a7097bf-76f9-4167-9fdf-527183becddd', 'memory': 'The course must be written in a rigorous and academic style', 'event': 'ADD'}]}\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "LTM_Writer_Active: The requirement for the course to be written in a rigorous and academic style has been duly noted and recorded. This standard will be strictly adhered to in all subsequent content development, ensuring precision, formal tone, and scholarly integrity throughout the course material.\n",
      "[LTM_Writer_Active]: The requirement for the course to be written in a rigorous and academic style has been duly noted and recorded. This standard will be strictly adhered to in all subsequent content development, ensuring precision, formal tone, and scholarly integrity throughout the course material.\n",
      "\n",
      "==================== Simulating a new session ====================\n",
      "\n",
      "[user]: I forgot, what was the writing style of our course again?\n",
      "LTM_Writer_Active: {\n",
      "    \"type\": \"tool_use\",\n",
      "    \"id\": \"call_e147c32d3d8e484e9a295a\",\n",
      "    \"name\": \"retrieve_from_memory\",\n",
      "    \"input\": {\n",
      "        \"keywords\": [\n",
      "            \"course writing style\"\n",
      "        ]\n",
      "    }\n",
      "}\n",
      "system: {\n",
      "    \"type\": \"tool_result\",\n",
      "    \"id\": \"call_e147c32d3d8e484e9a295a\",\n",
      "    \"name\": \"retrieve_from_memory\",\n",
      "    \"output\": [\n",
      "        {\n",
      "            \"type\": \"text\",\n",
      "            \"text\": \"The course must be written in a rigorous and academic style\\nWriting style of the course must be very rigorous and academic; this is a core requirement\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "LTM_Writer_Active: The writing style of our course must be rigorous and academic. This is a core requirement, ensuring clarity, precision, and scholarly depth in all content.\n",
      "[LTM_Writer_Active]: The writing style of our course must be rigorous and academic. This is a core requirement, ensuring clarity, precision, and scholarly depth in all content.\n"
     ]
    }
   ],
   "source": [
    "# Reuse the previously created long_term_memory instance\n",
    "# Recreate an Agent, this time using agent_control mode\n",
    "from textwrap import dedent\n",
    "ltm_agent_active = create_agent(\n",
    "    name=\"LTM_Writer_Active\",\n",
    "    sys_prompt=dedent(\n",
    "        \"You are a course writer with active memory management capabilities.\\n\" # \"ä½ æ˜¯ä¸€ä¸ªæ‹¥æœ‰ä¸»åŠ¨è®°å¿†ç®¡ç†èƒ½åŠ›çš„è¯¾ç¨‹ç¼–å†™å‘˜ã€‚\" -> \"You are a course writer with active memory management capabilities.\"\n",
    "        \"You can use the following tools to manage your long-term memory:\\n\"\n",
    "        \"- `record_to_memory(data: str)`: Records an important piece of information to long-term memory.\\n\" # \"å°†ä¸€æ®µé‡è¦çš„ä¿¡æ¯è®°å½•åˆ°é•¿æœŸè®°å¿†ä¸­ã€‚\" -> \"Records an important piece of information to long-term memory.\"\n",
    "        \"- `retrieve_from_memory(query: str) -> str`: Retrieves relevant information from long-term memory based on a query.\\n\" # \"æ ¹æ®æŸ¥è¯¢ä»é•¿æœŸè®°å¿†ä¸­æ£€ç´¢ç›¸å…³ä¿¡æ¯ã€‚\" -> \"Retrieves relevant information from long-term memory based on a query.\"\n",
    "        \"Before answering, first consider whether you need to retrieve memory. After the conversation, consider if there is critical information that needs to be recorded.\" # \"åœ¨å›ç­”é—®é¢˜å‰ï¼Œå…ˆæ€è€ƒæ˜¯å¦éœ€è¦æ£€ç´¢è®°å¿†ã€‚åœ¨å¯¹è¯ç»“æŸåï¼Œæ€è€ƒæ˜¯å¦æœ‰å…³é”®ä¿¡æ¯éœ€è¦è®°å½•ã€‚\" -> \"Before answering, first consider whether you need to retrieve memory. After the conversation, consider if there is critical information that needs to be recorded.\"\n",
    "    ),\n",
    "    long_term_memory=long_term_memory,\n",
    "    long_term_memory_mode=\"agent_control\", # Key parameter: set to Agent control mode\n",
    ")\n",
    "\n",
    "\n",
    "async def run_ltm_active_test():\n",
    "    # Conversation one: Agent autonomously decides to record information\n",
    "    msg1 = Msg(\"user\", \"The writing style of the course must be very rigorous and academic; this is a core requirement.\", \"user\") # \"è¯¾ç¨‹çš„å†™ä½œé£æ ¼å¿…é¡»éå¸¸ä¸¥è°¨å’Œå­¦æœ¯åŒ–ï¼Œè¿™æ˜¯ä¸€ä¸ªæ ¸å¿ƒè¦æ±‚ã€‚\" -> \"The writing style of the course must be very rigorous and academic; this is a core requirement.\"\n",
    "    print(f\"[{msg1.name}]: {msg1.content}\")\n",
    "    reply1 = await ltm_agent_active(msg1)\n",
    "    # The Agent, during its thinking process here, will determine that \"core requirement\" is important information and call the record_to_memory tool\n",
    "    print(f\"[{reply1.name}]: {reply1.content}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*20 + \" Simulating a new session \" + \"=\"*20 + \"\\n\") # \"æ¨¡æ‹Ÿä¸€æ¬¡æ–°çš„ä¼šè¯\" -> \"Simulating a new session\"\n",
    "    await ltm_agent_active.memory.clear()\n",
    "\n",
    "    # Conversation two: Agent autonomously decides to retrieve information\n",
    "    msg2 = Msg(\"user\", \"I forgot, what was the writing style of our course again?\", \"user\") # \"æˆ‘å¿˜äº†ï¼Œæˆ‘ä»¬è¯¾ç¨‹çš„å†™ä½œé£æ ¼æ˜¯ä»€ä¹ˆæ¥ç€ï¼Ÿ\" -> \"I forgot, what was the writing style of our course again?\"\n",
    "    print(f\"[{msg2.name}]: {msg2.content}\")\n",
    "    reply2 = await ltm_agent_active(msg2)\n",
    "    # The Agent, during its thinking process here, will first call retrieve_from_memory(query=\"writing style\"), and then generate an answer based on the retrieval result\n",
    "    print(f\"[{reply2.name}]: {reply2.content}\")\n",
    "\n",
    "await run_ltm_active_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e4d0c6",
   "metadata": {},
   "source": [
    "In this way, memory is no longer data \"fed\" to the Agent from the outside, but rather internal knowledge that it actively acquires, stores, and maintains. This allows the Agent to evolve from a simple \"tool\" into a true \"partner.\"\n",
    "\n",
    "> **Further reading: Cost-benefit analysis**  \n",
    ">\n",
    "> You might think that vector-based retrieval and active memory management introduce Embedding model calls, vector database queries, and additional LLM inference (to decide whether to call a tool), which would increase cost and latency.  \n",
    ">\n",
    "> However, we cannot simply compare the cost of \"one high-quality output\" with \"one low-quality output.\" Because if a single call cannot effectively solve the problem (e.g., forgetting a critical requirement), then no matter how low its cost, it is a waste.  \n",
    ">\n",
    "> A fairer comparison is: what is the total cost of both paths to obtain a \"usable\" answer?  \n",
    "> * Path A (no long-term memory): One call, an incorrect answer (problem not solved). You have to manually remind, then call again to solve the problem.  \n",
    "> * Path B (with long-term memory): One call (including retrieval), directly get the correct answer (problem solved).  \n",
    ">\n",
    "> From this perspective, the investment in a memory system is a necessary investment to ensure output quality and avoid repeated, ineffective attempts.\n",
    "\n",
    "#### 6.3.5 Building short-term and long-term memory systems\n",
    "\n",
    "Through the combination of the above strategies, you have built a complete memory system for the Agent, which can be clearly divided into two parts:\n",
    "\n",
    "* Short-term memory: Based on a conversational buffer, managed through truncation or summarization strategies. Its core responsibility is to maintain the coherence of the current conversation. For example, remembering your recently stated specific requirement about \"adding a case to Chapter Two.\"  \n",
    "* Long-term memory: Based on a vector database and tool-based calls. Its core responsibility is to persistently store critical information and support intelligent retrieval across sessions. For example, remembering that the core goal of the entire course project is \"to design for beginners, with a humorous and engaging style.\"\n",
    "\n",
    "An Agent with memory is no longer a cold, one-off Q&A machine. It can learn from experience, remember your preferences, understand long-term context, and ultimately evolve from a simple \"tool\" to a true \"partner.\"\n",
    "\n",
    "> **Practical application and usage recommendations**  \n",
    ">\n",
    "> **I. Quickly introduce memory capabilities**  \n",
    ">\n",
    "> You can leverage mature open-source frameworks or platforms to quickly add memory capabilities to your Agent.  \n",
    "> * AgentScope: As shown in this course, AgentScope provides InMemoryMemory as basic short-term memory, and Mem0LongTermMemory (integrated with Mem0) as an out-of-the-box long-term memory solution.  \n",
    "> * Mem0: An open-source intelligent memory layer specifically designed for AI applications, which encapsulates complex logic such as vector retrieval and memory conflict handling, providing powerful underlying support.  \n",
    "> * LangChain Memory: The powerful Agent development framework LangChain offers rich built-in Memory modules, including ConversationBufferMemory (buffer), ConversationSummaryMemory (summary), and VectorStoreRetrieverMemory (vector retrieval), allowing you to flexibly combine them according to your needs.  \n",
    "> * Alibaba Cloud Bailian Platform: For teams looking for quick validation or those without a technical background, the Bailian platform provides a visual Agent building process, where you can enable long-term memory functionality for your Agent with simple configurations.  \n",
    ">\n",
    "> **II. Memory usage recommendations**  \n",
    ">\n",
    "> * Selective memory: More memory is not always better. Accumulating a large amount of low-value or noisy information can interfere with subsequent retrieval effectiveness. You should establish an admission mechanism for memory writing, for example, only writing when the user explicitly requests it (\"Please remember...\") or when the information's importance exceeds a certain threshold. The agent_control pattern is a good way to achieve this.  \n",
    "> * Continuous governance: Memory is a dynamic data asset that requires a continuous governance mechanism, including regularly cleaning outdated information, merging duplicate entries, verifying factual accuracy, and providing users with an interface to actively manage their own memories (view, modify, delete).  \n",
    "> * Scenario-based application: Different business scenarios have different memory needs. For example, in a course document workflow requiring consistent style, personalized preferences should not be recorded; but for product factual information (such as API parameters, functional limitations), it can be recorded and regularly reviewed for validity to ensure the accuracy of content generated by the Agent.\n",
    "\n",
    "### 6.4 Summary\n",
    "\n",
    "Let's review what you've learned in this section:\n",
    "\n",
    "* Root cause of the problem: Statelessness: LLMs themselves have no memory; each call is independent. Naively passing the complete history leads to excessively long contexts and uncontrolled costs.  \n",
    "* Short-term vs. long-term memory: You can manage short-term memory through \"truncation\" and \"summarization\" strategies to maintain current conversation coherence; you can build long-term memory through \"vector-based retrieval\" to enable cross-session knowledge storage and access.  \n",
    "* Active memory management: By providing the Agent with memory tools like save, recall, update, you can transform it from passively receiving context to an intelligent agent capable of actively managing and utilizing its own memory, achieving true learning and growth.  \n",
    "* Best practices for memory: A powerful memory system needs effective governance. You should selectively write, continuously clean, and update memories, and decide what to remember and what not to remember based on specific business scenarios (such as course writing).\n",
    "\n",
    "## 7 Evaluation-driven development\n",
    "\n",
    "### 7.1 Why \"feeling okay\" is unreliable\n",
    "\n",
    "You just deployed the first version of your \"Course Writing Agent.\" When testing it locally with a few examples, it seemed \"pretty good.\" But after going live, user feedback was disappointing. Some complained that the explanations of technical concepts were inaccurate, others found the responses too verbose, and some encountered formatting errors where code examples couldn't run.\n",
    "\n",
    "You immediately tried to fix it, for example, by adjusting the prompt to make the Agent's explanations \"more accurate.\" After the changes, you re-entered the topic \"Introduction to Python's for loop,\" quickly scanned the generated content, and felt \"this time it's written pretty well, the language is smooth.\" But when you deployed it online, new problems emerged. You were stuck: what exactly was the problem? Did the recent changes optimize or degrade overall performance?\n",
    "\n",
    "> For example, you found that when the Agent explained \"overfitting\" in machine learning, its examples were too academic and not accessible enough. So you gave the Agent an instruction:  \n",
    ">\n",
    "> `...when explaining complex concepts, please use everyday analogies...`  \n",
    ">\n",
    "> After running, it indeed used the analogy of \"memorizing answers for an exam instead of truly understanding the knowledge\" to explain overfitting, which worked well. But you soon found that when generating a course on \"Pandas data filtering,\" it awkwardly inserted an inappropriate analogy, making a simple operation complex and difficult to understand.\n",
    "\n",
    "### 7.2 If it cannot be measured, it cannot be improved\n",
    "\n",
    "The fundamental problem you encountered is the lack of an objective, quantifiable standard. The most direct idea, which you are currently doing, is to manually test a few cases and judge based on subjective feeling. But this \"feeling good\" approach quickly exposes its inherent flaws:\n",
    "\n",
    "* Difficult to quantify: \"Feeling better\" cannot serve as a basis for engineering decisions. You can't know if this improvement was 10% or 20% better than last time.  \n",
    "* Lack of standards: What you consider \"examples too complex\" today might be seen as \"deep content\" if you're in a different mood tomorrow. Different testers and different times can lead to shifting evaluation standards.  \n",
    "* Irreproducible: You cannot systematically run regression tests to ensure new changes haven't broken previously good performance. When you fix the \"inappropriate analogy\" problem, you cannot guarantee that a previous \"clear explanation\" advantage hasn't been accidentally compromised.\n",
    "\n",
    "Why is this the case? It stems from how Agents work. The generation process of LLMs is probabilistic, and the models themselves lack a \"self-correction\" mechanism. Even minor adjustments to your prompt can trigger unpredictable \"butterfly effects\" in a complex system.\n",
    "\n",
    "Since debugging by feeling is not feasible, you naturally think of another approach: establish a systematic evaluation framework, using data rather than feelings to drive development. This is like preparing for an exam; you can't just rely on \"feeling like you've learned it,\" but need to objectively test your mastery by doing practice papers.\n",
    "\n",
    "This is evaluation-driven development. It elevates evaluation from the end of the development process to a core position that determines direction.\n",
    "\n",
    "This philosophy is based on three interconnected principles:\n",
    "\n",
    "* Evaluation, or your \"taste\" for good and bad, determines the upper limit of product capability.  \n",
    "* What can be measured can be effectively improved.  \n",
    "* The faster and more accurate the measurement feedback, the higher the efficiency and effectiveness of improvement.\n",
    "\n",
    "### 7.3 Two evaluation methods: From macro to micro\n",
    "\n",
    "To build an effective evaluation system, you need to examine your Agent from two dimensions: end-to-end evaluation and white-box evaluation.\n",
    "\n",
    "#### 7.3.1 Evaluation method one: End-to-end evaluation\n",
    "\n",
    "End-to-end evaluation focuses on the final output of the system. It answers the most important question: \"Is the course generated by this Agent useful for users?\"\n",
    "\n",
    "##### 7.3.1.1 Iterative establishment of evaluation criteria\n",
    "\n",
    "For complex Agent systems, you cannot predefine all perfect evaluation metrics before the project begins. The correct approach is to embrace iteration. Evaluation is important, but getting started quickly is more important:\n",
    "\n",
    "1. Rapid prototyping: First build a Minimum Viable Product (MVP).  \n",
    "2. Observe problems: Run it in a real scenario and observe where it makes mistakes.  \n",
    "3. Summarize key points: From these errors, identify the critical points that need to be prioritized for evaluation at the current stage and convert them into evaluation metrics.\n",
    "\n",
    "> For example, in the first version of content generated by your course writing Agent, you found that code examples often lacked necessary import statements, making them unable to run directly. This is a clear, high-priority error. Thus, you established the first evaluation metric: \"Code executability\"â€”all code blocks must be self-contained and syntactically correct. Then, you found that the Agent, in an attempt to make the language more vivid, overused metaphors, which instead made core concepts vague. So, you added a second evaluation metric: \"Explanation clarity,\" with a clear requirement to avoid inappropriate metaphors.\n",
    "\n",
    "This loop repeats, and your evaluation system becomes increasingly perfect and precise as the Agent evolves. The figure below shows this complete closed-loop process:\n",
    "\n",
    "<img src=\"https://img.alicdn.com/imgextra/i1/O1CN01I8JNo11e127NWm4wM_!!6000000003810-55-tps-2904-796.svg\" width=\"700\">\n",
    "\n",
    "As shown, starting from MVP, through real operation, error observation, metric refinement, combined with both objective and subjective evaluation methods, ultimately leads to continuous improvement of the Agent. Next, we delve into how to design these two types of metrics.\n",
    "\n",
    "##### 7.3.1.2 Designing evaluation metrics: Objective and subjective\n",
    "\n",
    "A comprehensive evaluation system needs to include both objective and subjective metrics.\n",
    "\n",
    "| Type | Description | \"Course writing Agent\" case |\n",
    "| :--- | :--- | :--- |\n",
    "| **Objective metrics** | Can be directly judged by code rules, results are deterministic. | â€¢ **Code executability**: Can the generated code snippets be successfully run by a Python interpreter?<br>â€¢ **Format check**: Does it include all required sections like \"pain points,\" \"solutions,\" \"summary\"?<br>â€¢ **Word count limit**: Is the length of each section between 300-500 words? |\n",
    "| **Subjective metrics** | Involve semantics, logic, and quality, usually requiring stronger intelligence to judge. | â€¢ **Content accuracy**: Are there factual errors in the explanation of technical concepts?<br>â€¢ **Teaching effectiveness**: Do the introduced cases stimulate learning interest? Are explanations from simple to complex?<br>â€¢ **Language style**: Does it conform to the \"rigorous, precise, calm\" course setting? |\n",
    "\n",
    "But the core problem here is: who defines these metrics? Especially subjective metrics, such as \"teaching effectiveness\" and \"language style,\" what do they really mean?\n",
    "\n",
    "**The key is that evaluation metrics must be led by the most senior business experts in your team.** For your \"course writing Agent,\" these people are top instructional designers and senior lecturers. However, there is a common misconception to avoid here:\n",
    "\n",
    "Many teams' approach is that technical staff first build an initial version of the Agent, and when they find the effect is not ideal, they then go to business experts to \"extract knowledge\"â€”asking them, \"What do you think makes a good course?\" Then the technical team goes back and tries to translate these vague descriptions into evaluation rules. This model is often inefficient because:\n",
    "\n",
    "* Experts lack motivation to participate: They are positioned as \"knowledge providers\" rather than co-builders of the project. Without seeing a direct link to their business goals, their enthusiasm for participation is low.  \n",
    "* Knowledge translation loss: Technical staff find it difficult to fully understand experts' implicit knowledge, and key elements are easily misinterpreted or overlooked during translation.  \n",
    "* Long feedback cycle: By the time the technical team implements and then returns for verification, they have often taken a detour, requiring significant rework.\n",
    "\n",
    "**The correct approach is to empower business experts as the owners of the evaluation system from day one of the project, with the technical team acting as facilitators.** Specifically:\n",
    "\n",
    "1. **Mobilize participation with business goals**: Don't say, \"We need your help to define evaluation metrics.\" Instead, say, \"This Agent will help us achieve [specific business goal, such as 'reduce course production time from 2 weeks to 3 days while maintaining over 90% user satisfaction']. As a guardian of course quality, you need to define what constitutes an 'acceptable quality baseline'.\" When experts see this directly relates to business outcomes they care about, their willingness to participate will significantly increase.\n",
    "\n",
    "2. **Provide structured tools to lower participation barriers**: The value of the technical team lies in providing scaffolding, not doing the work for them. For example:  \n",
    "   â—‹ **Evaluation metrics workshop**: Organize experts for structured dialogue, guiding them with questions like \"If you could only use three metrics to judge course quality, which three would you choose?\"  \n",
    "   â—‹ **Rating scale templates**: Provide fill-in-the-blank templates for \"1-5 points, what specific characteristics correspond to each score?\" so experts fill it out rather than describing from scratch.  \n",
    "   â—‹ **Case annotation tools**: Allow experts to directly annotate \"what's good, what's bad\" on actual Agent outputs, and then reverse-engineer rules from that.  \n",
    "\n",
    "> For example, when an expert annotates a lesson plan with \"feels too bland,\" the technical facilitator needs to ask: 'Bland' means it lacks relatable pain points? This can then refine into the metric 'relevance of opening case'.  \n",
    ">\n",
    "> When an expert says 'students won't understand,' dig deeper: is the concept jump too fast, for example, talking about 'lists' without explaining 'variables' first? This can then be transformed into the metric 'logical progression of theory'.  \n",
    ">\n",
    "> Through this dialogue, you can encode the expert's 'taste' into measurable evaluation items.\n",
    "\n",
    "3. **Establish continuous collaboration mechanisms**: Evaluation standards are not one-time documents but living documents that evolve with Agent capabilities and business needs. In weekly review meetings, experts review data, the technical team adjusts the system, and both parties jointly decide the next optimization direction.\n",
    "\n",
    "In this way, experts are no longer objects from whom \"knowledge is extracted,\" but true owners of the evaluation system. Their \"teaching intuition\" (i.e., \"tacit knowledge\") is systematically transformed into executable and iterative evaluation rules with the aid of structured tools."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c49ae50",
   "metadata": {},
   "source": [
    "##### 7.3.1.3 Improving the stability of subjective evaluation\n",
    "\n",
    "After defining the metrics, the next step is how to conduct the evaluation. You have two options: manual evaluation and automated evaluation with LLMs (LLM-as-a-Judge).\n",
    "\n",
    "*   **Manual evaluation**: Human experts score according to evaluation criteria. This is the most reliable \"gold standard,\" especially in the early stages of a project, as it helps you calibrate the definitions of \"good\" and \"bad.\" However, its drawbacks are high cost, slow speed, and difficulty in scaling up and frequent execution.\n",
    "\n",
    "*   **LLM-based automated evaluation**: Train or guide another LLM to act as an \"evaluation expert,\" automatically scoring the \"course writing Agent's\" output based on your defined metrics and scoring rubrics.\n",
    "\n",
    "To make LLM evaluation more stable, you need to break down a vague evaluation goal (e.g., \"good content quality\") into a series of specific, verifiable details. Then, let the LLM judge each item individually, and finally aggregate the scores according to rules.\n",
    "\n",
    "> For example, evaluating the \"content quality\" generated by the \"course writing Agent\" can be broken down into:\n",
    "> 1.  **Introduction of pain points**: Does it begin with an everyday, concrete pain point? (Yes/No)\n",
    "> 2.  **Theoretical elevation**: Does it clearly point out the limitations of preliminary solutions and introduce core theories? (Yes/No)\n",
    "> 3.  **Relevance of code examples**: Are the provided code examples closely related to the theory explained and sufficiently simplified? (Yes/No)\n",
    "\n",
    "**But you must be wary that LLM evaluation itself may be biased.**\n",
    "\n",
    "> **Further reading: LLM evaluator's \"mindset\"**\n",
    ">\n",
    "> Using an LLM as an evaluator is like hiring a knowledgeable expert who has personal biases. Its own training data determines its \"taste.\"\n",
    "> - **Style bias**: It might prefer a certain coding style (e.g., advocating method chaining), thereby giving lower scores to other equally correct but stylistically different code.\n",
    "> - **Length bias**: It might tend to believe that longer, more detailed explanations are \"more complete,\" thus unfairly penalizing answers that are \"concise but to the point.\"\n",
    "> - **\"People-pleaser\" bias**: Some models tend to give positive feedback and avoid conflict, making it difficult to uncover real problems.\n",
    "> - **Position bias**: Some studies show that when models process lists or compare multiple options, they might tend to choose options at the beginning or end. When designing evaluation prompts, consider randomizing the order of the content being evaluated to mitigate the impact of this bias.\n",
    ">\n",
    "> Therefore, the best practice is: **use human experts for evaluation in the early stages to establish a high-quality \"gold test set.\" Then, use this test set to \"calibrate\" your LLM evaluator**, checking its scoring consistency with human experts. In subsequent development, regularly use manual sampling to ensure the automated evaluation system hasn't \"gone off track.\"\n",
    "\n",
    "#### 7.3.2 Evaluation method two: White-box evaluation\n",
    "\n",
    "When your Agent's process becomes complex, the drawbacks of end-to-end evaluation become apparent. For example, your \"course writing Agent\" might include a \"concept explanation\" component and a \"code generation\" component. If the final course score is not high, it's hard to tell whether the concept explanation was poor or the code examples were terrible.\n",
    "\n",
    "**White-box evaluation** is designed to solve this problem. It advocates going deep inside the system to **design a separate evaluation system for key components**.\n",
    "\n",
    "The core advantages of white-box evaluation are:\n",
    "*  **Clear signals**: Provides unambiguous improvement signals, allowing you to focus on the true bottlenecks.\n",
    "*  **Rapid iteration**: Only needs to test individual components, without running the entire complex process, greatly shortening the verification cycle.\n",
    "*  **Precise optimization**: Whether adjusting hyperparameters or replacing external services, their effects can be precisely measured, making decisions data-driven.\n",
    "\n",
    "> In this way, you can:\n",
    "> - **Individually evaluate the \"concept explanation\" component**: Build a test set containing a series of technical terms (e.g., \"list comprehension,\" \"decorators\"), and then only evaluate whether the text explanations generated by this component are clear and accurate.\n",
    "> - **Individually evaluate the \"code generation\" component**: Build a test set containing a series of task descriptions (e.g., \"generate a function to merge two dictionaries\"), and then only evaluate whether the generated code runs correctly and follows best practices.\n",
    ">\n",
    "> The advantage of this method is that it provides unambiguous improvement signals, allowing you to focus on true bottlenecks and achieve fast, precise optimization.\n",
    "\n",
    "In practice, you don't need to aim for a fully automated, comprehensive, multi-dimensional evaluation system from the start. For example, when dealing with code correctness, you can begin with the simplest method: manually copy and run the code a few times. Then, gradually upgrade to writing a script that automatically executes code and catches errors. Finally, you can build a complete evaluation pipeline with various metrics (style, efficiency, correctness). The ultimate choice depends on your specific needs, budget, and acceptable error rate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f485cd97",
   "metadata": {},
   "source": [
    "### 7.4 Evaluation frameworks\n",
    "\n",
    "You can build an evaluation workflow that meets your business needs by writing code rules and combining them with LLMs. Alternatively, you can leverage mature community evaluation frameworks to accelerate this process. In addition to AgentScope, the RAGAS framework mentioned in the RAG evaluation section also provides end-to-end and component-level evaluation capabilities for Agents. Furthermore, you can choose DeepEval as an LLM evaluation framework.\n",
    "\n",
    "#### 7.4.1 Practice: AgentScope evaluation framework demo\n",
    "\n",
    "To run a minimal \"evaluation-driven development\" end-to-end example, you need to understand the following modules:\n",
    "\n",
    "- **agentscope.evaluate**: `Task` (task definition), `MetricBase/MetricResult/MetricType` (custom metrics), `SolutionOutput` (unified representation of solutions).\n",
    "- **pydantic**: Used to define structured output models, improving evaluation stability (allowing models to output parsable numerical values).\n",
    "- **agentscope.init (optional)**: Used to enable tracing, sending execution traces to Studio or an OTLP-compatible backend.\n",
    "\n",
    "> Note: The teaching-oriented \"minimal runnable\" version does not rely on `GeneralEvaluator/RayEvaluator` or other more complete evaluators; we can directly form a compact loop with `Task + Metric`. If you need to run large-scale benchmarks or distributed evaluations, then introduce evaluators and storage modules.\n",
    "\n",
    "The following example demonstrates \"drafting a Pandas data analysis course lesson\" and performs programmable objective scoring of the draft. Key points:\n",
    "- Structured output (`title/learning_objectives/code_example/quiz`), improving evaluation stability.\n",
    "- Fine-grained subjective scoring (LLM-as-Judge): evaluates five dimensions (language clarity/ambiguity, factual correctness, consistency, redundancy (lower redundancy, higher score), readability) on a 1-5 scale; uses structured output for stable scoring.\n",
    "- Tracing (optional): Set `AGENTSCOPE_STUDIO_URL` (to connect to AgentScope Studio) or `OTEL_TRACING_URL` (to connect to any OTLP-compatible backend) to automatically enable tracing; the example runs normally if not set.\n",
    "\n",
    "<img src=\"https://img.alicdn.com/imgextra/i1/O1CN01sVlrx61EZg4DxUddO_!!6000000000366-55-tps-2177-495.svg\" width=\"700\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "af57cc1d",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2025-11-24T09:56:57.716910Z",
     "iopub.status.busy": "2025-11-24T09:56:57.716684Z",
     "iopub.status.idle": "2025-11-24T09:57:34.528672Z",
     "shell.execute_reply": "2025-11-24T09:57:34.528072Z",
     "shell.execute_reply.started": "2025-11-24T09:56:57.716892Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Friday: Here is the lesson draft on pandas DataFrame.\n",
      "\n",
      "[pandas_intro] Draft content:\n",
      "{\n",
      "  \"title\": \"Introduction to Pandas DataFrame\",\n",
      "  \"learning_objectives\": [\n",
      "    \"Import pandas library\",\n",
      "    \"Create a DataFrame\",\n",
      "    \"Load data from CSV\",\n",
      "    \"View first few rows\",\n",
      "    \"Understand DataFrame structure\"\n",
      "  ],\n",
      "  \"lesson_content\": \"This lesson introduces the pandas DataFrame, a core data structure for data analysis. A DataFrame is a 2D table with rows and columns, similar to a spreadsheet. First, import pandas using 'import pandas as pd'. You can create a DataFrame from a dictionary or load one from a CSV file using pd.read_csv(). Use .head() to preview the first 5 rows. Common mistakes include incorrect file paths in read_csv() and forgetting to assign the result to a variable. Always check output after loading data. Understanding the shape and structure early prevents errors in later analysis. Summarizing: DataFrames organize data, and .head() helps verify correct loading.\",\n",
      "  \"code_example\": \"# Import pandas\\nimport pandas as pd\\n\\n# Create a simple DataFrame\\ndata = {'Name': ['Alice', 'Bob'], 'Age': [25, 30]}\\ndf = pd.DataFrame(data)\\n\\n# Display first few rows\\ndf.head()\",\n",
      "  \"quiz\": \"Which method shows the first 5 rows of a DataFrame?\\nA) df.top()\\nB) df.start()\\nC) df.begin()\\nD) df.head()\\nAnswer: D\"\n",
      "}\n",
      "Evaluator: The lesson draft is well-structured with clear objectives and a logical flow from introduction to summary, covering key concepts and common pitfalls. The code example is correct, runnable, and appropriately commented, aligning well with the content. The quiz is clearly marked and includes the correct answer.\n",
      "[pandas_intro] score=0.80 (clarity=4 | factual=5 | consistency=4 | redundancy=4 | readability=4 | feedback=Improve clarity by expanding the example to include loading from a CSV file, as this is one of the stated learning objectives but currently lacks a corresponding code demonstration.)\n",
      "Friday: Here is the lesson draft on pandas groupby and aggregation.\n",
      "\n",
      "[pandas_groupby] Draft content:\n",
      "{\n",
      "  \"title\": \"Grouping and Aggregating Data with Pandas\",\n",
      "  \"learning_objectives\": [\n",
      "    \"Use groupby on a column\",\n",
      "    \"Apply aggregation functions\",\n",
      "    \"Differentiate agg and describe\",\n",
      "    \"Analyze grouped statistics\",\n",
      "    \"Handle missing data in groups\"\n",
      "  ],\n",
      "  \"lesson_content\": \"This lesson covers groupby and aggregation in pandas, essential for business data analysis. The groupby operation splits data into groups based on a keyâ€”like sales by region. First, select a categorical column (e.g., 'Region') and apply .groupby() to it. Then, use .agg() to apply specific functions (e.g., sum, mean). For example, df.groupby('Region')['Sales'].agg('mean') computes average sales per region. In contrast, .describe() gives a full statistical summary (count, mean, std, etc.) of each group. Step-by-step: 1) Group the data, 2) Select numeric column(s), 3) Apply aggregation. Common errors include applying agg to non-numeric columns or forgetting parentheses. Always check data types and handle NaN values before grouping. Extended thinking: groupby enables multi-level analysis, such as region and product category together, revealing deeper insights. Summary: groupby organizes data, and agg/describe extract meaningful metrics.\",\n",
      "  \"code_example\": \"# Import pandas\\nimport pandas as pd\\n\\n# Sample sales data\\ndata = {\\n    'Region': ['North', 'South', 'North', 'South'],\\n    'Sales': [100, 150, 200, 130]\\n}\\ndf = pd.DataFrame(data)\\n\\n# Group by Region and aggregate mean sales\\ngrouped = df.groupby('Region')['Sales'].agg('mean')\\nprint(grouped)\",\n",
      "  \"quiz\": \"What does .describe() provide that .agg() does not?\\nA) Single aggregated value\\nB) Custom function application\\nC) Full statistical summary\\nD) Faster computation\\nAnswer: C\"\n",
      "}\n",
      "Evaluator: The lesson effectively explains grouping and aggregation in pandas with a logical flow, accurate code example, and clear quiz. All learning objectives are addressed, the content follows introduction â†’ concept â†’ example â†’ summary, and the code is runnable and commented. Common pitfalls and extended thinking are included.\n",
      "[pandas_groupby] score=1.00 (clarity=5 | factual=5 | consistency=5 | redundancy=5 | readability=5 | feedback=The lesson is clear and well-structured; consider adding a multi-level groupby example to further enhance depth.)\n",
      "\n",
      "Average score: 0.90\n"
     ]
    }
   ],
   "source": [
    "# End-to-end evaluation for educational course writing (pandas): two lesson drafts + five-dimension LLM scoring\n",
    "import asyncio\n",
    "import copy\n",
    "import json\n",
    "import os\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional, Dict\n",
    "\n",
    "import agentscope\n",
    "from agentscope.message import Msg\n",
    "from agentscope.agent import ReActAgent\n",
    "from agentscope.model import DashScopeChatModel\n",
    "from agentscope.formatter import DashScopeChatFormatter\n",
    "from agentscope.evaluate import (\n",
    "    Task,\n",
    "    MetricBase,\n",
    "    MetricResult,\n",
    "    MetricType,\n",
    "    SolutionOutput,\n",
    ")\n",
    "\n",
    "assert os.getenv(\"DASHSCOPE_API_KEY\"), \"Please set DASHSCOPE_API_KEY in your environment first\"\n",
    "\n",
    "# (Optional) Enable tracing: prioritize connecting to Studio; otherwise, connect to any OTLP-compatible backend\n",
    "studio_url = os.getenv(\"AGENTSCOPE_STUDIO_URL\")\n",
    "otel_url = os.getenv(\"OTEL_TRACING_URL\")\n",
    "if studio_url:\n",
    "    agentscope.init(studio_url=studio_url)\n",
    "elif otel_url:\n",
    "    agentscope.init(tracing_url=otel_url)\n",
    "\n",
    "# 1) Define a minimal benchmark (two lesson writing tasks)\n",
    "COURSE_BENCHMARK = [\n",
    "    {\n",
    "        \"id\": \"pandas_intro\",\n",
    "        \"prompt\": (\n",
    "            \"Please write a draft for an introductory lesson on pandas DataFrame in concise English. The output must include structured fields:\\n\"\n",
    "            \"- title: Lesson title;\\n\"\n",
    "            \"- learning_objectives (3-5 items, each no more than 25 characters);\\n\"\n",
    "            \"- lesson_content: At least 180 characters of main lesson text, including an opening guide, explanation of core concepts, step-by-step example explanation, and a class summary;\\n\" \n",
    "            \"- code_example: Minimal runnable pandas code with comments (demonstrating `import pandas as pd`, `read_csv` or DataFrame creation, and `head()` usage example);\\n\"\n",
    "            \"- quiz: A single-choice question with options, no less than 4 options, and marking the correct answer.\\n\"\n",
    "            \"lesson_content should emphasize common pitfalls for beginners and correspond with code examples.\"\n",
    "        ),\n",
    "        \"tags\": {\"topic\": \"intro\", \"min_objectives\": 3},\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"pandas_groupby\",\n",
    "        \"prompt\": (\n",
    "            \"Please write a draft for a lesson on pandas groupby and aggregation in concise English. The output must include structured fields:\\n\"\n",
    "            \"- title: Lesson title;\\n\"\n",
    "            \"- learning_objectives (3-5 items, each no more than 25 characters);\\n\"\n",
    "            \"- lesson_content: At least 200 characters of main lesson text, first explaining the groupby idea, then breaking down aggregation steps with a real business context, including the difference between agg and describe, and adding common error tips;\\n\"\n",
    "            \"- code_example: Minimal runnable pandas code with comments, demonstrating at least one groupby and one agg or describe;\\n\"\n",
    "            \"- quiz: A single-choice question with options, no less than 4 options, and marking the correct answer.\\n\"\n",
    "            \"lesson_content should provide step-by-step operational explanations and extended thinking.\"\n",
    "        ),\n",
    "        \"tags\": {\"topic\": \"groupby\", \"min_objectives\": 3},\n",
    "    },\n",
    "]\n",
    "\n",
    "# 2) Define structured output model\n",
    "class CourseDraft(BaseModel):\n",
    "    title: str = Field(description=\"Lesson title\")\n",
    "    learning_objectives: List[str] = Field(description=\"Learning objectives (3-5 items)\")\n",
    "    lesson_content: str = Field(description=\"Main lesson text, at least 180 characters for the detailed draft\")\n",
    "    code_example: str = Field(description=\"Minimal runnable pandas code example\")\n",
    "    quiz: str = Field(description=\"A multiple-choice question (brief)\")\n",
    "\n",
    "# 3) Define five-dimension LLM scoring structure and metrics\n",
    "class EvalScore(BaseModel):\n",
    "    clarity: int = Field(description=\"Language clarity/ambiguity, 1-5 (higher = clearer)\")\n",
    "    factual_correctness: int = Field(description=\"Factual correctness, 1-5 (higher = more correct)\")\n",
    "    consistency: int = Field(description=\"Consistency in expression, 1-5 (higher = more consistent)\")\n",
    "    redundancy: int = Field(description=\"Redundancy in expression, 1-5 (higher = more concise)\")\n",
    "    readability: int = Field(description=\"Readability, 1-5 (higher = more readable)\")\n",
    "    overall: Optional[float] = Field(default=None, description=\"Optional, overall score 0-1\")\n",
    "    feedback: str = Field(description=\"One-sentence improvement suggestion\")\n",
    "\n",
    "class LLMEvalMetric(MetricBase):\n",
    "    def __init__(self, eval_agent: ReActAgent, axis_weights: Optional[Dict[str, float]] = None):\n",
    "        super().__init__(\n",
    "            name=\"llm_eval_course_draft\",\n",
    "            metric_type=MetricType.NUMERICAL,\n",
    "            description=\"LLM-as-Judge for five axes\",\n",
    "            categories=[],\n",
    "        )\n",
    "        self.eval_agent = eval_agent\n",
    "        self.axis_weights = axis_weights or {\n",
    "            \"clarity\": 1.0,\n",
    "            \"factual_correctness\": 1.0,\n",
    "            \"consistency\": 1.0,\n",
    "            \"redundancy\": 1.0,\n",
    "            \"readability\": 1.0,\n",
    "        }\n",
    "        # Take a snapshot of the evaluator's pristine state so every call starts clean.\n",
    "        self._initial_state = copy.deepcopy(self.eval_agent.state_dict())\n",
    "\n",
    "    async def __call__(self, solution: SolutionOutput) -> MetricResult:\n",
    "        # Reset evaluator state before scoring to avoid cross-task contamination.\n",
    "        try:\n",
    "            self.eval_agent.load_state_dict(copy.deepcopy(self._initial_state))\n",
    "        except Exception as exc:  # pragma: no cover - defensive\n",
    "            return MetricResult(\n",
    "                name=self.name,\n",
    "                result=0.0,\n",
    "                message=f\"failed to reset evaluator state: {exc}\",\n",
    "            )\n",
    "\n",
    "        draft = solution.output or {}\n",
    "        # Provide clear scoring criteria, requiring strictly structured output\n",
    "        prompt = (\n",
    "            \"As an educational content reviewer, please evaluate the following lesson draft across five dimensions on a 1-5 scale, and provide a one-sentence improvement suggestion.\\n\"\n",
    "            \"Scoring dimensions:\\n\"\n",
    "            \"1) clarity: Language clarity/ambiguity (higher score = clearer);\\n\"\n",
    "            \"2) factual_correctness: Factual correctness (higher score = more correct);\\n\"\n",
    "            \"3) consistency: Consistency in expression (higher score = more consistent);\\n\"\n",
    "            \"4) redundancy: Redundancy in expression (higher score = more concise);\\n\"\n",
    "            \"5) readability: Readability (higher score = more readable).\\n\"\n",
    "            \"Scoring reference: 5 points only for excellent drafts requiring almost no modification; 4 points for excellent but still needing minor adjustments; 3 points for basically acceptable but with obvious problems; 2 points or less means significant modification is needed. If lesson_content is less than 180 characters, lacks step-by-step explanations, or does not cover common pitfalls, please set the upper limit for clarity and readability scores to 3 points and explain in the feedback.\\n\"\n",
    "            \"Check points: Does the number of learning objectives meet requirements, does lesson_content include introduction â†’ concept â†’ example â†’ summary and correspond with code, is the code example runnable and commented, is the quiz clearly marked with the correct answer.\\n\"\n",
    "            \"Only output structured fields: clarity, factual_correctness, consistency, redundancy, readability, overall(optional), feedback.\\n\\n\"\n",
    "            f\"Title: {draft.get('title','')}\\n\"\n",
    "            f\"Learning objectives: {draft.get('learning_objectives', [])}\\n\"\n",
    "            f\"Content:\\n{draft.get('lesson_content','')}\\n\\n\"\n",
    "            f\"Code example:\\n{draft.get('code_example','')}\\n\"\n",
    "            f\"Quiz: {draft.get('quiz','')}\\n\"\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            res = await self.eval_agent(\n",
    "                Msg(\"user\", prompt, role=\"user\"),\n",
    "                structured_model=EvalScore,\n",
    "            )\n",
    "        except Exception as exc:\n",
    "            return MetricResult(\n",
    "                name=self.name,\n",
    "                result=0.0,\n",
    "                message=f\"evaluator call failed: {exc}\",\n",
    "            )\n",
    "\n",
    "        s = res.metadata or {}\n",
    "        if not isinstance(s, dict):\n",
    "            return MetricResult(\n",
    "                name=self.name,\n",
    "                result=0.0,\n",
    "                message=f\"invalid evaluator metadata type: {type(s).__name__}\",\n",
    "            )\n",
    "\n",
    "        axes = [\"clarity\", \"factual_correctness\", \"consistency\", \"redundancy\", \"readability\"]\n",
    "\n",
    "        def norm(v: int) -> float:\n",
    "            return max(0.0, min(1.0, (float(v) - 1.0) / 4.0))\n",
    "\n",
    "        def _coerce(axis: str) -> int:\n",
    "            if axis not in s:\n",
    "                return 1\n",
    "            return int(s[axis])\n",
    "\n",
    "        try:\n",
    "            # Coerce scores to integers, defaulting to baseline when missing.\n",
    "            values = {axis: _coerce(axis) for axis in axes}\n",
    "        except Exception as exc:\n",
    "            return MetricResult(\n",
    "                name=self.name,\n",
    "                result=0.0,\n",
    "                message=f\"invalid evaluator payload: {exc}\",\n",
    "            )\n",
    "\n",
    "        weighted = sum(self.axis_weights[axis] * norm(values.get(axis, 1)) for axis in axes)\n",
    "        denom = sum(self.axis_weights.values()) or 1.0\n",
    "        score = weighted / denom\n",
    "\n",
    "        msg = (\n",
    "            f\"clarity={values.get('clarity')} | factual={values.get('factual_correctness')} | \"\n",
    "            f\"consistency={values.get('consistency')} | redundancy={values.get('redundancy')} | \"\n",
    "            f\"readability={values.get('readability')} | feedback={s.get('feedback','')}\"\n",
    "        )\n",
    "        return MetricResult(name=self.name, result=score, message=msg)\n",
    "\n",
    "# 4) Assemble into a Task list\n",
    "def build_tasks() -> list[Task]:\n",
    "    tasks: list[Task] = []\n",
    "    for item in COURSE_BENCHMARK:\n",
    "        tasks.append(\n",
    "            Task(\n",
    "                id=item[\"id\"],\n",
    "                input=item[\"prompt\"],\n",
    "                ground_truth=1.0,  # Expect all to pass objective checks\n",
    "                tags=item[\"tags\"],\n",
    "                metrics=[],  # Inject LLM scoring metrics later\n",
    "                metadata={},\n",
    "            )\n",
    "        )\n",
    "    return tasks\n",
    "\n",
    "# 5) Create a minimal agent (real DashScope API call)\n",
    "agent = ReActAgent(\n",
    "    name=\"Friday\",\n",
    "    sys_prompt=(\n",
    "        \"You are an educational course author, specializing in pandas data analysis. Please write a lesson draft in concise English,\"\n",
    "        \"strictly outputting structured fields: title, learning_objectives(list[str]), lesson_content(str), code_example(str), quiz(str).\"\n",
    "        \"lesson_content should be at least 180 characters, including an introduction, concept explanation, step-by-step examples, common error tips, and a summary.\"\n",
    "    ),\n",
    "    model=DashScopeChatModel(\n",
    "        api_key=os.environ.get(\"DASHSCOPE_API_KEY\"),\n",
    "        model_name=\"qwen-plus\",\n",
    "        stream=False,\n",
    "    ),\n",
    "    formatter=DashScopeChatFormatter(),\n",
    "    enable_meta_tool=False,\n",
    ")\n",
    "\n",
    "# 5.1) Review Agent (can reuse the same model as generation)\n",
    "evaluator = ReActAgent(\n",
    "    name=\"Evaluator\",\n",
    "    sys_prompt=(\n",
    "        \"You are a strict educational content reviewer, outputting structured scores (1-5) and a one-sentence suggestion according to the scoring criteria,\"\n",
    "        \"do not output any content other than the structured output.\"\n",
    "    ),\n",
    "    model=DashScopeChatModel(\n",
    "        api_key=os.environ.get(\"DASHSCOPE_API_KEY\"),\n",
    "        model_name=\"qwen-plus\",\n",
    "        stream=False,\n",
    "    ),\n",
    "    formatter=DashScopeChatFormatter(),\n",
    "    enable_meta_tool=False,\n",
    ")\n",
    "\n",
    "# 6) Minimal evaluation loop\n",
    "async def run_minimal_eval() -> None:\n",
    "    tasks = build_tasks()\n",
    "    # Inject five-dimension LLM scoring metrics\n",
    "    metric = LLMEvalMetric(eval_agent=evaluator)\n",
    "    for t in tasks:\n",
    "        t.metrics = [metric]\n",
    "    scores = []\n",
    "    for task in tasks:\n",
    "        res = await agent(\n",
    "            Msg(\"user\", task.input, role=\"user\"),\n",
    "            structured_model=CourseDraft,\n",
    "        )\n",
    "        draft = {\n",
    "            \"title\": res.metadata.get(\"title\"),\n",
    "            \"learning_objectives\": res.metadata.get(\"learning_objectives\"),\n",
    "            \"lesson_content\": res.metadata.get(\"lesson_content\"),\n",
    "            \"code_example\": res.metadata.get(\"code_example\"),\n",
    "            \"quiz\": res.metadata.get(\"quiz\"),\n",
    "        }\n",
    "        print(\n",
    "            f\"\\n[{task.id}] Draft content:\\n\"\n",
    "            f\"{json.dumps(draft, ensure_ascii=False, indent=2)}\"\n",
    "        )\n",
    "\n",
    "        solution = SolutionOutput(success=True, output=draft, trajectory=[])\n",
    "        metric_res = await task.metrics[0](solution)\n",
    "        scores.append(metric_res.result)\n",
    "        print(f\"[{task.id}] score={metric_res.result:.2f} ({metric_res.message})\")\n",
    "\n",
    "    avg = sum(scores) / len(scores) if scores else 0.0\n",
    "    print(f\"\\nAverage score: {avg:.2f}\")\n",
    "\n",
    "await run_minimal_eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9745be",
   "metadata": {},
   "source": [
    "> **Summary**: The code above demonstrates the minimal closed loop of \"evaluation-driven development\"â€”encoding the objective elements of a \"good lesson\" into executable checks using `Task + Metric`, and then running them end-to-end with a real API for quantitative scoring. You can try: fine-tuning `sys_prompt`, changing `model_name` or temperature, or improving metrics (e.g., checking if code runs, if it includes links to output screenshots), then repeat the evaluation and observe if the score improves. If `AGENTSCOPE_STUDIO_URL` or `OTEL_TRACING_URL` is set, you can also view the time consumption and trace details of models/tools/formatters in the tracing backend.\n",
    "\n",
    "Ultimately, transitioning from relying on subjective feelings to establishing an evaluation system that combines \"end-to-end\" and \"white-box\" approaches is the necessary path to building high-level Agents. This process essentially transforms vague \"good\" and \"bad\" standards into clear, executable engineering problems. Evaluation is not the end of development but the beginning of optimization. A powerful evaluation system will become your most reliable compass when exploring the boundaries of Agent capabilities.\n",
    "\n",
    "### 7.5 Summary\n",
    "\n",
    "Let's review what you've learned in this section:\n",
    "\n",
    "- **Beyond subjective feelings**: Agent optimization should move away from the \"feeling good\" pattern and towards evaluation-driven development based on objective data. This is a prerequisite for rigorous, controllable optimization.\n",
    "- **Experts define standards**: Evaluation metrics, especially subjective ones, should be primarily defined by senior business experts, translating their implicit knowledge into clear, measurable rules.\n",
    "- **Beware of model bias**: When using LLMs for automated evaluation, you must be wary of their inherent biases (e.g., style, length) and regularly calibrate them with \"gold test sets\" from human experts.\n",
    "- **Combine end-to-end and white-box approaches**: Use end-to-end evaluation to grasp the Agent's overall user value, while leveraging white-box evaluation to delve into key components, precisely identifying and resolving performance bottlenecks.\n",
    "- **Iterative refinement**: A powerful evaluation system evolves gradually rather than being built all at once. Start with the most critical and easiest parts to implement, and iterate continuously.\n",
    "\n",
    "## 8 Summary\n",
    "\n",
    "At this point, you have completed all the content of this chapter. Let's review and systematically organize the Agent knowledge you've just built from a more macroscopic perspective.\n",
    "\n",
    "### 8.1 Everything starts with \"user intent\"\n",
    "\n",
    "You started with a common pain point: a single LLM call, while capable of language tasks, often struggles when faced with complex tasks requiring multiple steps and interaction with the external world.\n",
    "\n",
    "To solve this problem, your goal is to build a system that can stably and reliably understand and fulfill true user intent. This is where the value of an Agent lies. If an LLM is a smart \"brain\" confined in a \"black box,\" then what you've learned in this chapter is how to build a complete \"engineering system\" around this \"brain,\" enabling it to accomplish complex real-world tasks.\n",
    "\n",
    "### 8.2 Core methodology: Context engineering\n",
    "\n",
    "In exploring how to build Agents, you learned various engineering techniques. Now, let's examine these techniques from a core engineering perspective: **Context Engineering**.\n",
    "\n",
    "When you first encountered LLMs, you learned about **Prompt Engineering**, whose core is to enable the model to deliver the best output in a **single interaction** through carefully designed instructions.\n",
    "\n",
    "Now you are dealing with complex tasks that span **multiple interactions** and involve **multiple external information sources**. At this point, your focus shifts from \"writing a good Prompt\" to systematically providing the most sufficient and precise **context** for every decision the model makes. This is context engineering.\n",
    "\n",
    "From this perspective, as the designer of an Agent, you are no longer just a \"questioner,\" but an **\"information architect.\"** Your core task is to design processes and call tools to build a perfect **\"information cocoon\"** for the LLM node responsible for final decisions, containing everything needed to solve the problemâ€”no more and no less. **The quality of the context directly determines the upper limit of the Agent's capabilities.**\n",
    "\n",
    "Under the \"context engineering\" approach, the capabilities you learned in the first half of this chapter all have clear positions: they are specific means within the discipline of **\"context injection\"**:\n",
    "\n",
    "- **Tool use**: Injecting real-time, deterministic information from the external world into the context.\n",
    "- **Reflection**: Using the \"evaluation result\" of the previous step as new feedback, revising the context for the next step to guide subsequent actions.\n",
    "- **Workflow**: Designing a relatively fixed task pipeline, specifying **when** and **by which node** to inject **what kind of context** into the modelâ€”like a dedicated \"context manipulation\" pipeline driving all subsequent steps to run stably.\n",
    "- **Memory system**: Retrieving the most relevant parts from massive historical information and injecting them into the current context to provide references for subsequent decisions.\n",
    "\n",
    "These capabilities do not exist in isolation but collectively serve the core goal of **\"optimizing context,\"** enabling the Agent to complete tasks more efficiently and reliably.\n",
    "\n",
    "### 8.3 Quality assurance: Evaluation-driven development\n",
    "\n",
    "Since context is key, how do you ensure the context you build is \"high-quality\"? The answer is: **evaluation**.\n",
    "\n",
    "Without measurement, there is no improvement. Transforming the Agent's development process from \"debugging by feeling\" to \"data-driven\" is crucial for its successful deployment in a production environment. To this end, you learned three complementary evaluation dimensions:\n",
    "\n",
    "- **End-to-end evaluation**: It answers the most important question: *\"Did the Agent ultimately fulfill the user's intent?\"* This is a macroscopic assessment from a business perspective.\n",
    "- **White-box evaluation**: It helps you pinpoint the problem: *\"Did the tool call fail, or was memory retrieval inaccurate?\"* This is a microscopic diagnosis that delves into the internal system, focusing on each \"context injection\" node.\n",
    "- **Continuous iteration**: Integrating evaluation into every aspect of development, forming a data-driven, continuously optimizing closed loop. This ensures that the Agent's capabilities can evolve with business development and data accumulation.\n",
    "\n",
    "By establishing such a **\"macro + micro + iterative\"** evaluation system, you gain a flywheel that drives continuous optimization of the Agent. More importantly, this system is not limited to context engineering but serves as the **\"feedback nervous system\"** for the entire Agent system, permeating subsequent autonomous planning and multi-agent collaboration.\n",
    "\n",
    "### 8.4 Outlook: More powerful autonomy\n",
    "\n",
    "So far, the \"context engineering\" we've discussed primarily focuses on building an Agent with exceptionally strong **\"individual capabilities\"** and clearly controllable behavior boundaries around a single task. You have mastered the basic paradigm of enabling it to use various tools, possess memory, and learn to reflect. This engineering approach, centered on fixed workflows, is already very powerful and represents the most mainstream and pragmatic implementation paradigm in the industry today.\n",
    "\n",
    "But the evolution of single Agents does not stop there. The next stage of its development is to grant it greater **\"autonomy\"**:\n",
    "\n",
    "- **Autonomous planning**: The Agent no longer strictly executes your preset static workflow, but, like a project manager, autonomously plans, decomposes, and executes tasks based on the ultimate goal. This means the Agent gains the ability to dynamically adapt to problems and autonomously generate solutions.\n",
    "- **Multi-agent systems**: Building further on autonomous planning, this involves having multiple Agents with autonomous decision-making capabilities form a team, allowing them to autonomously divide labor, initiate collaboration, exchange information, and integrate intermediate results around a common goalâ€”rather than having you hardcode each collaboration process. At this point, the system's \"autonomy\" is no longer limited to the planning capabilities of a single Agent but is amplified into a **collective intelligence** closer to a real team through the interaction of multiple Agents.\n",
    "\n",
    "This represents a leap in Agent systems from a mode primarily focused on engineering controllability to one of more open autonomy and emergent behavior. While the structured workflows you've learned are the most reliable foundation for current engineering practices, exploring advanced capabilities like autonomous planning and multi-agent collaboration will be key to unlocking the next phase of Agent potential.\n",
    "\n",
    "Ultimately, you need to keep pace with the times. First, apply the context engineering and evaluation system you've learned to practice, building an Agent engineering system with fixed workflows as its skeleton, controllable behavior, and high reliability. On this foundation, under the guidance and constraints of the same evaluation and feedback mechanism, gradually introduce autonomous planning and multi-agent collaboration, allowing the system to progress towards more open autonomy and emergent intelligence while ensuring controllability.\n",
    "\n",
    "### Final Summary\n",
    "\n",
    "An excellent Agent system is not a single advanced technology but a combination of two complementary approaches:\n",
    "\n",
    "1. **Engineered controllable autonomy**: Deeply understand business scenarios, translate efficient real-world processes and evaluation principles into the Agent's workflows and evaluation system, and meticulously control every aspect through context engineering to maximize the model's \"individual capabilities\" within clear boundaries, thereby building a reliable and controllable Agent engineering system. This is the **\"engineering foundation\"** at the strategic and tactical levels.\n",
    "2. **Open-ended autonomous evolution**: On top of this engineering foundation, and under the constraints and guidance of the same evaluation and feedback mechanism, introduce autonomous planning and multi-agent collaboration. This allows Agents to move beyond passively executing preset processes, enabling them to plan, divide tasks, collaborate, and generate emergent behaviors around a goal, gradually raising the overall intelligence ceiling of the system while maintaining controllability. This represents **\"intelligent evolution\"** for the future.\n",
    "\n",
    "By mastering these two approaches, you will have the foundation to build powerful, reliable, and continuously evolving intelligent systems. Now is the time to use them to realize your creativity and build your own AI applications, systems, and services."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python (llm_learn)",
   "language": "python",
   "name": "llm_learn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
